{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph æ•™ç¨‹ 04ï¼šå·¥å…·è°ƒç”¨å’ŒAgent\n",
    "\n",
    "## è¯¾ç¨‹ç›®æ ‡\n",
    "\n",
    "åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæ‚¨å°†å­¦ä¹ ï¼š\n",
    "\n",
    "1. å·¥å…·é›†æˆçš„åŸºæœ¬æ¦‚å¿µå’Œæ–¹æ³•\n",
    "2. ToolNodeçš„ä½¿ç”¨å’Œé…ç½®\n",
    "3. Agentæ‰§è¡Œå™¨çš„æ„å»º\n",
    "4. å·¥å…·è°ƒç”¨çŠ¶æ€ç®¡ç†\n",
    "5. é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æ¢å¤\n",
    "6. æ„å»ºå®Œæ•´çš„æ™ºèƒ½Agentç³»ç»Ÿ\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚å¿µä»‹ç»\n",
    "\n",
    "åœ¨LangGraphä¸­ï¼Œå·¥å…·ï¼ˆToolsï¼‰æ˜¯Agentä¸å¤–éƒ¨ä¸–ç•Œäº¤äº’çš„æ¡¥æ¢ã€‚Agentå¯ä»¥è°ƒç”¨å„ç§å·¥å…·æ¥è·å–ä¿¡æ¯ã€æ‰§è¡Œæ“ä½œæˆ–å¤„ç†æ•°æ®ã€‚è¿™ä½¿å¾—AIç³»ç»Ÿèƒ½å¤Ÿè¶…è¶Šçº¯æ–‡æœ¬ç”Ÿæˆï¼Œæ‰§è¡ŒçœŸæ­£æœ‰ç”¨çš„ä»»åŠ¡ã€‚\n",
    "\n",
    "### å…³é”®æ¦‚å¿µï¼š\n",
    "- **å·¥å…·ï¼ˆToolï¼‰**ï¼šå¯ä»¥è¢«Agentè°ƒç”¨çš„å‡½æ•°æˆ–æœåŠ¡\n",
    "- **ToolNode**ï¼šä¸“é—¨å¤„ç†å·¥å…·è°ƒç”¨çš„èŠ‚ç‚¹ç±»å‹\n",
    "- **Agentæ‰§è¡Œå™¨**ï¼šç®¡ç†Agentå†³ç­–å’Œå·¥å…·è°ƒç”¨çš„æ ¸å¿ƒç»„ä»¶\n",
    "- **å·¥å…·è°ƒç”¨çŠ¶æ€**ï¼šè¿½è¸ªå·¥å…·è°ƒç”¨è¿‡ç¨‹å’Œç»“æœçš„çŠ¶æ€ä¿¡æ¯\n",
    "- **å‡½æ•°è°ƒç”¨ï¼ˆFunction Callingï¼‰**ï¼šLLMå†³å®šè°ƒç”¨å“ªä¸ªå·¥å…·åŠä¼ å…¥ä»€ä¹ˆå‚æ•°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒå‡†å¤‡å’Œå¯¼å…¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„åº“\n",
    "# !pip install langgraph langchain-core langchain-openai langchain-community\n",
    "\n",
    "import os\n",
    "from typing import Annotated, Literal, TypedDict, List, Dict, Any\n",
    "from langgraph import StateGraph, START, END\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"ç¯å¢ƒå‡†å¤‡å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åŸºç¡€å·¥å…·å®šä¹‰å’Œä½¿ç”¨\n",
    "\n",
    "é¦–å…ˆå­¦ä¹ å¦‚ä½•å®šä¹‰å’Œä½¿ç”¨åŸºæœ¬çš„å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨è£…é¥°å™¨å®šä¹‰å·¥å…·\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"è®¡ç®—æ•°å­¦è¡¨è¾¾å¼çš„ç»“æœã€‚\n",
    "    \n",
    "    Args:\n",
    "        expression: è¦è®¡ç®—çš„æ•°å­¦è¡¨è¾¾å¼ï¼Œä¾‹å¦‚ \"2 + 3 * 4\"\n",
    "        \n",
    "    Returns:\n",
    "        è®¡ç®—ç»“æœçš„å­—ç¬¦ä¸²è¡¨ç¤º\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # å®‰å…¨çš„æ•°å­¦è¡¨è¾¾å¼è®¡ç®—\n",
    "        allowed_chars = '0123456789+-*/().'\n",
    "        if all(c in allowed_chars or c.isspace() for c in expression):\n",
    "            result = eval(expression)\n",
    "            return f\"è®¡ç®—ç»“æœ: {result}\"\n",
    "        else:\n",
    "            return \"é”™è¯¯: è¡¨è¾¾å¼åŒ…å«ä¸å…è®¸çš„å­—ç¬¦\"\n",
    "    except Exception as e:\n",
    "        return f\"è®¡ç®—é”™è¯¯: {str(e)}\"\n",
    "\n",
    "@tool  \n",
    "def get_current_time() -> str:\n",
    "    \"\"\"è·å–å½“å‰çš„æ—¥æœŸå’Œæ—¶é—´ã€‚\n",
    "    \n",
    "    Returns:\n",
    "        å½“å‰æ—¥æœŸå’Œæ—¶é—´çš„å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    current_time = datetime.now()\n",
    "    return f\"å½“å‰æ—¶é—´: {current_time.strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "@tool\n",
    "def search_weather(city: str) -> str:\n",
    "    \"\"\"æŸ¥è¯¢æŒ‡å®šåŸå¸‚çš„å¤©æ°”ä¿¡æ¯ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        city: è¦æŸ¥è¯¢çš„åŸå¸‚åç§°\n",
    "        \n",
    "    Returns:\n",
    "        å¤©æ°”ä¿¡æ¯å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®\n",
    "    weather_options = [\n",
    "        \"æ™´å¤©ï¼Œæ°”æ¸©25Â°C\",\n",
    "        \"å¤šäº‘ï¼Œæ°”æ¸©22Â°C\", \n",
    "        \"å°é›¨ï¼Œæ°”æ¸©18Â°C\",\n",
    "        \"é˜´å¤©ï¼Œæ°”æ¸©20Â°C\"\n",
    "    ]\n",
    "    weather = random.choice(weather_options)\n",
    "    return f\"{city}çš„å¤©æ°”: {weather}\"\n",
    "\n",
    "@tool\n",
    "def generate_random_number(min_val: int = 1, max_val: int = 100) -> str:\n",
    "    \"\"\"ç”ŸæˆæŒ‡å®šèŒƒå›´å†…çš„éšæœºæ•°ã€‚\n",
    "    \n",
    "    Args:\n",
    "        min_val: æœ€å°å€¼ï¼ˆé»˜è®¤1ï¼‰\n",
    "        max_val: æœ€å¤§å€¼ï¼ˆé»˜è®¤100ï¼‰\n",
    "        \n",
    "    Returns:\n",
    "        éšæœºæ•°å­—ç¬¦ä¸²\n",
    "    \"\"\"\n",
    "    number = random.randint(min_val, max_val)\n",
    "    return f\"éšæœºæ•°: {number} (èŒƒå›´: {min_val}-{max_val})\"\n",
    "\n",
    "# åˆ›å»ºå·¥å…·åˆ—è¡¨\n",
    "basic_tools = [calculator, get_current_time, search_weather, generate_random_number]\n",
    "\n",
    "# æµ‹è¯•å·¥å…·\n",
    "print(\"åŸºç¡€å·¥å…·æµ‹è¯•ï¼š\")\n",
    "print(calculator.invoke({\"expression\": \"2 + 3 * 4\"}))\n",
    "print(get_current_time.invoke({}))\n",
    "print(search_weather.invoke({\"city\": \"åŒ—äº¬\"}))\n",
    "print(generate_random_number.invoke({\"min_val\": 10, \"max_val\": 50}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ToolNodeçš„ä½¿ç”¨\n",
    "\n",
    "ToolNodeæ˜¯LangGraphæä¾›çš„ä¸“é—¨å¤„ç†å·¥å…·è°ƒç”¨çš„èŠ‚ç‚¹ç±»å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰å¸¦æœ‰å·¥å…·è°ƒç”¨çš„çŠ¶æ€\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list, \"æ¶ˆæ¯åˆ—è¡¨\"]\n",
    "    \n",
    "# æ¨¡æ‹ŸLLMèŠ‚ç‚¹ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šä½¿ç”¨çœŸå®çš„LLMï¼‰\n",
    "def mock_llm_node(state: AgentState) -> AgentState:\n",
    "    \"\"\"æ¨¡æ‹ŸLLMå†³ç­–å·¥å…·è°ƒç”¨çš„èŠ‚ç‚¹\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        content = last_message.content.lower()\n",
    "        \n",
    "        # æ ¹æ®ç”¨æˆ·è¾“å…¥å†³å®šè°ƒç”¨å“ªä¸ªå·¥å…·\n",
    "        if \"è®¡ç®—\" in content or \"ç®—\" in content:\n",
    "            # æå–æ•°å­¦è¡¨è¾¾å¼ï¼ˆç®€å•ç¤ºä¾‹ï¼‰\n",
    "            expression = \"2 + 3\"  # å®é™…åº”ç”¨ä¸­éœ€è¦æ›´æ™ºèƒ½çš„æå–\n",
    "            if \"*\" in content or \"ä¹˜\" in content:\n",
    "                expression = \"5 * 6\"\n",
    "            elif \"/\" in content or \"é™¤\" in content:\n",
    "                expression = \"20 / 4\"\n",
    "            \n",
    "            ai_message = AIMessage(\n",
    "                content=\"æˆ‘æ¥å¸®ä½ è®¡ç®—\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"calculator\",\n",
    "                        \"args\": {\"expression\": expression},\n",
    "                        \"id\": \"calc_\" + str(random.randint(1000, 9999))\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        elif \"æ—¶é—´\" in content or \"å‡ ç‚¹\" in content:\n",
    "            ai_message = AIMessage(\n",
    "                content=\"æˆ‘æ¥æŸ¥è¯¢å½“å‰æ—¶é—´\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"get_current_time\",\n",
    "                        \"args\": {},\n",
    "                        \"id\": \"time_\" + str(random.randint(1000, 9999))\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        elif \"å¤©æ°”\" in content:\n",
    "            # ç®€å•æå–åŸå¸‚åï¼ˆå®é™…åº”ç”¨éœ€è¦æ›´å¤æ‚çš„NERï¼‰\n",
    "            city = \"åŒ—äº¬\"  # é»˜è®¤åŸå¸‚\n",
    "            if \"ä¸Šæµ·\" in content:\n",
    "                city = \"ä¸Šæµ·\"\n",
    "            elif \"æ·±åœ³\" in content:\n",
    "                city = \"æ·±åœ³\"\n",
    "                \n",
    "            ai_message = AIMessage(\n",
    "                content=f\"æˆ‘æ¥æŸ¥è¯¢{city}çš„å¤©æ°”\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"search_weather\",\n",
    "                        \"args\": {\"city\": city},\n",
    "                        \"id\": \"weather_\" + str(random.randint(1000, 9999))\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        elif \"éšæœº\" in content:\n",
    "            ai_message = AIMessage(\n",
    "                content=\"æˆ‘æ¥ç”Ÿæˆä¸€ä¸ªéšæœºæ•°\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"generate_random_number\",\n",
    "                        \"args\": {\"min_val\": 1, \"max_val\": 100},\n",
    "                        \"id\": \"random_\" + str(random.randint(1000, 9999))\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            ai_message = AIMessage(content=\"æˆ‘æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„å·¥å…·æ¥å¤„ç†æ‚¨çš„è¯·æ±‚ã€‚è¯·å°è¯•è¯¢é—®æ—¶é—´ã€å¤©æ°”ã€è®¡ç®—æˆ–éšæœºæ•°ã€‚\")\n",
    "    else:\n",
    "        # å¤„ç†å·¥å…·è°ƒç”¨ç»“æœ\n",
    "        tool_messages = [msg for msg in messages if isinstance(msg, ToolMessage)]\n",
    "        if tool_messages:\n",
    "            latest_tool_result = tool_messages[-1].content\n",
    "            ai_message = AIMessage(content=f\"æ ¹æ®å·¥å…·è°ƒç”¨ç»“æœï¼š{latest_tool_result}\")\n",
    "        else:\n",
    "            ai_message = AIMessage(content=\"è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ã€‚\")\n",
    "    \n",
    "    return {\"messages\": messages + [ai_message]}\n",
    "\n",
    "# åˆ›å»ºToolNode\n",
    "tool_node = ToolNode(basic_tools)\n",
    "\n",
    "# å†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·\n",
    "def should_continue(state: AgentState) -> Literal[\"tools\", \"end\"]:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    # æ£€æŸ¥æœ€åä¸€æ¡æ¶ˆæ¯æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return \"end\"\n",
    "\n",
    "# æ„å»ºå¸¦æœ‰å·¥å…·è°ƒç”¨çš„å›¾\n",
    "tool_workflow = StateGraph(AgentState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "tool_workflow.add_node(\"llm\", mock_llm_node)\n",
    "tool_workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# è®¾ç½®å…¥å£ç‚¹\n",
    "tool_workflow.set_entry_point(\"llm\")\n",
    "\n",
    "# æ·»åŠ æ¡ä»¶è¾¹\n",
    "tool_workflow.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# å·¥å…·æ‰§è¡Œåå›åˆ°LLM\n",
    "tool_workflow.add_edge(\"tools\", \"llm\")\n",
    "\n",
    "# ç¼–è¯‘å›¾\n",
    "tool_app = tool_workflow.compile()\n",
    "\n",
    "# æµ‹è¯•å·¥å…·è°ƒç”¨\n",
    "test_queries = [\n",
    "    \"è¯·å¸®æˆ‘è®¡ç®—5ä¹˜ä»¥8\",\n",
    "    \"ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ\",\n",
    "    \"åŒ—äº¬ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\",\n",
    "    \"ç»™æˆ‘ä¸€ä¸ªéšæœºæ•°\",\n",
    "    \"ä½ å¥½\"  # ä¸éœ€è¦å·¥å…·è°ƒç”¨çš„æŸ¥è¯¢\n",
    "]\n",
    "\n",
    "print(\"\\nå·¥å…·è°ƒç”¨æµ‹è¯•ï¼š\")\n",
    "for query in test_queries:\n",
    "    print(f\"\\nç”¨æˆ·: {query}\")\n",
    "    result = tool_app.invoke({\"messages\": [HumanMessage(content=query)]})\n",
    "    \n",
    "    # æ˜¾ç¤ºå¯¹è¯å†å²\n",
    "    for msg in result[\"messages\"]:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            print(f\"AI: {msg.content}\")\n",
    "            if msg.tool_calls:\n",
    "                print(f\"  å·¥å…·è°ƒç”¨: {msg.tool_calls}\")\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            print(f\"  å·¥å…·ç»“æœ: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. å¤æ‚å·¥å…·ç³»ç»Ÿ\n",
    "\n",
    "æ„å»ºæ›´å¤æ‚çš„å·¥å…·ç³»ç»Ÿï¼ŒåŒ…å«å¤šç§ç±»å‹çš„å·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–‡ä»¶æ“ä½œå·¥å…·\n",
    "@tool\n",
    "def read_file(file_path: str) -> str:\n",
    "    \"\"\"è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        file_path: æ–‡ä»¶è·¯å¾„\n",
    "        \n",
    "    Returns:\n",
    "        æ–‡ä»¶å†…å®¹æˆ–é”™è¯¯ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    # æ¨¡æ‹Ÿæ–‡ä»¶å†…å®¹\n",
    "    mock_files = {\n",
    "        \"data.txt\": \"è¿™æ˜¯æ•°æ®æ–‡ä»¶çš„å†…å®¹\\nåŒ…å«ä¸€äº›é‡è¦ä¿¡æ¯\",\n",
    "        \"config.json\": '{\"api_key\": \"xxx\", \"timeout\": 30}',\n",
    "        \"log.txt\": \"2023-01-01 10:00:00 - ç³»ç»Ÿå¯åŠ¨\\n2023-01-01 10:01:00 - åŠ è½½é…ç½®\"\n",
    "    }\n",
    "    \n",
    "    if file_path in mock_files:\n",
    "        return f\"æ–‡ä»¶ {file_path} çš„å†…å®¹:\\n{mock_files[file_path]}\"\n",
    "    else:\n",
    "        return f\"é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}\"\n",
    "\n",
    "@tool\n",
    "def write_file(file_path: str, content: str) -> str:\n",
    "    \"\"\"å†™å…¥æ–‡ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        file_path: æ–‡ä»¶è·¯å¾„\n",
    "        content: è¦å†™å…¥çš„å†…å®¹\n",
    "        \n",
    "    Returns:\n",
    "        æ“ä½œç»“æœ\n",
    "    \"\"\"\n",
    "    # æ¨¡æ‹Ÿå†™å…¥æ“ä½œ\n",
    "    return f\"æˆåŠŸå°†å†…å®¹å†™å…¥æ–‡ä»¶ {file_path}\\nå†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦\"\n",
    "\n",
    "# æ•°æ®å¤„ç†å·¥å…·\n",
    "@tool\n",
    "def analyze_data(data: str) -> str:\n",
    "    \"\"\"åˆ†ææ•°æ®å¹¶æä¾›ç»Ÿè®¡ä¿¡æ¯ã€‚\n",
    "    \n",
    "    Args:\n",
    "        data: è¦åˆ†æçš„æ•°æ®ï¼ˆç”¨é€—å·åˆ†éš”çš„æ•°å­—ï¼‰\n",
    "        \n",
    "    Returns:\n",
    "        æ•°æ®åˆ†æç»“æœ\n",
    "    \"\"\"\n",
    "    try:\n",
    "        numbers = [float(x.strip()) for x in data.split(',')]\n",
    "        if not numbers:\n",
    "            return \"é”™è¯¯: æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•°å­—\"\n",
    "            \n",
    "        count = len(numbers)\n",
    "        total = sum(numbers)\n",
    "        average = total / count\n",
    "        minimum = min(numbers)\n",
    "        maximum = max(numbers)\n",
    "        \n",
    "        return f\"\"\"æ•°æ®åˆ†æç»“æœ:\n",
    "æ•°é‡: {count}\n",
    "æ€»å’Œ: {total}\n",
    "å¹³å‡å€¼: {average:.2f}\n",
    "æœ€å°å€¼: {minimum}\n",
    "æœ€å¤§å€¼: {maximum}\"\"\"\n",
    "    except Exception as e:\n",
    "        return f\"æ•°æ®åˆ†æé”™è¯¯: {str(e)}\"\n",
    "\n",
    "# ç½‘ç»œè¯·æ±‚å·¥å…·\n",
    "@tool\n",
    "def fetch_url(url: str) -> str:\n",
    "    \"\"\"è·å–URLå†…å®¹ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        url: è¦è·å–çš„URL\n",
    "        \n",
    "    Returns:\n",
    "        URLå†…å®¹æˆ–é”™è¯¯ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    # æ¨¡æ‹Ÿç½‘ç»œè¯·æ±‚\n",
    "    mock_responses = {\n",
    "        \"https://api.example.com/status\": '{\"status\": \"online\", \"version\": \"1.0\"}',\n",
    "        \"https://api.example.com/data\": '{\"data\": [1, 2, 3, 4, 5]}',\n",
    "        \"https://news.example.com\": \"ä»Šæ—¥å¤´æ¡æ–°é—»å†…å®¹\"\n",
    "    }\n",
    "    \n",
    "    if url in mock_responses:\n",
    "        return f\"æˆåŠŸè·å– {url}:\\n{mock_responses[url]}\"\n",
    "    else:\n",
    "        return f\"æ¨¡æ‹Ÿè¯·æ±‚ {url}\\nè¿”å›: 404 - é¡µé¢æœªæ‰¾åˆ°\"\n",
    "\n",
    "# é‚®ä»¶å‘é€å·¥å…·\n",
    "@tool\n",
    "def send_email(to: str, subject: str, body: str) -> str:\n",
    "    \"\"\"å‘é€é‚®ä»¶ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        to: æ”¶ä»¶äººé‚®ç®±\n",
    "        subject: é‚®ä»¶ä¸»é¢˜\n",
    "        body: é‚®ä»¶å†…å®¹\n",
    "        \n",
    "    Returns:\n",
    "        å‘é€ç»“æœ\n",
    "    \"\"\"\n",
    "    return f\"\"\"é‚®ä»¶å‘é€æˆåŠŸ!\n",
    "æ”¶ä»¶äºº: {to}\n",
    "ä¸»é¢˜: {subject}\n",
    "å†…å®¹é•¿åº¦: {len(body)} å­—ç¬¦\n",
    "å‘é€æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\"\"\n",
    "\n",
    "# æ•°æ®åº“æŸ¥è¯¢å·¥å…·\n",
    "@tool\n",
    "def query_database(table: str, condition: str = \"\") -> str:\n",
    "    \"\"\"æŸ¥è¯¢æ•°æ®åº“ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        table: è¡¨å\n",
    "        condition: æŸ¥è¯¢æ¡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
    "        \n",
    "    Returns:\n",
    "        æŸ¥è¯¢ç»“æœ\n",
    "    \"\"\"\n",
    "    # æ¨¡æ‹Ÿæ•°æ®åº“æ•°æ®\n",
    "    mock_data = {\n",
    "        \"users\": [\n",
    "            {\"id\": 1, \"name\": \"å¼ ä¸‰\", \"age\": 25},\n",
    "            {\"id\": 2, \"name\": \"æå››\", \"age\": 30},\n",
    "            {\"id\": 3, \"name\": \"ç‹äº”\", \"age\": 35}\n",
    "        ],\n",
    "        \"orders\": [\n",
    "            {\"id\": 101, \"user_id\": 1, \"amount\": 100.0},\n",
    "            {\"id\": 102, \"user_id\": 2, \"amount\": 200.0}\n",
    "        ],\n",
    "        \"products\": [\n",
    "            {\"id\": 1, \"name\": \"ç¬”è®°æœ¬ç”µè„‘\", \"price\": 5000},\n",
    "            {\"id\": 2, \"name\": \"æ‰‹æœº\", \"price\": 3000}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    if table in mock_data:\n",
    "        data = mock_data[table]\n",
    "        result_count = len(data)\n",
    "        \n",
    "        return f\"\"\"æŸ¥è¯¢è¡¨ '{table}' æˆåŠŸ:\n",
    "æ¡ä»¶: {condition if condition else 'æ— '}\n",
    "ç»“æœæ•°é‡: {result_count}\n",
    "æ•°æ®: {json.dumps(data, ensure_ascii=False, indent=2)}\"\"\"\n",
    "    else:\n",
    "        return f\"é”™è¯¯: æ‰¾ä¸åˆ°è¡¨ '{table}'\"\n",
    "\n",
    "# åˆ›å»ºå¤æ‚å·¥å…·åˆ—è¡¨\n",
    "advanced_tools = [\n",
    "    calculator, get_current_time, search_weather, generate_random_number,\n",
    "    read_file, write_file, analyze_data, fetch_url, send_email, query_database\n",
    "]\n",
    "\n",
    "print(\"å¤æ‚å·¥å…·ç³»ç»Ÿæµ‹è¯•ï¼š\")\n",
    "print(\"\\n1. æ–‡ä»¶æ“ä½œ:\")\n",
    "print(read_file.invoke({\"file_path\": \"data.txt\"}))\n",
    "\n",
    "print(\"\\n2. æ•°æ®åˆ†æ:\")\n",
    "print(analyze_data.invoke({\"data\": \"10, 20, 30, 40, 50\"}))\n",
    "\n",
    "print(\"\\n3. ç½‘ç»œè¯·æ±‚:\")\n",
    "print(fetch_url.invoke({\"url\": \"https://api.example.com/status\"}))\n",
    "\n",
    "print(\"\\n4. æ•°æ®åº“æŸ¥è¯¢:\")\n",
    "print(query_database.invoke({\"table\": \"users\", \"condition\": \"age > 25\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agentæ‰§è¡Œå™¨æ„å»º\n",
    "\n",
    "æ„å»ºä¸€ä¸ªå®Œæ•´çš„Agentæ‰§è¡Œå™¨ï¼Œèƒ½å¤Ÿæ™ºèƒ½åœ°é€‰æ‹©å’Œæ‰§è¡Œå·¥å…·"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¢å¼ºçš„AgentçŠ¶æ€\n",
    "class EnhancedAgentState(TypedDict):\n",
    "    messages: Annotated[list, \"æ¶ˆæ¯å†å²\"]\n",
    "    current_task: str\n",
    "    tool_results: Dict[str, Any]\n",
    "    execution_step: int\n",
    "    max_steps: int\n",
    "    error_count: int\n",
    "    context: Dict[str, Any]\n",
    "\n",
    "# æ™ºèƒ½LLMèŠ‚ç‚¹ï¼ˆæ›´å¤æ‚çš„å†³ç­–é€»è¾‘ï¼‰\n",
    "def intelligent_llm_node(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"æ™ºèƒ½LLMèŠ‚ç‚¹ï¼Œèƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡åšå‡ºæ›´å¥½çš„å†³ç­–\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    execution_step = state.get(\"execution_step\", 0)\n",
    "    max_steps = state.get(\"max_steps\", 10)\n",
    "    tool_results = state.get(\"tool_results\", {})\n",
    "    context = state.get(\"context\", {})\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§æ­¥æ•°\n",
    "    if execution_step >= max_steps:\n",
    "        ai_message = AIMessage(content=f\"å·²è¾¾åˆ°æœ€å¤§æ‰§è¡Œæ­¥æ•°({max_steps})ï¼Œåœæ­¢æ‰§è¡Œã€‚\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"messages\": messages + [ai_message]\n",
    "        }\n",
    "    \n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        content = last_message.content.lower()\n",
    "        task_type = analyze_task_type(content)\n",
    "        \n",
    "        # æ ¹æ®ä»»åŠ¡ç±»å‹åˆ¶å®šæ‰§è¡Œè®¡åˆ’\n",
    "        ai_message, new_context = plan_execution(content, task_type, context)\n",
    "        \n",
    "    elif isinstance(last_message, ToolMessage):\n",
    "        # å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ\n",
    "        ai_message = process_tool_result(last_message, messages, tool_results, context)\n",
    "        new_context = context\n",
    "    else:\n",
    "        ai_message = AIMessage(content=\"è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ã€‚\")\n",
    "        new_context = context\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": messages + [ai_message],\n",
    "        \"execution_step\": execution_step + 1,\n",
    "        \"context\": new_context\n",
    "    }\n",
    "\n",
    "def analyze_task_type(content: str) -> str:\n",
    "    \"\"\"åˆ†æä»»åŠ¡ç±»å‹\"\"\"\n",
    "    if any(word in content for word in [\"è®¡ç®—\", \"ç®—\", \"æ•°å­¦\"]):\n",
    "        return \"calculation\"\n",
    "    elif any(word in content for word in [\"æ–‡ä»¶\", \"è¯»å–\", \"å†™å…¥\", \"ä¿å­˜\"]):\n",
    "        return \"file_operation\"\n",
    "    elif any(word in content for word in [\"æ•°æ®\", \"åˆ†æ\", \"ç»Ÿè®¡\"]):\n",
    "        return \"data_analysis\"\n",
    "    elif any(word in content for word in [\"é‚®ä»¶\", \"å‘é€\", \"é€šçŸ¥\"]):\n",
    "        return \"communication\"\n",
    "    elif any(word in content for word in [\"æŸ¥è¯¢\", \"æœç´¢\", \"æ•°æ®åº“\"]):\n",
    "        return \"query\"\n",
    "    elif any(word in content for word in [\"å¤©æ°”\", \"æ—¶é—´\", \"ä¿¡æ¯\"]):\n",
    "        return \"information\"\n",
    "    else:\n",
    "        return \"general\"\n",
    "\n",
    "def plan_execution(content: str, task_type: str, context: Dict) -> tuple:\n",
    "    \"\"\"åˆ¶å®šæ‰§è¡Œè®¡åˆ’\"\"\"\n",
    "    \n",
    "    if task_type == \"calculation\":\n",
    "        # æå–è¡¨è¾¾å¼\n",
    "        expression = extract_math_expression(content)\n",
    "        ai_message = AIMessage(\n",
    "            content=f\"æˆ‘æ¥è®¡ç®—è¡¨è¾¾å¼: {expression}\",\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"calculator\",\n",
    "                    \"args\": {\"expression\": expression},\n",
    "                    \"id\": f\"calc_{random.randint(1000, 9999)}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        new_context = {**context, \"task_type\": \"calculation\", \"expression\": expression}\n",
    "        \n",
    "    elif task_type == \"file_operation\":\n",
    "        if \"è¯»å–\" in content or \"read\" in content:\n",
    "            file_path = extract_file_path(content)\n",
    "            ai_message = AIMessage(\n",
    "                content=f\"æˆ‘æ¥è¯»å–æ–‡ä»¶: {file_path}\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"read_file\",\n",
    "                        \"args\": {\"file_path\": file_path},\n",
    "                        \"id\": f\"read_{random.randint(1000, 9999)}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        else:\n",
    "            # å†™å…¥æ–‡ä»¶çš„ä¾‹å­\n",
    "            ai_message = AIMessage(\n",
    "                content=\"æˆ‘æ¥åˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"write_file\",\n",
    "                        \"args\": {\n",
    "                            \"file_path\": \"example.txt\",\n",
    "                            \"content\": \"è¿™æ˜¯ä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶å†…å®¹\"\n",
    "                        },\n",
    "                        \"id\": f\"write_{random.randint(1000, 9999)}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        new_context = {**context, \"task_type\": \"file_operation\"}\n",
    "        \n",
    "    elif task_type == \"data_analysis\":\n",
    "        # æå–æ•°æ®æˆ–ä½¿ç”¨ç¤ºä¾‹æ•°æ®\n",
    "        data = extract_data(content) or \"1,2,3,4,5,6,7,8,9,10\"\n",
    "        ai_message = AIMessage(\n",
    "            content=f\"æˆ‘æ¥åˆ†ææ•°æ®: {data}\",\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"analyze_data\",\n",
    "                    \"args\": {\"data\": data},\n",
    "                    \"id\": f\"analyze_{random.randint(1000, 9999)}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        new_context = {**context, \"task_type\": \"data_analysis\", \"data\": data}\n",
    "        \n",
    "    elif task_type == \"query\":\n",
    "        table = extract_table_name(content)\n",
    "        ai_message = AIMessage(\n",
    "            content=f\"æˆ‘æ¥æŸ¥è¯¢æ•°æ®åº“è¡¨: {table}\",\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"query_database\",\n",
    "                    \"args\": {\"table\": table},\n",
    "                    \"id\": f\"query_{random.randint(1000, 9999)}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        new_context = {**context, \"task_type\": \"query\", \"table\": table}\n",
    "        \n",
    "    elif task_type == \"information\":\n",
    "        if \"æ—¶é—´\" in content:\n",
    "            ai_message = AIMessage(\n",
    "                content=\"æˆ‘æ¥è·å–å½“å‰æ—¶é—´\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"get_current_time\",\n",
    "                        \"args\": {},\n",
    "                        \"id\": f\"time_{random.randint(1000, 9999)}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        else:  # å¤©æ°”æŸ¥è¯¢\n",
    "            city = extract_city(content)\n",
    "            ai_message = AIMessage(\n",
    "                content=f\"æˆ‘æ¥æŸ¥è¯¢{city}çš„å¤©æ°”\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"search_weather\",\n",
    "                        \"args\": {\"city\": city},\n",
    "                        \"id\": f\"weather_{random.randint(1000, 9999)}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        new_context = {**context, \"task_type\": \"information\"}\n",
    "        \n",
    "    else:\n",
    "        ai_message = AIMessage(content=\"è¯·æ›´å…·ä½“åœ°æè¿°æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ã€‚æˆ‘å¯ä»¥å¸®æ‚¨ï¼šè®¡ç®—ã€æ–‡ä»¶æ“ä½œã€æ•°æ®åˆ†æã€æŸ¥è¯¢æ•°æ®åº“ã€è·å–ä¿¡æ¯ç­‰ã€‚\")\n",
    "        new_context = context\n",
    "        \n",
    "    return ai_message, new_context\n",
    "\n",
    "# è¾…åŠ©å‡½æ•°\n",
    "def extract_math_expression(content: str) -> str:\n",
    "    \"\"\"ä»æ–‡æœ¬ä¸­æå–æ•°å­¦è¡¨è¾¾å¼ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰\"\"\"\n",
    "    # ç®€å•çš„è¡¨è¾¾å¼æå–é€»è¾‘\n",
    "    import re\n",
    "    # å¯»æ‰¾æ•°å­¦è¡¨è¾¾å¼æ¨¡å¼\n",
    "    patterns = [\n",
    "        r'(\\d+(?:\\.\\d+)?\\s*[+\\-*/]\\s*\\d+(?:\\.\\d+)?(?:\\s*[+\\-*/]\\s*\\d+(?:\\.\\d+)?)*)',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[+åŠ ]\\s*(\\d+(?:\\.\\d+)?)',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[\\-å‡]\\s*(\\d+(?:\\.\\d+)?)',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[*Ã—ä¹˜]\\s*(\\d+(?:\\.\\d+)?)',\n",
    "        r'(\\d+(?:\\.\\d+)?)\\s*[/Ã·é™¤]\\s*(\\d+(?:\\.\\d+)?)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, content)\n",
    "        if match:\n",
    "            if len(match.groups()) == 1:\n",
    "                return match.group(1)\n",
    "            else:\n",
    "                # å¤„ç†ä¸­æ–‡è¿ç®—ç¬¦\n",
    "                if 'åŠ ' in content:\n",
    "                    return f\"{match.group(1)} + {match.group(2)}\"\n",
    "                elif 'å‡' in content:\n",
    "                    return f\"{match.group(1)} - {match.group(2)}\"\n",
    "                elif any(x in content for x in ['ä¹˜', 'Ã—']):\n",
    "                    return f\"{match.group(1)} * {match.group(2)}\"\n",
    "                elif any(x in content for x in ['é™¤', 'Ã·']):\n",
    "                    return f\"{match.group(1)} / {match.group(2)}\"\n",
    "    \n",
    "    return \"2 + 2\"  # é»˜è®¤è¡¨è¾¾å¼\n",
    "\n",
    "def extract_file_path(content: str) -> str:\n",
    "    \"\"\"æå–æ–‡ä»¶è·¯å¾„\"\"\"\n",
    "    if \"data.txt\" in content:\n",
    "        return \"data.txt\"\n",
    "    elif \"config\" in content:\n",
    "        return \"config.json\"\n",
    "    elif \"log\" in content:\n",
    "        return \"log.txt\"\n",
    "    return \"data.txt\"\n",
    "\n",
    "def extract_data(content: str) -> str:\n",
    "    \"\"\"æå–æ•°æ®\"\"\"\n",
    "    import re\n",
    "    # å¯»æ‰¾é€—å·åˆ†éš”çš„æ•°å­—\n",
    "    match = re.search(r'([0-9, ]+)', content)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "def extract_table_name(content: str) -> str:\n",
    "    \"\"\"æå–è¡¨å\"\"\"\n",
    "    if \"ç”¨æˆ·\" in content or \"user\" in content:\n",
    "        return \"users\"\n",
    "    elif \"è®¢å•\" in content or \"order\" in content:\n",
    "        return \"orders\"\n",
    "    elif \"äº§å“\" in content or \"product\" in content:\n",
    "        return \"products\"\n",
    "    return \"users\"\n",
    "\n",
    "def extract_city(content: str) -> str:\n",
    "    \"\"\"æå–åŸå¸‚å\"\"\"\n",
    "    cities = [\"åŒ—äº¬\", \"ä¸Šæµ·\", \"æ·±åœ³\", \"å¹¿å·\", \"æ­å·\", \"æˆéƒ½\"]\n",
    "    for city in cities:\n",
    "        if city in content:\n",
    "            return city\n",
    "    return \"åŒ—äº¬\"\n",
    "\n",
    "def process_tool_result(tool_message: ToolMessage, messages: list, tool_results: Dict, context: Dict) -> AIMessage:\n",
    "    \"\"\"å¤„ç†å·¥å…·æ‰§è¡Œç»“æœ\"\"\"\n",
    "    result = tool_message.content\n",
    "    task_type = context.get(\"task_type\", \"general\")\n",
    "    \n",
    "    # æ ¹æ®ä»»åŠ¡ç±»å‹æä¾›ä¸åŒçš„å“åº”\n",
    "    if task_type == \"calculation\":\n",
    "        return AIMessage(content=f\"è®¡ç®—å®Œæˆï¼{result}\")\n",
    "    elif task_type == \"file_operation\":\n",
    "        return AIMessage(content=f\"æ–‡ä»¶æ“ä½œå®Œæˆï¼š{result}\")\n",
    "    elif task_type == \"data_analysis\":\n",
    "        return AIMessage(content=f\"æ•°æ®åˆ†æç»“æœï¼š\\n{result}\")\n",
    "    elif task_type == \"query\":\n",
    "        return AIMessage(content=f\"æ•°æ®åº“æŸ¥è¯¢ç»“æœï¼š\\n{result}\")\n",
    "    else:\n",
    "        return AIMessage(content=f\"æ“ä½œå®Œæˆï¼š{result}\")\n",
    "\n",
    "# é”™è¯¯å¤„ç†èŠ‚ç‚¹\n",
    "def error_handler(state: EnhancedAgentState) -> EnhancedAgentState:\n",
    "    \"\"\"å¤„ç†æ‰§è¡Œé”™è¯¯\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    error_count = state.get(\"error_count\", 0) + 1\n",
    "    \n",
    "    if error_count >= 3:\n",
    "        ai_message = AIMessage(content=\"æŠ±æ­‰ï¼Œè¿ç»­å‡ºç°å¤šæ¬¡é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚\")\n",
    "    else:\n",
    "        ai_message = AIMessage(content=f\"æ‰§è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œæ­£åœ¨é‡è¯•... (ç¬¬{error_count}æ¬¡)\")\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": messages + [ai_message],\n",
    "        \"error_count\": error_count\n",
    "    }\n",
    "\n",
    "# æ„å»ºå¢å¼ºçš„Agentæ‰§è¡Œå™¨\n",
    "def enhanced_should_continue(state: EnhancedAgentState) -> Literal[\"tools\", \"error\", \"end\"]:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    error_count = state.get(\"error_count\", 0)\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    # æ£€æŸ¥é”™è¯¯æ¬¡æ•°\n",
    "    if error_count >= 3:\n",
    "        return \"error\"\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return \"end\"\n",
    "\n",
    "# åˆ›å»ºå¢å¼ºçš„å·¥å…·èŠ‚ç‚¹\n",
    "enhanced_tool_node = ToolNode(advanced_tools)\n",
    "\n",
    "# æ„å»ºå¢å¼ºçš„Agentå›¾\n",
    "enhanced_agent_workflow = StateGraph(EnhancedAgentState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "enhanced_agent_workflow.add_node(\"llm\", intelligent_llm_node)\n",
    "enhanced_agent_workflow.add_node(\"tools\", enhanced_tool_node)\n",
    "enhanced_agent_workflow.add_node(\"error_handler\", error_handler)\n",
    "\n",
    "# è®¾ç½®å…¥å£\n",
    "enhanced_agent_workflow.set_entry_point(\"llm\")\n",
    "\n",
    "# æ·»åŠ æ¡ä»¶è¾¹\n",
    "enhanced_agent_workflow.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    enhanced_should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"error\": \"error_handler\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# å·¥å…·æ‰§è¡Œåå›åˆ°LLM\n",
    "enhanced_agent_workflow.add_edge(\"tools\", \"llm\")\n",
    "enhanced_agent_workflow.add_edge(\"error_handler\", END)\n",
    "\n",
    "# ç¼–è¯‘å¢å¼ºAgent\n",
    "enhanced_agent_app = enhanced_agent_workflow.compile()\n",
    "\n",
    "# æµ‹è¯•å¢å¼ºAgent\n",
    "complex_queries = [\n",
    "    \"è¯·è®¡ç®—15ä¹˜ä»¥23åŠ ä¸Š67\",\n",
    "    \"å¸®æˆ‘è¯»å–data.txtæ–‡ä»¶çš„å†…å®¹\",\n",
    "    \"åˆ†æè¿™äº›æ•°æ®ï¼š10, 15, 20, 25, 30, 35, 40\",\n",
    "    \"æŸ¥è¯¢ç”¨æˆ·è¡¨çš„ä¿¡æ¯\",\n",
    "    \"ç°åœ¨å‡ ç‚¹äº†ï¼Ÿ\",\n",
    "    \"ä¸Šæµ·ä»Šå¤©å¤©æ°”å¦‚ä½•ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "print(\"\\nå¢å¼ºAgentæ‰§è¡Œå™¨æµ‹è¯•ï¼š\")\n",
    "for query in complex_queries:\n",
    "    print(f\"\\n========== æŸ¥è¯¢: {query} ==========\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"current_task\": query,\n",
    "        \"tool_results\": {},\n",
    "        \"execution_step\": 0,\n",
    "        \"max_steps\": 5,\n",
    "        \"error_count\": 0,\n",
    "        \"context\": {}\n",
    "    }\n",
    "    \n",
    "    result = enhanced_agent_app.invoke(initial_state)\n",
    "    \n",
    "    # æ˜¾ç¤ºæ‰§è¡Œè¿‡ç¨‹\n",
    "    for i, msg in enumerate(result[\"messages\"]):\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            print(f\"ğŸ‘¤ ç”¨æˆ·: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(f\"ğŸ¤– AI: {msg.content}\")\n",
    "            if msg.tool_calls:\n",
    "                for tool_call in msg.tool_calls:\n",
    "                    print(f\"   ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}({tool_call['args']})\")\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            print(f\"   âš™ï¸ å·¥å…·ç»“æœ: {msg.content[:100]}...\" if len(msg.content) > 100 else f\"   âš™ï¸ å·¥å…·ç»“æœ: {msg.content}\")\n",
    "    \n",
    "    print(f\"æ‰§è¡Œæ­¥æ•°: {result['execution_step']}, é”™è¯¯æ¬¡æ•°: {result['error_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. é”™è¯¯å¤„ç†å’Œå¼‚å¸¸æ¢å¤\n",
    "\n",
    "å®ç°å¥å£®çš„é”™è¯¯å¤„ç†æœºåˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¸¦æœ‰é”™è¯¯å¤„ç†çš„å·¥å…·\n",
    "@tool\n",
    "def unreliable_service(task: str, fail_rate: float = 0.3) -> str:\n",
    "    \"\"\"æ¨¡æ‹Ÿä¸å¯é çš„æœåŠ¡è°ƒç”¨ã€‚\n",
    "    \n",
    "    Args:\n",
    "        task: è¦æ‰§è¡Œçš„ä»»åŠ¡æè¿°\n",
    "        fail_rate: å¤±è´¥ç‡ï¼ˆ0.0-1.0ï¼‰\n",
    "        \n",
    "    Returns:\n",
    "        ä»»åŠ¡ç»“æœæˆ–é”™è¯¯ä¿¡æ¯\n",
    "    \"\"\"\n",
    "    if random.random() < fail_rate:\n",
    "        error_types = [\n",
    "            \"ç½‘ç»œè¶…æ—¶\",\n",
    "            \"æœåŠ¡ä¸å¯ç”¨\", \n",
    "            \"æƒé™ä¸è¶³\",\n",
    "            \"è¯·æ±‚æ ¼å¼é”™è¯¯\",\n",
    "            \"ç³»ç»Ÿç»´æŠ¤ä¸­\"\n",
    "        ]\n",
    "        error = random.choice(error_types)\n",
    "        raise Exception(f\"æœåŠ¡è°ƒç”¨å¤±è´¥: {error}\")\n",
    "    \n",
    "    return f\"ä»»åŠ¡ '{task}' æ‰§è¡ŒæˆåŠŸï¼ç»“æœï¼šæ¨¡æ‹Ÿæ•°æ®å¤„ç†å®Œæˆ\"\n",
    "\n",
    "@tool\n",
    "def validate_input(input_data: str, data_type: str = \"string\") -> str:\n",
    "    \"\"\"éªŒè¯è¾“å…¥æ•°æ®ã€‚\n",
    "    \n",
    "    Args:\n",
    "        input_data: è¦éªŒè¯çš„æ•°æ®\n",
    "        data_type: æœŸæœ›çš„æ•°æ®ç±»å‹ (string, number, email, url)\n",
    "        \n",
    "    Returns:\n",
    "        éªŒè¯ç»“æœ\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    if data_type == \"number\":\n",
    "        try:\n",
    "            float(input_data)\n",
    "            return f\"âœ… æ•°å­—éªŒè¯é€šè¿‡: {input_data}\"\n",
    "        except ValueError:\n",
    "            raise ValueError(f\"âŒ æ— æ•ˆçš„æ•°å­—æ ¼å¼: {input_data}\")\n",
    "            \n",
    "    elif data_type == \"email\":\n",
    "        pattern = r'^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$'\n",
    "        if re.match(pattern, input_data):\n",
    "            return f\"âœ… é‚®ç®±æ ¼å¼éªŒè¯é€šè¿‡: {input_data}\"\n",
    "        else:\n",
    "            raise ValueError(f\"âŒ æ— æ•ˆçš„é‚®ç®±æ ¼å¼: {input_data}\")\n",
    "            \n",
    "    elif data_type == \"url\":\n",
    "        pattern = r'^https?://[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}'\n",
    "        if re.match(pattern, input_data):\n",
    "            return f\"âœ… URLæ ¼å¼éªŒè¯é€šè¿‡: {input_data}\"\n",
    "        else:\n",
    "            raise ValueError(f\"âŒ æ— æ•ˆçš„URLæ ¼å¼: {input_data}\")\n",
    "    \n",
    "    return f\"âœ… å­—ç¬¦ä¸²éªŒè¯é€šè¿‡: {input_data}\"\n",
    "\n",
    "# é”™è¯¯æ¢å¤çŠ¶æ€\n",
    "class ErrorRecoveryState(TypedDict):\n",
    "    messages: Annotated[list, \"æ¶ˆæ¯å†å²\"]\n",
    "    current_task: str\n",
    "    retry_count: Dict[str, int]\n",
    "    max_retries: int\n",
    "    error_history: list\n",
    "    fallback_strategies: Dict[str, str]\n",
    "    execution_status: str  # running, error, recovered, failed\n",
    "\n",
    "# é”™è¯¯æ¢å¤LLMèŠ‚ç‚¹\n",
    "def error_recovery_llm(state: ErrorRecoveryState) -> ErrorRecoveryState:\n",
    "    \"\"\"å¸¦æœ‰é”™è¯¯æ¢å¤èƒ½åŠ›çš„LLMèŠ‚ç‚¹\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    retry_count = state.get(\"retry_count\", {})\n",
    "    max_retries = state.get(\"max_retries\", 3)\n",
    "    error_history = state.get(\"error_history\", [])\n",
    "    \n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        content = last_message.content.lower()\n",
    "        \n",
    "        if \"éªŒè¯\" in content:\n",
    "            # è¾“å…¥éªŒè¯ä»»åŠ¡\n",
    "            if \"é‚®ç®±\" in content:\n",
    "                test_email = \"invalid-email\"  # æ•…æ„ä½¿ç”¨æ— æ•ˆé‚®ç®±æ¥è§¦å‘é”™è¯¯\n",
    "                ai_message = AIMessage(\n",
    "                    content=f\"æˆ‘æ¥éªŒè¯é‚®ç®±æ ¼å¼: {test_email}\",\n",
    "                    tool_calls=[\n",
    "                        {\n",
    "                            \"name\": \"validate_input\",\n",
    "                            \"args\": {\"input_data\": test_email, \"data_type\": \"email\"},\n",
    "                            \"id\": f\"validate_{random.randint(1000, 9999)}\"\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                ai_message = AIMessage(\n",
    "                    content=\"æˆ‘æ¥éªŒè¯è¾“å…¥æ•°æ®\",\n",
    "                    tool_calls=[\n",
    "                        {\n",
    "                            \"name\": \"validate_input\",\n",
    "                            \"args\": {\"input_data\": \"test123\", \"data_type\": \"number\"},\n",
    "                            \"id\": f\"validate_{random.randint(1000, 9999)}\"\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "        \n",
    "        elif \"æœåŠ¡\" in content or \"è°ƒç”¨\" in content:\n",
    "            # ä¸å¯é æœåŠ¡è°ƒç”¨\n",
    "            ai_message = AIMessage(\n",
    "                content=\"æˆ‘æ¥è°ƒç”¨æœåŠ¡\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"unreliable_service\",\n",
    "                        \"args\": {\"task\": \"æ•°æ®å¤„ç†\", \"fail_rate\": 0.6},\n",
    "                        \"id\": f\"service_{random.randint(1000, 9999)}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            ai_message = AIMessage(content=\"è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦éªŒè¯ä»€ä¹ˆæ•°æ®æˆ–è°ƒç”¨ä»€ä¹ˆæœåŠ¡ã€‚\")\n",
    "    \n",
    "    elif isinstance(last_message, ToolMessage):\n",
    "        # æ£€æŸ¥å·¥å…·è°ƒç”¨æ˜¯å¦æˆåŠŸ\n",
    "        if \"é”™è¯¯\" in last_message.content or \"å¤±è´¥\" in last_message.content:\n",
    "            # å¤„ç†é”™è¯¯\n",
    "            tool_name = last_message.name or \"unknown_tool\"\n",
    "            current_retries = retry_count.get(tool_name, 0)\n",
    "            \n",
    "            if current_retries < max_retries:\n",
    "                # é‡è¯•\n",
    "                ai_message = AIMessage(content=f\"å·¥å…·è°ƒç”¨å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... (ç¬¬{current_retries + 1}æ¬¡)\")\n",
    "                new_retry_count = {**retry_count, tool_name: current_retries + 1}\n",
    "                new_error_history = error_history + [{\n",
    "                    \"tool\": tool_name,\n",
    "                    \"error\": last_message.content,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"retry_count\": current_retries + 1\n",
    "                }]\n",
    "                new_status = \"error\"\n",
    "            else:\n",
    "                # è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥\n",
    "                ai_message = AIMessage(content=f\"å·¥å…· {tool_name} å¤šæ¬¡è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨ç­–ç•¥ã€‚\")\n",
    "                new_retry_count = retry_count\n",
    "                new_error_history = error_history + [{\n",
    "                    \"tool\": tool_name,\n",
    "                    \"error\": \"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°\",\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"retry_count\": current_retries\n",
    "                }]\n",
    "                new_status = \"failed\"\n",
    "        else:\n",
    "            # æˆåŠŸæ‰§è¡Œ\n",
    "            ai_message = AIMessage(content=f\"æ“ä½œæˆåŠŸå®Œæˆï¼š{last_message.content}\")\n",
    "            new_retry_count = retry_count\n",
    "            new_error_history = error_history\n",
    "            new_status = \"recovered\" if error_history else \"running\"\n",
    "    \n",
    "    else:\n",
    "        ai_message = AIMessage(content=\"è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ã€‚\")\n",
    "        new_retry_count = retry_count\n",
    "        new_error_history = error_history\n",
    "        new_status = \"running\"\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": messages + [ai_message],\n",
    "        \"retry_count\": new_retry_count,\n",
    "        \"error_history\": new_error_history,\n",
    "        \"execution_status\": new_status\n",
    "    }\n",
    "\n",
    "# å¸¦é”™è¯¯å¤„ç†çš„å·¥å…·èŠ‚ç‚¹\n",
    "class ErrorHandlingToolNode:\n",
    "    def __init__(self, tools):\n",
    "        self.tools = {tool.name: tool for tool in tools}\n",
    "    \n",
    "    def __call__(self, state: ErrorRecoveryState) -> ErrorRecoveryState:\n",
    "        messages = state.get(\"messages\", [])\n",
    "        last_message = messages[-1] if messages else None\n",
    "        \n",
    "        if not isinstance(last_message, AIMessage) or not last_message.tool_calls:\n",
    "            return state\n",
    "        \n",
    "        new_messages = messages.copy()\n",
    "        \n",
    "        for tool_call in last_message.tool_calls:\n",
    "            tool_name = tool_call[\"name\"]\n",
    "            tool_args = tool_call[\"args\"]\n",
    "            call_id = tool_call[\"id\"]\n",
    "            \n",
    "            if tool_name in self.tools:\n",
    "                try:\n",
    "                    # æ‰§è¡Œå·¥å…·\n",
    "                    result = self.tools[tool_name].invoke(tool_args)\n",
    "                    tool_message = ToolMessage(\n",
    "                        content=result,\n",
    "                        tool_call_id=call_id,\n",
    "                        name=tool_name\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    # æ•è·å·¥å…·æ‰§è¡Œé”™è¯¯\n",
    "                    error_msg = f\"å·¥å…· {tool_name} æ‰§è¡Œå¤±è´¥: {str(e)}\"\n",
    "                    tool_message = ToolMessage(\n",
    "                        content=error_msg,\n",
    "                        tool_call_id=call_id,\n",
    "                        name=tool_name\n",
    "                    )\n",
    "                \n",
    "                new_messages.append(tool_message)\n",
    "            else:\n",
    "                # æœªçŸ¥å·¥å…·\n",
    "                error_msg = f\"æœªçŸ¥å·¥å…·: {tool_name}\"\n",
    "                tool_message = ToolMessage(\n",
    "                    content=error_msg,\n",
    "                    tool_call_id=call_id,\n",
    "                    name=tool_name\n",
    "                )\n",
    "                new_messages.append(tool_message)\n",
    "        \n",
    "        return {**state, \"messages\": new_messages}\n",
    "\n",
    "# åˆ›å»ºé”™è¯¯å¤„ç†å·¥å…·\n",
    "error_tools = [unreliable_service, validate_input, calculator]\n",
    "error_tool_node = ErrorHandlingToolNode(error_tools)\n",
    "\n",
    "# å†³ç­–æ˜¯å¦ç»§ç»­\n",
    "def error_recovery_continue(state: ErrorRecoveryState) -> Literal[\"tools\", \"end\"]:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    execution_status = state.get(\"execution_status\", \"running\")\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    # å¦‚æœçŠ¶æ€ä¸ºå¤±è´¥ï¼Œç»“æŸæ‰§è¡Œ\n",
    "    if execution_status == \"failed\":\n",
    "        return \"end\"\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·\n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return \"end\"\n",
    "\n",
    "# æ„å»ºé”™è¯¯æ¢å¤å›¾\n",
    "error_recovery_workflow = StateGraph(ErrorRecoveryState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "error_recovery_workflow.add_node(\"llm\", error_recovery_llm)\n",
    "error_recovery_workflow.add_node(\"tools\", error_tool_node)\n",
    "\n",
    "# è®¾ç½®å…¥å£\n",
    "error_recovery_workflow.set_entry_point(\"llm\")\n",
    "\n",
    "# æ·»åŠ æ¡ä»¶è¾¹\n",
    "error_recovery_workflow.add_conditional_edges(\n",
    "    \"llm\",\n",
    "    error_recovery_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# å·¥å…·æ‰§è¡Œåå›åˆ°LLM\n",
    "error_recovery_workflow.add_edge(\"tools\", \"llm\")\n",
    "\n",
    "# ç¼–è¯‘é”™è¯¯æ¢å¤å›¾\n",
    "error_recovery_app = error_recovery_workflow.compile()\n",
    "\n",
    "# æµ‹è¯•é”™è¯¯å¤„ç†å’Œæ¢å¤\n",
    "error_test_cases = [\n",
    "    \"è¯·è°ƒç”¨ä¸å¯é çš„æœåŠ¡\",\n",
    "    \"è¯·éªŒè¯é‚®ç®±æ ¼å¼\",\n",
    "    \"è¯·éªŒè¯æ•°å­—æ ¼å¼\"\n",
    "]\n",
    "\n",
    "print(\"\\né”™è¯¯å¤„ç†å’Œæ¢å¤æµ‹è¯•ï¼š\")\n",
    "for test_case in error_test_cases:\n",
    "    print(f\"\\n========== æµ‹è¯•: {test_case} ==========\")\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=test_case)],\n",
    "        \"current_task\": test_case,\n",
    "        \"retry_count\": {},\n",
    "        \"max_retries\": 2,\n",
    "        \"error_history\": [],\n",
    "        \"fallback_strategies\": {},\n",
    "        \"execution_status\": \"running\"\n",
    "    }\n",
    "    \n",
    "    result = error_recovery_app.invoke(initial_state)\n",
    "    \n",
    "    # æ˜¾ç¤ºæ‰§è¡Œç»“æœ\n",
    "    for msg in result[\"messages\"]:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            print(f\"ğŸ‘¤ ç”¨æˆ·: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(f\"ğŸ¤– AI: {msg.content}\")\n",
    "            if msg.tool_calls:\n",
    "                for tool_call in msg.tool_calls:\n",
    "                    print(f\"   ğŸ”§ è°ƒç”¨å·¥å…·: {tool_call['name']}\")\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            status_icon = \"âŒ\" if (\"é”™è¯¯\" in msg.content or \"å¤±è´¥\" in msg.content) else \"âœ…\"\n",
    "            print(f\"   {status_icon} å·¥å…·ç»“æœ: {msg.content}\")\n",
    "    \n",
    "    print(f\"æœ€ç»ˆçŠ¶æ€: {result['execution_status']}\")\n",
    "    print(f\"é‡è¯•è®¡æ•°: {result['retry_count']}\")\n",
    "    if result['error_history']:\n",
    "        print(f\"é”™è¯¯å†å²: {len(result['error_history'])} ä¸ªé”™è¯¯\")\n",
    "        for error in result['error_history'][-2:]:  # åªæ˜¾ç¤ºæœ€å2ä¸ªé”™è¯¯\n",
    "            print(f\"  - {error['tool']}: {error['error'][:50]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å®è·µæ¡ˆä¾‹ï¼šæ™ºèƒ½æ•°æ®å¤„ç†Agent\n",
    "\n",
    "æ„å»ºä¸€ä¸ªå®Œæ•´çš„æ™ºèƒ½æ•°æ®å¤„ç†Agentç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ•°æ®å¤„ç†ä¸“ç”¨å·¥å…·\n",
    "@tool\n",
    "def load_dataset(source: str, format_type: str = \"csv\") -> str:\n",
    "    \"\"\"åŠ è½½æ•°æ®é›†ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        source: æ•°æ®æºåç§°æˆ–è·¯å¾„\n",
    "        format_type: æ•°æ®æ ¼å¼ (csv, json, excel)\n",
    "        \n",
    "    Returns:\n",
    "        æ•°æ®åŠ è½½ç»“æœ\n",
    "    \"\"\"\n",
    "    mock_datasets = {\n",
    "        \"sales_data\": {\n",
    "            \"rows\": 1000,\n",
    "            \"columns\": [\"date\", \"product\", \"sales\", \"region\"],\n",
    "            \"size\": \"2.5MB\"\n",
    "        },\n",
    "        \"user_data\": {\n",
    "            \"rows\": 5000,\n",
    "            \"columns\": [\"id\", \"name\", \"age\", \"city\", \"registration_date\"],\n",
    "            \"size\": \"1.8MB\"\n",
    "        },\n",
    "        \"log_data\": {\n",
    "            \"rows\": 10000,\n",
    "            \"columns\": [\"timestamp\", \"level\", \"message\", \"source\"],\n",
    "            \"size\": \"5.2MB\"\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if source in mock_datasets:\n",
    "        data_info = mock_datasets[source]\n",
    "        return f\"\"\"æ•°æ®é›† '{source}' åŠ è½½æˆåŠŸï¼\n",
    "æ ¼å¼: {format_type.upper()}\n",
    "è¡Œæ•°: {data_info['rows']:,}\n",
    "åˆ—æ•°: {len(data_info['columns'])}\n",
    "åˆ—å: {', '.join(data_info['columns'])}\n",
    "æ–‡ä»¶å¤§å°: {data_info['size']}\n",
    "çŠ¶æ€: å·²åŠ è½½åˆ°å†…å­˜\"\"\"\n",
    "    else:\n",
    "        return f\"é”™è¯¯: æ‰¾ä¸åˆ°æ•°æ®é›† '{source}'\"\n",
    "\n",
    "@tool\n",
    "def clean_data(dataset: str, operations: str) -> str:\n",
    "    \"\"\"æ¸…ç†æ•°æ®ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        dataset: æ•°æ®é›†åç§°\n",
    "        operations: æ¸…ç†æ“ä½œåˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”\n",
    "        \n",
    "    Returns:\n",
    "        æ•°æ®æ¸…ç†ç»“æœ\n",
    "    \"\"\"\n",
    "    operations_list = [op.strip() for op in operations.split(',')]\n",
    "    \n",
    "    results = []\n",
    "    for op in operations_list:\n",
    "        if \"ç©ºå€¼\" in op or \"null\" in op.lower():\n",
    "            results.append(\"åˆ é™¤äº†125ä¸ªç©ºå€¼è®°å½•\")\n",
    "        elif \"é‡å¤\" in op or \"duplicate\" in op.lower():\n",
    "            results.append(\"åˆ é™¤äº†43ä¸ªé‡å¤è®°å½•\")\n",
    "        elif \"æ ¼å¼\" in op or \"format\" in op.lower():\n",
    "            results.append(\"æ ‡å‡†åŒ–äº†æ—¥æœŸæ ¼å¼\")\n",
    "        elif \"å¼‚å¸¸\" in op or \"outlier\" in op.lower():\n",
    "            results.append(\"è¯†åˆ«å¹¶æ ‡è®°äº†15ä¸ªå¼‚å¸¸å€¼\")\n",
    "        else:\n",
    "            results.append(f\"æ‰§è¡Œäº†æ“ä½œ: {op}\")\n",
    "    \n",
    "    return f\"\"\"æ•°æ®é›† '{dataset}' æ¸…ç†å®Œæˆï¼š\n",
    "æ‰§è¡Œçš„æ“ä½œ:\n{chr(10).join([f\"- {result}\" for result in results])}\n",
    "æ¸…ç†åæ•°æ®è´¨é‡å¾—åˆ†: 94/100\"\"\"\n",
    "\n",
    "@tool\n",
    "def statistical_analysis(dataset: str, analysis_type: str) -> str:\n",
    "    \"\"\"æ‰§è¡Œç»Ÿè®¡åˆ†æï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        dataset: æ•°æ®é›†åç§°\n",
    "        analysis_type: åˆ†æç±»å‹ (basic, correlation, trend, distribution)\n",
    "        \n",
    "    Returns:\n",
    "        ç»Ÿè®¡åˆ†æç»“æœ\n",
    "    \"\"\"\n",
    "    if analysis_type == \"basic\":\n",
    "        return f\"\"\"åŸºç¡€ç»Ÿè®¡åˆ†æç»“æœ - {dataset}:\n",
    "å¹³å‡å€¼: 245.67\n",
    "ä¸­ä½æ•°: 230.00\n",
    "æ ‡å‡†å·®: 78.23\n",
    "æœ€å°å€¼: 45.00\n",
    "æœ€å¤§å€¼: 987.00\n",
    "å››åˆ†ä½æ•°èŒƒå›´: [180.00, 320.00]\"\"\"\n",
    "    \n",
    "    elif analysis_type == \"correlation\":\n",
    "        return f\"\"\"ç›¸å…³æ€§åˆ†æç»“æœ - {dataset}:\n",
    "å¼ºæ­£ç›¸å…³ (r > 0.7):\n",
    "- sales & marketing_spend: r = 0.85\n",
    "- age & experience: r = 0.72\n",
    "\n",
    "å¼ºè´Ÿç›¸å…³ (r < -0.7):\n",
    "- price & demand: r = -0.78\n",
    "\n",
    "å¼±ç›¸å…³ (-0.3 < r < 0.3):\n",
    "- region & satisfaction: r = 0.12\"\"\"\n",
    "    \n",
    "    elif analysis_type == \"trend\":\n",
    "        return f\"\"\"è¶‹åŠ¿åˆ†æç»“æœ - {dataset}:\n",
    "æ—¶é—´åºåˆ—è¶‹åŠ¿:\n",
    "- æ•´ä½“è¶‹åŠ¿: ä¸Šå‡ (+12.5%)\n",
    "- å­£èŠ‚æ€§æ¨¡å¼: æ£€æµ‹åˆ°å­£åº¦å‘¨æœŸ\n",
    "- å¼‚å¸¸ç‚¹: å‘ç°3ä¸ªå¼‚å¸¸æ—¶æœŸ\n",
    "- é¢„æµ‹å‡†ç¡®åº¦: 87.3%\n",
    "- ä¸‹ä¸€å‘¨æœŸé¢„æµ‹: é¢„è®¡å¢é•¿8.2%\"\"\"\n",
    "    \n",
    "    else:  # distribution\n",
    "        return f\"\"\"åˆ†å¸ƒåˆ†æç»“æœ - {dataset}:\n",
    "æ•°æ®åˆ†å¸ƒç‰¹å¾:\n",
    "- åˆ†å¸ƒç±»å‹: è¿‘ä¼¼æ­£æ€åˆ†å¸ƒ\n",
    "- ååº¦: 0.23 (è½»å¾®å³å)\n",
    "- å³°åº¦: -0.47 (è¾ƒå¹³å¦)\n",
    "- æ­£æ€æ€§æ£€éªŒ: p-value = 0.082\n",
    "- å¼‚å¸¸å€¼æ¯”ä¾‹: 2.1%\"\"\"\n",
    "\n",
    "@tool\n",
    "def generate_visualization(dataset: str, chart_type: str, variables: str) -> str:\n",
    "    \"\"\"ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        dataset: æ•°æ®é›†åç§°\n",
    "        chart_type: å›¾è¡¨ç±»å‹ (bar, line, scatter, heatmap, histogram)\n",
    "        variables: è¦å¯è§†åŒ–çš„å˜é‡ï¼Œç”¨é€—å·åˆ†éš”\n",
    "        \n",
    "    Returns:\n",
    "        å¯è§†åŒ–ç”Ÿæˆç»“æœ\n",
    "    \"\"\"\n",
    "    chart_types = {\n",
    "        \"bar\": \"æŸ±çŠ¶å›¾\",\n",
    "        \"line\": \"æŠ˜çº¿å›¾\",\n",
    "        \"scatter\": \"æ•£ç‚¹å›¾\",\n",
    "        \"heatmap\": \"çƒ­åŠ›å›¾\",\n",
    "        \"histogram\": \"ç›´æ–¹å›¾\",\n",
    "        \"pie\": \"é¥¼å›¾\"\n",
    "    }\n",
    "    \n",
    "    chart_name = chart_types.get(chart_type, chart_type)\n",
    "    variables_list = [v.strip() for v in variables.split(',')]\n",
    "    \n",
    "    return f\"\"\"å¯è§†åŒ–å›¾è¡¨ç”ŸæˆæˆåŠŸï¼\n",
    "æ•°æ®é›†: {dataset}\n",
    "å›¾è¡¨ç±»å‹: {chart_name}\n",
    "å˜é‡: {', '.join(variables_list)}\n",
    "å›¾è¡¨å°ºå¯¸: 1200x800 åƒç´ \n",
    "ä¿å­˜è·¯å¾„: ./charts/{dataset}_{chart_type}_chart.png\n",
    "äº¤äº’å¼ç‰ˆæœ¬: ./charts/{dataset}_{chart_type}_interactive.html\n",
    "ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\"\"\n",
    "\n",
    "@tool\n",
    "def export_report(dataset: str, format_type: str = \"pdf\") -> str:\n",
    "    \"\"\"å¯¼å‡ºåˆ†ææŠ¥å‘Šï¼ˆæ¨¡æ‹Ÿï¼‰ã€‚\n",
    "    \n",
    "    Args:\n",
    "        dataset: æ•°æ®é›†åç§°\n",
    "        format_type: æŠ¥å‘Šæ ¼å¼ (pdf, html, docx)\n",
    "        \n",
    "    Returns:\n",
    "        æŠ¥å‘Šå¯¼å‡ºç»“æœ\n",
    "    \"\"\"\n",
    "    report_sections = [\n",
    "        \"æ‰§è¡Œæ‘˜è¦\",\n",
    "        \"æ•°æ®æ¦‚è§ˆ\",\n",
    "        \"æ•°æ®è´¨é‡è¯„ä¼°\",\n",
    "        \"ç»Ÿè®¡åˆ†æç»“æœ\",\n",
    "        \"å¯è§†åŒ–å›¾è¡¨\",\n",
    "        \"ä¸»è¦å‘ç°\",\n",
    "        \"å»ºè®®å’Œç»“è®º\",\n",
    "        \"é™„å½•\"\n",
    "    ]\n",
    "    \n",
    "    return f\"\"\"åˆ†ææŠ¥å‘Šå¯¼å‡ºå®Œæˆï¼\n",
    "æ•°æ®é›†: {dataset}\n",
    "æŠ¥å‘Šæ ¼å¼: {format_type.upper()}\n",
    "åŒ…å«ç« èŠ‚: {len(report_sections)} ä¸ª\n",
    "é¡µæ•°: 25 é¡µ\n",
    "æ–‡ä»¶å¤§å°: 3.2 MB\n",
    "ä¿å­˜è·¯å¾„: ./reports/{dataset}_analysis_report.{format_type}\n",
    "ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "æŠ¥å‘Šç« èŠ‚:\n{chr(10).join([f\"{i+1}. {section}\" for i, section in enumerate(report_sections)])}\"\"\"\n",
    "\n",
    "# æ•°æ®å¤„ç†AgentçŠ¶æ€\n",
    "class DataProcessingAgentState(TypedDict):\n",
    "    messages: Annotated[list, \"æ¶ˆæ¯å†å²\"]\n",
    "    current_dataset: str\n",
    "    processing_pipeline: list\n",
    "    completed_steps: list\n",
    "    analysis_results: Dict[str, Any]\n",
    "    workflow_status: str\n",
    "    next_action: str\n",
    "\n",
    "# æ•°æ®å¤„ç†è§„åˆ’å™¨\n",
    "def data_processing_planner(state: DataProcessingAgentState) -> DataProcessingAgentState:\n",
    "    \"\"\"æ•°æ®å¤„ç†ä»»åŠ¡è§„åˆ’å™¨\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    if isinstance(last_message, HumanMessage):\n",
    "        content = last_message.content.lower()\n",
    "        \n",
    "        # åˆ†æç”¨æˆ·æ„å›¾å¹¶åˆ¶å®šå¤„ç†è®¡åˆ’\n",
    "        if \"åˆ†æ\" in content and \"æ•°æ®\" in content:\n",
    "            # ç¡®å®šæ•°æ®é›†\n",
    "            dataset = determine_dataset(content)\n",
    "            \n",
    "            # åˆ¶å®šå¤„ç†æµæ°´çº¿\n",
    "            pipeline = create_processing_pipeline(content)\n",
    "            \n",
    "            ai_message = AIMessage(\n",
    "                content=f\"æˆ‘å°†ä¸ºæ‚¨åˆ†æ {dataset} æ•°æ®é›†ã€‚å¤„ç†æµç¨‹åŒ…æ‹¬ï¼š{', '.join(pipeline)}\",\n",
    "                tool_calls=[\n",
    "                    {\n",
    "                        \"name\": \"load_dataset\",\n",
    "                        \"args\": {\"source\": dataset, \"format_type\": \"csv\"},\n",
    "                        \"id\": f\"load_{random.randint(1000, 9999)}\"\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            new_state = {\n",
    "                **state,\n",
    "                \"messages\": messages + [ai_message],\n",
    "                \"current_dataset\": dataset,\n",
    "                \"processing_pipeline\": pipeline,\n",
    "                \"completed_steps\": [],\n",
    "                \"workflow_status\": \"data_loading\",\n",
    "                \"next_action\": \"load_data\"\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            ai_message = AIMessage(content=\"è¯·å‘Šè¯‰æˆ‘æ‚¨æƒ³è¦åˆ†æä»€ä¹ˆæ•°æ®ã€‚æˆ‘å¯ä»¥å¸®æ‚¨åˆ†æé”€å”®æ•°æ®ã€ç”¨æˆ·æ•°æ®æˆ–æ—¥å¿—æ•°æ®ã€‚\")\n",
    "            new_state = {**state, \"messages\": messages + [ai_message]}\n",
    "    \n",
    "    elif isinstance(last_message, ToolMessage):\n",
    "        # æ ¹æ®å½“å‰å·¥ä½œæµçŠ¶æ€å†³å®šä¸‹ä¸€æ­¥\n",
    "        new_state = process_workflow_step(state, last_message)\n",
    "    \n",
    "    else:\n",
    "        ai_message = AIMessage(content=\"è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆæ•°æ®åˆ†æå¸®åŠ©ã€‚\")\n",
    "        new_state = {**state, \"messages\": messages + [ai_message]}\n",
    "    \n",
    "    return new_state\n",
    "\n",
    "def determine_dataset(content: str) -> str:\n",
    "    \"\"\"ç¡®å®šè¦ä½¿ç”¨çš„æ•°æ®é›†\"\"\"\n",
    "    if \"é”€å”®\" in content or \"sale\" in content:\n",
    "        return \"sales_data\"\n",
    "    elif \"ç”¨æˆ·\" in content or \"user\" in content:\n",
    "        return \"user_data\"\n",
    "    elif \"æ—¥å¿—\" in content or \"log\" in content:\n",
    "        return \"log_data\"\n",
    "    else:\n",
    "        return \"sales_data\"  # é»˜è®¤æ•°æ®é›†\n",
    "\n",
    "def create_processing_pipeline(content: str) -> list:\n",
    "    \"\"\"åˆ›å»ºå¤„ç†æµæ°´çº¿\"\"\"\n",
    "    pipeline = [\"åŠ è½½æ•°æ®\"]\n",
    "    \n",
    "    if \"æ¸…ç†\" in content or \"clean\" in content:\n",
    "        pipeline.append(\"æ•°æ®æ¸…ç†\")\n",
    "    \n",
    "    if any(word in content for word in [\"ç»Ÿè®¡\", \"åˆ†æ\", \"statistical\"]):\n",
    "        pipeline.append(\"ç»Ÿè®¡åˆ†æ\")\n",
    "    \n",
    "    if any(word in content for word in [\"å¯è§†åŒ–\", \"å›¾è¡¨\", \"visualization\", \"chart\"]):\n",
    "        pipeline.append(\"ç”Ÿæˆå›¾è¡¨\")\n",
    "    \n",
    "    if \"æŠ¥å‘Š\" in content or \"report\" in content:\n",
    "        pipeline.append(\"å¯¼å‡ºæŠ¥å‘Š\")\n",
    "    \n",
    "    # å¦‚æœæ²¡æœ‰æŒ‡å®šå…·ä½“æ“ä½œï¼Œæ·»åŠ é»˜è®¤æµç¨‹\n",
    "    if len(pipeline) == 1:\n",
    "        pipeline.extend([\"æ•°æ®æ¸…ç†\", \"ç»Ÿè®¡åˆ†æ\", \"ç”Ÿæˆå›¾è¡¨\"])\n",
    "    \n",
    "    return pipeline\n",
    "\n",
    "def process_workflow_step(state: DataProcessingAgentState, tool_result: ToolMessage) -> DataProcessingAgentState:\n",
    "    \"\"\"å¤„ç†å·¥ä½œæµæ­¥éª¤\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    current_dataset = state.get(\"current_dataset\", \"\")\n",
    "    pipeline = state.get(\"processing_pipeline\", [])\n",
    "    completed_steps = state.get(\"completed_steps\", [])\n",
    "    workflow_status = state.get(\"workflow_status\", \"\")\n",
    "    \n",
    "    # è®°å½•å®Œæˆçš„æ­¥éª¤\n",
    "    if workflow_status not in completed_steps:\n",
    "        completed_steps = completed_steps + [workflow_status]\n",
    "    \n",
    "    # ç¡®å®šä¸‹ä¸€æ­¥\n",
    "    next_step_map = {\n",
    "        \"data_loading\": \"data_cleaning\",\n",
    "        \"data_cleaning\": \"statistical_analysis\", \n",
    "        \"statistical_analysis\": \"visualization\",\n",
    "        \"visualization\": \"report_generation\",\n",
    "        \"report_generation\": \"completed\"\n",
    "    }\n",
    "    \n",
    "    next_status = next_step_map.get(workflow_status, \"completed\")\n",
    "    \n",
    "    if next_status == \"data_cleaning\" and \"æ•°æ®æ¸…ç†\" in pipeline:\n",
    "        ai_message = AIMessage(\n",
    "            content=\"æ•°æ®åŠ è½½å®Œæˆï¼Œç°åœ¨å¼€å§‹æ¸…ç†æ•°æ®\",\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"clean_data\",\n",
    "                    \"args\": {\n",
    "                        \"dataset\": current_dataset,\n",
    "                        \"operations\": \"åˆ é™¤ç©ºå€¼, åˆ é™¤é‡å¤é¡¹, æ ¼å¼æ ‡å‡†åŒ–\"\n",
    "                    },\n",
    "                    \"id\": f\"clean_{random.randint(1000, 9999)}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    elif next_status == \"statistical_analysis\" and \"ç»Ÿè®¡åˆ†æ\" in pipeline:\n",
    "        ai_message = AIMessage(\n",
    "            content=\"æ•°æ®æ¸…ç†å®Œæˆï¼Œå¼€å§‹ç»Ÿè®¡åˆ†æ\",\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"statistical_analysis\",\n",
    "                    \"args\": {\"dataset\": current_dataset, \"analysis_type\": \"basic\"},\n",
    "                    \"id\": f\"stats_{random.randint(1000, 9999)}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    elif next_status == \"visualization\" and \"ç”Ÿæˆå›¾è¡¨\" in pipeline:\n",
    "        ai_message = AIMessage(\n",
    "            content=\"ç»Ÿè®¡åˆ†æå®Œæˆï¼Œç”Ÿæˆå¯è§†åŒ–å›¾è¡¨\",\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"generate_visualization\",\n",
    "                    \"args\": {\n",
    "                        \"dataset\": current_dataset,\n",
    "                        \"chart_type\": \"bar\",\n",
    "                        \"variables\": \"sales, region\"\n",
    "                    },\n",
    "                    \"id\": f\"viz_{random.randint(1000, 9999)}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    elif next_status == \"report_generation\" and \"å¯¼å‡ºæŠ¥å‘Š\" in pipeline:\n",
    "        ai_message = AIMessage(\n",
    "            content=\"å›¾è¡¨ç”Ÿæˆå®Œæˆï¼Œå¯¼å‡ºåˆ†ææŠ¥å‘Š\",\n",
    "            tool_calls=[\n",
    "                {\n",
    "                    \"name\": \"export_report\",\n",
    "                    \"args\": {\"dataset\": current_dataset, \"format_type\": \"pdf\"},\n",
    "                    \"id\": f\"report_{random.randint(1000, 9999)}\"\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        # å·¥ä½œæµå®Œæˆ\n",
    "        progress = f\"å®Œæˆæ­¥éª¤: {len(completed_steps)}/{len(pipeline)}\"\n",
    "        ai_message = AIMessage(content=f\"æ•°æ®åˆ†æå·¥ä½œæµå·²å®Œæˆï¼\\n{progress}\\næ‰€æœ‰åˆ†æç»“æœå·²ä¿å­˜ã€‚\")\n",
    "        next_status = \"completed\"\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"messages\": messages + [ai_message],\n",
    "        \"completed_steps\": completed_steps,\n",
    "        \"workflow_status\": next_status\n",
    "    }\n",
    "\n",
    "# åˆ›å»ºæ•°æ®å¤„ç†å·¥å…·èŠ‚ç‚¹\n",
    "data_tools = [load_dataset, clean_data, statistical_analysis, generate_visualization, export_report]\n",
    "data_tool_node = ToolNode(data_tools)\n",
    "\n",
    "# å†³ç­–æ˜¯å¦ç»§ç»­\n",
    "def data_processing_continue(state: DataProcessingAgentState) -> Literal[\"tools\", \"end\"]:\n",
    "    messages = state.get(\"messages\", [])\n",
    "    workflow_status = state.get(\"workflow_status\", \"\")\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    if workflow_status == \"completed\":\n",
    "        return \"end\"\n",
    "    \n",
    "    if isinstance(last_message, AIMessage) and last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    \n",
    "    return \"end\"\n",
    "\n",
    "# æ„å»ºæ•°æ®å¤„ç†Agent\n",
    "data_processing_workflow = StateGraph(DataProcessingAgentState)\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "data_processing_workflow.add_node(\"planner\", data_processing_planner)\n",
    "data_processing_workflow.add_node(\"tools\", data_tool_node)\n",
    "\n",
    "# è®¾ç½®å…¥å£\n",
    "data_processing_workflow.set_entry_point(\"planner\")\n",
    "\n",
    "# æ·»åŠ æ¡ä»¶è¾¹\n",
    "data_processing_workflow.add_conditional_edges(\n",
    "    \"planner\",\n",
    "    data_processing_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",\n",
    "        \"end\": END\n",
    "    }\n",
    ")\n",
    "\n",
    "# å·¥å…·æ‰§è¡Œåå›åˆ°è§„åˆ’å™¨\n",
    "data_processing_workflow.add_edge(\"tools\", \"planner\")\n",
    "\n",
    "# ç¼–è¯‘æ•°æ®å¤„ç†Agent\n",
    "data_processing_app = data_processing_workflow.compile()\n",
    "\n",
    "# æµ‹è¯•æ•°æ®å¤„ç†Agent\n",
    "data_queries = [\n",
    "    \"è¯·åˆ†æé”€å”®æ•°æ®ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…ç†ã€ç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–\",\n",
    "    \"å¸®æˆ‘å¤„ç†ç”¨æˆ·æ•°æ®ï¼Œç”Ÿæˆåˆ†ææŠ¥å‘Š\",\n",
    "    \"åˆ†ææ—¥å¿—æ•°æ®çš„è¶‹åŠ¿å’Œå¼‚å¸¸\"\n",
    "]\n",
    "\n",
    "print(\"\\næ™ºèƒ½æ•°æ®å¤„ç†Agentæµ‹è¯•ï¼š\")\n",
    "for query in data_queries:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ“Š æ•°æ®åˆ†æè¯·æ±‚: {query}\")\n",
    "    print('='*60)\n",
    "    \n",
    "    initial_state = {\n",
    "        \"messages\": [HumanMessage(content=query)],\n",
    "        \"current_dataset\": \"\",\n",
    "        \"processing_pipeline\": [],\n",
    "        \"completed_steps\": [],\n",
    "        \"analysis_results\": {},\n",
    "        \"workflow_status\": \"planning\",\n",
    "        \"next_action\": \"\"\n",
    "    }\n",
    "    \n",
    "    result = data_processing_app.invoke(initial_state)\n",
    "    \n",
    "    # æ˜¾ç¤ºå¤„ç†è¿‡ç¨‹\n",
    "    step_counter = 1\n",
    "    for msg in result[\"messages\"]:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            print(f\"ğŸ‘¤ ç”¨æˆ·è¯·æ±‚: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(f\"\\nğŸ¤– æ­¥éª¤ {step_counter}: {msg.content}\")\n",
    "            if msg.tool_calls:\n",
    "                for tool_call in msg.tool_calls:\n",
    "                    print(f\"   ğŸ”§ æ‰§è¡Œ: {tool_call['name']}({', '.join([f'{k}={v}' for k, v in tool_call['args'].items()])})\") \n",
    "            step_counter += 1\n",
    "        elif isinstance(msg, ToolMessage):\n",
    "            print(f\"   âœ… ç»“æœ: {msg.content[:150]}...\" if len(msg.content) > 150 else f\"   âœ… ç»“æœ: {msg.content}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ å·¥ä½œæµçŠ¶æ€: {result.get('workflow_status', 'N/A')}\")\n",
    "    print(f\"ğŸ“‹ å¤„ç†æµç¨‹: {' â†’ '.join(result.get('processing_pipeline', []))}\")\n",
    "    print(f\"âœ”ï¸  å·²å®Œæˆæ­¥éª¤: {len(result.get('completed_steps', []))}/{len(result.get('processing_pipeline', []))}\")\n",
    "    \n",
    "    if result.get('workflow_status') == 'completed':\n",
    "        print(\"ğŸ‰ æ•°æ®åˆ†æå·¥ä½œæµå…¨éƒ¨å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç»ƒä¹ é¢˜\n",
    "\n",
    "### ç»ƒä¹ 1ï¼šé‚®ä»¶å¤„ç†Agent\n",
    "åˆ›å»ºä¸€ä¸ªé‚®ä»¶å¤„ç†Agentï¼Œèƒ½å¤Ÿåˆ†ç±»ã€å›å¤å’Œç®¡ç†é‚®ä»¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹ 1ï¼šè¯·å®Œæˆé‚®ä»¶å¤„ç†Agent\n",
    "# è¦æ±‚ï¼š\n",
    "# 1. åˆ†ç±»é‚®ä»¶ï¼ˆç´§æ€¥ã€æ™®é€šã€åƒåœ¾é‚®ä»¶ï¼‰\n",
    "# 2. è‡ªåŠ¨å›å¤åŠŸèƒ½\n",
    "# 3. é‚®ä»¶è½¬å‘å’Œæ ‡è®°\n",
    "# 4. é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶\n",
    "\n",
    "# TODO: å®šä¹‰é‚®ä»¶ç›¸å…³å·¥å…·\n",
    "@tool\n",
    "def classify_email(subject: str, content: str) -> str:\n",
    "    \"\"\"åˆ†ç±»é‚®ä»¶\"\"\"\n",
    "    # è¯·å®ç°é‚®ä»¶åˆ†ç±»é€»è¾‘\n",
    "    pass\n",
    "\n",
    "@tool  \n",
    "def auto_reply(email_type: str, sender: str) -> str:\n",
    "    \"\"\"è‡ªåŠ¨å›å¤é‚®ä»¶\"\"\"\n",
    "    # è¯·å®ç°è‡ªåŠ¨å›å¤é€»è¾‘\n",
    "    pass\n",
    "\n",
    "# TODO: å®ç°é‚®ä»¶å¤„ç†Agent\n",
    "\n",
    "print(\"è¯·å®ç°é‚®ä»¶å¤„ç†Agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»ƒä¹ 2ï¼šå¤šå·¥å…·åä½œç³»ç»Ÿ\n",
    "è®¾è®¡ä¸€ä¸ªéœ€è¦å¤šä¸ªå·¥å…·åä½œå®Œæˆçš„å¤æ‚ä»»åŠ¡ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç»ƒä¹ 2ï¼šè¯·å®Œæˆå¤šå·¥å…·åä½œç³»ç»Ÿ\n",
    "# åœºæ™¯ï¼šæ™ºèƒ½å†…å®¹ç”Ÿæˆå’Œå‘å¸ƒç³»ç»Ÿ\n",
    "# è¦æ±‚ï¼š\n",
    "# 1. å†…å®¹ç”Ÿæˆå·¥å…·\n",
    "# 2. å†…å®¹æ£€æŸ¥å’Œä¼˜åŒ–å·¥å…·  \n",
    "# 3. å¤šå¹³å°å‘å¸ƒå·¥å…·\n",
    "# 4. æ•ˆæœè·Ÿè¸ªå·¥å…·\n",
    "# 5. å¼‚å¸¸å¤„ç†å’Œå›æ»šæœºåˆ¶\n",
    "\n",
    "# TODO: å®ç°å†…å®¹å¤„ç†ç›¸å…³å·¥å…·å’ŒAgent\n",
    "\n",
    "print(\"è¯·å®ç°å¤šå·¥å…·åä½œç³»ç»Ÿ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "åœ¨æœ¬è¯¾ç¨‹ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†LangGraphä¸­å·¥å…·è°ƒç”¨å’ŒAgentæ„å»ºçš„å„ä¸ªæ–¹é¢ï¼š\n",
    "\n",
    "### å…³é”®è¦ç‚¹ï¼š\n",
    "\n",
    "1. **å·¥å…·å®šä¹‰**\n",
    "   - ä½¿ç”¨`@tool`è£…é¥°å™¨å®šä¹‰å·¥å…·å‡½æ•°\n",
    "   - æä¾›æ¸…æ™°çš„æ–‡æ¡£å­—ç¬¦ä¸²å’Œç±»å‹æ³¨è§£\n",
    "   - å®ç°é€‚å½“çš„é”™è¯¯å¤„ç†\n",
    "\n",
    "2. **ToolNodeä½¿ç”¨**\n",
    "   - `ToolNode`è‡ªåŠ¨å¤„ç†å·¥å…·è°ƒç”¨å’Œç»“æœè¿”å›\n",
    "   - æ”¯æŒå¤šä¸ªå·¥å…·çš„æ‰¹é‡è°ƒç”¨\n",
    "   - ä¸LangGraphçš„æ¶ˆæ¯æµæ— ç¼é›†æˆ\n",
    "\n",
    "3. **Agentæ‰§è¡Œå™¨**\n",
    "   - æ™ºèƒ½å†³ç­–å·¥å…·é€‰æ‹©å’Œå‚æ•°ä¼ é€’\n",
    "   - æ”¯æŒå¤æ‚çš„å¤šæ­¥éª¤å·¥ä½œæµ\n",
    "   - çŠ¶æ€ç®¡ç†å’Œä¸Šä¸‹æ–‡ä¼ é€’\n",
    "\n",
    "4. **é”™è¯¯å¤„ç†**\n",
    "   - å·¥å…·æ‰§è¡Œå¼‚å¸¸æ•è·\n",
    "   - é‡è¯•æœºåˆ¶å’Œå¤‡ç”¨ç­–ç•¥\n",
    "   - é”™è¯¯æ¢å¤å’Œä¼˜é›…é™çº§\n",
    "\n",
    "5. **å®é™…åº”ç”¨**\n",
    "   - æ•°æ®å¤„ç†å·¥ä½œæµ\n",
    "   - æ™ºèƒ½å®¢æœç³»ç»Ÿ\n",
    "   - å†…å®¹ç®¡ç†å¹³å°\n",
    "   - è‡ªåŠ¨åŒ–åŠå…¬åŠ©æ‰‹\n",
    "\n",
    "### æœ€ä½³å®è·µï¼š\n",
    "\n",
    "- **å·¥å…·è®¾è®¡**ï¼šä¿æŒå·¥å…·åŠŸèƒ½å•ä¸€ã€æ¥å£æ¸…æ™°\n",
    "- **é”™è¯¯å¤„ç†**ï¼šå®ç°å¥å£®çš„å¼‚å¸¸å¤„ç†å’Œæ¢å¤æœºåˆ¶\n",
    "- **çŠ¶æ€ç®¡ç†**ï¼šåˆç†è®¾è®¡çŠ¶æ€ç»“æ„ï¼Œé¿å…çŠ¶æ€æ±¡æŸ“\n",
    "- **æ€§èƒ½ä¼˜åŒ–**ï¼šè€ƒè™‘å·¥å…·è°ƒç”¨çš„å¼€é”€å’Œå¹¶å‘å¤„ç†\n",
    "- **å®‰å…¨æ€§**ï¼šéªŒè¯å·¥å…·è¾“å…¥ï¼Œé˜²æ­¢æ¶æ„è°ƒç”¨\n",
    "\n",
    "### è¿›é˜¶è¯é¢˜ï¼š\n",
    "\n",
    "- **åŠ¨æ€å·¥å…·åŠ è½½**ï¼šè¿è¡Œæ—¶åŠ è½½å’Œå¸è½½å·¥å…·\n",
    "- **å·¥å…·ç»„åˆ**ï¼šå°†å¤šä¸ªç®€å•å·¥å…·ç»„åˆæˆå¤æ‚åŠŸèƒ½\n",
    "- **ç¼“å­˜ç­–ç•¥**ï¼šç¼“å­˜å·¥å…·ç»“æœæé«˜æ€§èƒ½\n",
    "- **ç›‘æ§å’Œæ—¥å¿—**ï¼šè·Ÿè¸ªå·¥å…·ä½¿ç”¨æƒ…å†µå’Œæ€§èƒ½æŒ‡æ ‡\n",
    "\n",
    "## ä¸‹ä¸€è¯¾é¢„å‘Š\n",
    "\n",
    "åœ¨ä¸‹ä¸€è¯¾ã€Šå­å›¾å’ŒåµŒå¥—å›¾ã€‹ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ï¼š\n",
    "\n",
    "1. å­å›¾çš„æ¦‚å¿µå’Œä¼˜åŠ¿\n",
    "2. åµŒå¥—å›¾ç»“æ„çš„è®¾è®¡\n",
    "3. å­å›¾ç¼–è¯‘å’Œæ‰§è¡Œ\n",
    "4. çŠ¶æ€ä¼ é€’å’Œéš”ç¦»\n",
    "5. æ¨¡å—åŒ–è®¾è®¡æœ€ä½³å®è·µ\n",
    "6. å¤æ‚ç³»ç»Ÿçš„æ¶æ„ç»„ç»‡\n",
    "\n",
    "å­å›¾æ˜¯æ„å»ºå¤§å‹ã€å¤æ‚LangGraphåº”ç”¨çš„å…³é”®æŠ€æœ¯ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿå°†ç³»ç»Ÿåˆ†è§£ä¸ºå¯é‡ç”¨çš„æ¨¡å—ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}