{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. çŠ¶æ€ç®¡ç†å’Œ StateGraph\n",
    "\n",
    "## è¯¾ç¨‹ç›®æ ‡\n",
    "- æ·±å…¥ç†è§£ LangGraph çš„çŠ¶æ€ç®¡ç†æœºåˆ¶\n",
    "- æŒæ¡ StateGraph çš„ä½¿ç”¨æ–¹æ³•\n",
    "- å­¦ä¹  Reducer å‡½æ•°çš„åº”ç”¨\n",
    "- ç†è§£çŠ¶æ€æ³¨è§£å’Œç±»å‹ç³»ç»Ÿ\n",
    "- å®ç°å¤æ‚çš„çŠ¶æ€æ›´æ–°é€»è¾‘\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "StateGraph æ˜¯ LangGraph ä¸­æœ€å¸¸ç”¨çš„å›¾ç±»å‹ï¼Œå®ƒæä¾›äº†ï¼š\n",
    "1. **ç±»å‹å®‰å…¨çš„çŠ¶æ€ç®¡ç†**\n",
    "2. **è‡ªåŠ¨çŠ¶æ€åˆå¹¶æœºåˆ¶**\n",
    "3. **å†…ç½®çš„æ¶ˆæ¯å¤„ç†**\n",
    "4. **çµæ´»çš„çŠ¶æ€æ›´æ–°ç­–ç•¥**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ç¯å¢ƒå‡†å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "from typing import TypedDict, Annotated, Sequence, Literal\n",
    "from typing import Optional, Union, Any\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.graph.message import add_messages, Messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. StateGraph åŸºç¡€\n",
    "\n",
    "### 2.1 å®šä¹‰çŠ¶æ€ç»“æ„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŸºç¡€çŠ¶æ€å®šä¹‰\n",
    "class BasicState(TypedDict):\n",
    "    \"\"\"æœ€ç®€å•çš„çŠ¶æ€å®šä¹‰\"\"\"\n",
    "    count: int\n",
    "    messages: list[str]\n",
    "    status: str\n",
    "\n",
    "# åˆ›å»ºåŸºç¡€ StateGraph\n",
    "basic_graph = StateGraph(BasicState)\n",
    "\n",
    "# å®šä¹‰èŠ‚ç‚¹å‡½æ•°\n",
    "def increment_counter(state: BasicState) -> BasicState:\n",
    "    \"\"\"é€’å¢è®¡æ•°å™¨\"\"\"\n",
    "    print(f\"å½“å‰è®¡æ•°: {state.get('count', 0)}\")\n",
    "    return {\n",
    "        \"count\": state.get(\"count\", 0) + 1,\n",
    "        \"messages\": state.get(\"messages\", []) + [\"è®¡æ•°å™¨å·²é€’å¢\"],\n",
    "        \"status\": \"processing\"\n",
    "    }\n",
    "\n",
    "def check_limit(state: BasicState) -> BasicState:\n",
    "    \"\"\"æ£€æŸ¥è®¡æ•°é™åˆ¶\"\"\"\n",
    "    count = state.get(\"count\", 0)\n",
    "    if count >= 5:\n",
    "        status = \"limit_reached\"\n",
    "        message = \"å·²è¾¾åˆ°é™åˆ¶\"\n",
    "    else:\n",
    "        status = \"under_limit\"\n",
    "        message = f\"å½“å‰è®¡æ•° {count}ï¼Œæœªè¾¾é™åˆ¶\"\n",
    "    \n",
    "    return {\n",
    "        \"messages\": state.get(\"messages\", []) + [message],\n",
    "        \"status\": status\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå›¾\n",
    "basic_graph.add_node(\"increment\", increment_counter)\n",
    "basic_graph.add_node(\"check\", check_limit)\n",
    "\n",
    "# è®¾ç½®è¾¹\n",
    "basic_graph.set_entry_point(\"increment\")\n",
    "basic_graph.add_edge(\"increment\", \"check\")\n",
    "basic_graph.add_edge(\"check\", END)\n",
    "\n",
    "# ç¼–è¯‘\n",
    "basic_app = basic_graph.compile()\n",
    "\n",
    "# æ‰§è¡Œ\n",
    "result = basic_app.invoke({\"count\": 3})\n",
    "print(\"\\næ‰§è¡Œç»“æœ:\")\n",
    "print(json.dumps(result, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ä½¿ç”¨ Reducer å‡½æ•°è¿›è¡ŒçŠ¶æ€åˆå¹¶\n",
    "\n",
    "Reducer å‡½æ•°å®šä¹‰äº†å¦‚ä½•åˆå¹¶çŠ¶æ€æ›´æ–°ã€‚è¿™æ˜¯ StateGraph çš„æ ¸å¿ƒç‰¹æ€§ä¹‹ä¸€ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰å¸¦æœ‰ Reducer çš„çŠ¶æ€\n",
    "class ReducerState(TypedDict):\n",
    "    # ä½¿ç”¨ Annotated å’Œ operator.add ä½œä¸º reducer\n",
    "    messages: Annotated[list[str], operator.add]\n",
    "    # ä½¿ç”¨è‡ªå®šä¹‰ reducer\n",
    "    total: Annotated[int, lambda x, y: x + y]\n",
    "    # ä¸ä½¿ç”¨ reducerï¼ˆé»˜è®¤è¦†ç›–ï¼‰\n",
    "    current_value: int\n",
    "    # åˆ—è¡¨ç´¯ç§¯\n",
    "    history: Annotated[list[dict], operator.add]\n",
    "\n",
    "# åˆ›å»ºå¸¦ Reducer çš„å›¾\n",
    "reducer_graph = StateGraph(ReducerState)\n",
    "\n",
    "def add_values(state: ReducerState) -> dict:\n",
    "    \"\"\"æ·»åŠ å€¼åˆ°çŠ¶æ€\"\"\"\n",
    "    print(\"æ·»åŠ æ–°å€¼...\")\n",
    "    return {\n",
    "        \"messages\": [\"æ·»åŠ äº†æ–°å€¼\"],  # ä¼šè¢«è¿½åŠ åˆ°åˆ—è¡¨\n",
    "        \"total\": 10,  # ä¼šè¢«ç´¯åŠ \n",
    "        \"current_value\": 42,  # ä¼šè¦†ç›–\n",
    "        \"history\": [{\"action\": \"add\", \"value\": 10, \"time\": datetime.now().isoformat()}]\n",
    "    }\n",
    "\n",
    "def multiply_values(state: ReducerState) -> dict:\n",
    "    \"\"\"ä¹˜æ³•æ“ä½œ\"\"\"\n",
    "    current = state.get(\"current_value\", 1)\n",
    "    print(f\"å½“å‰å€¼ {current} ä¹˜ä»¥ 2\")\n",
    "    return {\n",
    "        \"messages\": [f\"æ‰§è¡Œä¹˜æ³•: {current} * 2\"],\n",
    "        \"total\": current * 2,\n",
    "        \"current_value\": current * 2,\n",
    "        \"history\": [{\"action\": \"multiply\", \"value\": current * 2, \"time\": datetime.now().isoformat()}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå’Œæ‰§è¡Œ Reducer å›¾\n",
    "reducer_graph.add_node(\"add\", add_values)\n",
    "reducer_graph.add_node(\"multiply\", multiply_values)\n",
    "\n",
    "reducer_graph.set_entry_point(\"add\")\n",
    "reducer_graph.add_edge(\"add\", \"multiply\")\n",
    "reducer_graph.add_edge(\"multiply\", END)\n",
    "\n",
    "reducer_app = reducer_graph.compile()\n",
    "\n",
    "# æ‰§è¡Œå¹¶è§‚å¯Ÿ reducer çš„æ•ˆæœ\n",
    "initial_state = {\n",
    "    \"messages\": [\"å¼€å§‹\"],\n",
    "    \"total\": 5,\n",
    "    \"current_value\": 1,\n",
    "    \"history\": []\n",
    "}\n",
    "\n",
    "print(\"åˆå§‹çŠ¶æ€:\")\n",
    "print(json.dumps(initial_state, ensure_ascii=False, indent=2))\n",
    "\n",
    "result = reducer_app.invoke(initial_state)\n",
    "\n",
    "print(\"\\næœ€ç»ˆçŠ¶æ€:\")\n",
    "print(json.dumps(result, ensure_ascii=False, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. è‡ªå®šä¹‰ Reducer å‡½æ•°\n",
    "\n",
    "é™¤äº†ä½¿ç”¨å†…ç½®çš„ reducerï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åˆ›å»ºè‡ªå®šä¹‰çš„ reducer å‡½æ•°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# è‡ªå®šä¹‰ reducer å‡½æ•°\n",
    "def merge_dicts(existing: dict, new: dict) -> dict:\n",
    "    \"\"\"åˆå¹¶ä¸¤ä¸ªå­—å…¸ï¼Œæ·±åº¦åˆå¹¶\"\"\"\n",
    "    result = existing.copy()\n",
    "    for key, value in new.items():\n",
    "        if key in result and isinstance(result[key], dict) and isinstance(value, dict):\n",
    "            result[key] = merge_dicts(result[key], value)\n",
    "        else:\n",
    "            result[key] = value\n",
    "    return result\n",
    "\n",
    "def keep_last_n(existing: list, new: list, n: int = 5) -> list:\n",
    "    \"\"\"åªä¿ç•™æœ€å n ä¸ªå…ƒç´ \"\"\"\n",
    "    combined = existing + new\n",
    "    return combined[-n:] if len(combined) > n else combined\n",
    "\n",
    "# ä½¿ç”¨è‡ªå®šä¹‰ reducer çš„çŠ¶æ€\n",
    "class CustomReducerState(TypedDict):\n",
    "    # æ·±åº¦åˆå¹¶å­—å…¸\n",
    "    config: Annotated[dict, merge_dicts]\n",
    "    # åªä¿ç•™æœ€å5æ¡æ¶ˆæ¯\n",
    "    recent_messages: Annotated[list, lambda x, y: keep_last_n(x, y, 5)]\n",
    "    # å–æœ€å¤§å€¼\n",
    "    max_value: Annotated[int, max]\n",
    "    # é›†åˆå»é‡\n",
    "    unique_tags: Annotated[set, lambda x, y: x.union(y) if x else y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä½¿ç”¨è‡ªå®šä¹‰ reducer çš„å›¾\n",
    "custom_graph = StateGraph(CustomReducerState)\n",
    "\n",
    "def process_data_1(state: CustomReducerState) -> dict:\n",
    "    return {\n",
    "        \"config\": {\"level1\": {\"setting1\": \"value1\"}},\n",
    "        \"recent_messages\": [\"æ¶ˆæ¯1\", \"æ¶ˆæ¯2\"],\n",
    "        \"max_value\": 10,\n",
    "        \"unique_tags\": {\"tag1\", \"tag2\"}\n",
    "    }\n",
    "\n",
    "def process_data_2(state: CustomReducerState) -> dict:\n",
    "    return {\n",
    "        \"config\": {\"level1\": {\"setting2\": \"value2\"}, \"level2\": {\"option\": \"enabled\"}},\n",
    "        \"recent_messages\": [\"æ¶ˆæ¯3\", \"æ¶ˆæ¯4\", \"æ¶ˆæ¯5\", \"æ¶ˆæ¯6\"],\n",
    "        \"max_value\": 15,\n",
    "        \"unique_tags\": {\"tag2\", \"tag3\", \"tag4\"}\n",
    "    }\n",
    "\n",
    "# æ„å»ºå›¾\n",
    "custom_graph.add_node(\"process1\", process_data_1)\n",
    "custom_graph.add_node(\"process2\", process_data_2)\n",
    "\n",
    "custom_graph.set_entry_point(\"process1\")\n",
    "custom_graph.add_edge(\"process1\", \"process2\")\n",
    "custom_graph.add_edge(\"process2\", END)\n",
    "\n",
    "custom_app = custom_graph.compile()\n",
    "\n",
    "# æ‰§è¡Œ\n",
    "result = custom_app.invoke({})\n",
    "print(\"è‡ªå®šä¹‰ Reducer ç»“æœ:\")\n",
    "print(json.dumps(result, ensure_ascii=False, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. æ¶ˆæ¯å¤„ç†å’Œ add_messages\n",
    "\n",
    "LangGraph æä¾›äº†ä¸“é—¨çš„æ¶ˆæ¯å¤„ç†æœºåˆ¶ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "# ä½¿ç”¨å†…ç½®çš„æ¶ˆæ¯ reducer\n",
    "class MessageState(TypedDict):\n",
    "    messages: Annotated[Sequence[Messages], add_messages]\n",
    "    context: str\n",
    "    turn_count: int\n",
    "\n",
    "# åˆ›å»ºæ¶ˆæ¯å¤„ç†å›¾\n",
    "message_graph = StateGraph(MessageState)\n",
    "\n",
    "def process_user_input(state: MessageState) -> dict:\n",
    "    \"\"\"å¤„ç†ç”¨æˆ·è¾“å…¥\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    \n",
    "    # è·å–æœ€åä¸€æ¡æ¶ˆæ¯\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    print(f\"å¤„ç†ç”¨æˆ·æ¶ˆæ¯: {last_message.content if last_message else 'æ— '}\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [SystemMessage(content=\"æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...\")],\n",
    "        \"context\": \"user_input_processed\",\n",
    "        \"turn_count\": state.get(\"turn_count\", 0) + 1\n",
    "    }\n",
    "\n",
    "def generate_response(state: MessageState) -> dict:\n",
    "    \"\"\"ç”ŸæˆAIå“åº”\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    context = state.get(\"context\", \"\")\n",
    "    \n",
    "    # ç®€å•çš„å“åº”ç”Ÿæˆé€»è¾‘\n",
    "    response = f\"åŸºäºä¸Šä¸‹æ–‡ '{context}'ï¼Œæˆ‘çš„å›å¤æ˜¯ï¼šç†è§£æ‚¨çš„éœ€æ±‚ï¼Œæ­£åœ¨å¤„ç†ã€‚\"\n",
    "    \n",
    "    print(f\"ç”Ÿæˆå“åº”: {response}\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=response)],\n",
    "        \"context\": \"response_generated\"\n",
    "    }\n",
    "\n",
    "def log_conversation(state: MessageState) -> dict:\n",
    "    \"\"\"è®°å½•å¯¹è¯\"\"\"\n",
    "    messages = state.get(\"messages\", [])\n",
    "    turn_count = state.get(\"turn_count\", 0)\n",
    "    \n",
    "    print(f\"\\nå¯¹è¯è½®æ¬¡: {turn_count}\")\n",
    "    print(f\"æ¶ˆæ¯æ€»æ•°: {len(messages)}\")\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [SystemMessage(content=f\"å¯¹è¯å·²è®°å½•ï¼Œå…±{turn_count}è½®\")]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºæ¶ˆæ¯å¤„ç†å›¾\n",
    "message_graph.add_node(\"process_input\", process_user_input)\n",
    "message_graph.add_node(\"generate\", generate_response)\n",
    "message_graph.add_node(\"log\", log_conversation)\n",
    "\n",
    "message_graph.set_entry_point(\"process_input\")\n",
    "message_graph.add_edge(\"process_input\", \"generate\")\n",
    "message_graph.add_edge(\"generate\", \"log\")\n",
    "message_graph.add_edge(\"log\", END)\n",
    "\n",
    "message_app = message_graph.compile()\n",
    "\n",
    "# æµ‹è¯•æ¶ˆæ¯å¤„ç†\n",
    "test_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=\"ä½ å¥½ï¼Œæˆ‘éœ€è¦å¸®åŠ©\")\n",
    "    ],\n",
    "    \"context\": \"\",\n",
    "    \"turn_count\": 0\n",
    "}\n",
    "\n",
    "result = message_app.invoke(test_state)\n",
    "\n",
    "print(\"\\næœ€ç»ˆæ¶ˆæ¯åˆ—è¡¨:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"- [{msg.__class__.__name__}]: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å¤æ‚çŠ¶æ€ç®¡ç†ç¤ºä¾‹ï¼šä»»åŠ¡ç®¡ç†ç³»ç»Ÿ\n",
    "\n",
    "è®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªæ›´å¤æ‚çš„ä¾‹å­ï¼Œå±•ç¤ºçŠ¶æ€ç®¡ç†çš„å®é™…åº”ç”¨ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List, Dict\n",
    "\n",
    "# å®šä¹‰ä»»åŠ¡çŠ¶æ€æšä¸¾\n",
    "class TaskStatus(str, Enum):\n",
    "    PENDING = \"pending\"\n",
    "    IN_PROGRESS = \"in_progress\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\"\n",
    "\n",
    "# å®šä¹‰ä»»åŠ¡ç»“æ„\n",
    "class Task(TypedDict):\n",
    "    id: str\n",
    "    title: str\n",
    "    status: TaskStatus\n",
    "    priority: int\n",
    "    assigned_to: Optional[str]\n",
    "    created_at: str\n",
    "    updated_at: str\n",
    "\n",
    "# å¤æ‚çš„çŠ¶æ€ç®¡ç†\n",
    "class TaskManagementState(TypedDict):\n",
    "    # ä»»åŠ¡åˆ—è¡¨\n",
    "    tasks: Annotated[List[Task], operator.add]\n",
    "    # å½“å‰å¤„ç†çš„ä»»åŠ¡ID\n",
    "    current_task_id: Optional[str]\n",
    "    # ç»Ÿè®¡ä¿¡æ¯ï¼ˆä½¿ç”¨è‡ªå®šä¹‰ reducerï¼‰\n",
    "    stats: Annotated[Dict[str, int], lambda x, y: {**x, **y}]\n",
    "    # æ“ä½œæ—¥å¿—\n",
    "    logs: Annotated[List[str], operator.add]\n",
    "    # é”™è¯¯ä¿¡æ¯\n",
    "    errors: Annotated[List[str], operator.add]\n",
    "    # ç³»ç»ŸçŠ¶æ€\n",
    "    system_status: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä»»åŠ¡ç®¡ç†å›¾\n",
    "task_graph = StateGraph(TaskManagementState)\n",
    "\n",
    "def create_task(state: TaskManagementState) -> dict:\n",
    "    \"\"\"åˆ›å»ºæ–°ä»»åŠ¡\"\"\"\n",
    "    import uuid\n",
    "    \n",
    "    task_id = str(uuid.uuid4())[:8]\n",
    "    new_task = Task(\n",
    "        id=task_id,\n",
    "        title=f\"ä»»åŠ¡ {task_id}\",\n",
    "        status=TaskStatus.PENDING,\n",
    "        priority=1,\n",
    "        assigned_to=None,\n",
    "        created_at=datetime.now().isoformat(),\n",
    "        updated_at=datetime.now().isoformat()\n",
    "    )\n",
    "    \n",
    "    print(f\"âœ… åˆ›å»ºä»»åŠ¡: {new_task['title']}\")\n",
    "    \n",
    "    # æ›´æ–°ç»Ÿè®¡\n",
    "    current_stats = state.get(\"stats\", {})\n",
    "    pending_count = current_stats.get(\"pending\", 0) + 1\n",
    "    \n",
    "    return {\n",
    "        \"tasks\": [new_task],\n",
    "        \"current_task_id\": task_id,\n",
    "        \"stats\": {\"pending\": pending_count, \"total\": current_stats.get(\"total\", 0) + 1},\n",
    "        \"logs\": [f\"ä»»åŠ¡ {task_id} å·²åˆ›å»º\"],\n",
    "        \"system_status\": \"task_created\"\n",
    "    }\n",
    "\n",
    "def assign_task(state: TaskManagementState) -> dict:\n",
    "    \"\"\"åˆ†é…ä»»åŠ¡\"\"\"\n",
    "    current_task_id = state.get(\"current_task_id\")\n",
    "    \n",
    "    if not current_task_id:\n",
    "        return {\n",
    "            \"errors\": [\"æ²¡æœ‰å½“å‰ä»»åŠ¡å¯åˆ†é…\"],\n",
    "            \"system_status\": \"error\"\n",
    "        }\n",
    "    \n",
    "    # æ¨¡æ‹Ÿåˆ†é…\n",
    "    assignee = \"Agent-001\"\n",
    "    \n",
    "    print(f\"ğŸ‘¤ åˆ†é…ä»»åŠ¡ {current_task_id} ç»™ {assignee}\")\n",
    "    \n",
    "    return {\n",
    "        \"logs\": [f\"ä»»åŠ¡ {current_task_id} å·²åˆ†é…ç»™ {assignee}\"],\n",
    "        \"system_status\": \"task_assigned\"\n",
    "    }\n",
    "\n",
    "def process_task(state: TaskManagementState) -> dict:\n",
    "    \"\"\"å¤„ç†ä»»åŠ¡\"\"\"\n",
    "    current_task_id = state.get(\"current_task_id\")\n",
    "    \n",
    "    if not current_task_id:\n",
    "        return {\n",
    "            \"errors\": [\"æ²¡æœ‰å½“å‰ä»»åŠ¡å¯å¤„ç†\"],\n",
    "            \"system_status\": \"error\"\n",
    "        }\n",
    "    \n",
    "    print(f\"âš™ï¸ å¤„ç†ä»»åŠ¡ {current_task_id}\")\n",
    "    \n",
    "    # æ›´æ–°ç»Ÿè®¡\n",
    "    current_stats = state.get(\"stats\", {})\n",
    "    \n",
    "    return {\n",
    "        \"stats\": {\n",
    "            \"in_progress\": current_stats.get(\"in_progress\", 0) + 1,\n",
    "            \"pending\": max(0, current_stats.get(\"pending\", 0) - 1)\n",
    "        },\n",
    "        \"logs\": [f\"ä»»åŠ¡ {current_task_id} æ­£åœ¨å¤„ç†\"],\n",
    "        \"system_status\": \"processing\"\n",
    "    }\n",
    "\n",
    "def complete_task(state: TaskManagementState) -> dict:\n",
    "    \"\"\"å®Œæˆä»»åŠ¡\"\"\"\n",
    "    current_task_id = state.get(\"current_task_id\")\n",
    "    \n",
    "    if not current_task_id:\n",
    "        return {\n",
    "            \"errors\": [\"æ²¡æœ‰å½“å‰ä»»åŠ¡å¯å®Œæˆ\"],\n",
    "            \"system_status\": \"error\"\n",
    "        }\n",
    "    \n",
    "    print(f\"âœ”ï¸ å®Œæˆä»»åŠ¡ {current_task_id}\")\n",
    "    \n",
    "    # æ›´æ–°ç»Ÿè®¡\n",
    "    current_stats = state.get(\"stats\", {})\n",
    "    \n",
    "    return {\n",
    "        \"stats\": {\n",
    "            \"completed\": current_stats.get(\"completed\", 0) + 1,\n",
    "            \"in_progress\": max(0, current_stats.get(\"in_progress\", 0) - 1)\n",
    "        },\n",
    "        \"logs\": [f\"ä»»åŠ¡ {current_task_id} å·²å®Œæˆ\"],\n",
    "        \"current_task_id\": None,  # æ¸…ç©ºå½“å‰ä»»åŠ¡\n",
    "        \"system_status\": \"task_completed\"\n",
    "    }\n",
    "\n",
    "def generate_report(state: TaskManagementState) -> dict:\n",
    "    \"\"\"ç”ŸæˆæŠ¥å‘Š\"\"\"\n",
    "    stats = state.get(\"stats\", {})\n",
    "    logs = state.get(\"logs\", [])\n",
    "    \n",
    "    report = f\"\"\"\n",
    "    ğŸ“Š ä»»åŠ¡ç®¡ç†æŠ¥å‘Š\n",
    "    ================\n",
    "    æ€»ä»»åŠ¡æ•°: {stats.get('total', 0)}\n",
    "    å¾…å¤„ç†: {stats.get('pending', 0)}\n",
    "    è¿›è¡Œä¸­: {stats.get('in_progress', 0)}\n",
    "    å·²å®Œæˆ: {stats.get('completed', 0)}\n",
    "    \n",
    "    æœ€è¿‘æ“ä½œ:\n",
    "    {chr(10).join(f'  - {log}' for log in logs[-5:])}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(report)\n",
    "    \n",
    "    return {\n",
    "        \"logs\": [\"æŠ¥å‘Šå·²ç”Ÿæˆ\"],\n",
    "        \"system_status\": \"report_generated\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºä»»åŠ¡ç®¡ç†æµç¨‹\n",
    "task_graph.add_node(\"create\", create_task)\n",
    "task_graph.add_node(\"assign\", assign_task)\n",
    "task_graph.add_node(\"process\", process_task)\n",
    "task_graph.add_node(\"complete\", complete_task)\n",
    "task_graph.add_node(\"report\", generate_report)\n",
    "\n",
    "# å®šä¹‰æµç¨‹\n",
    "task_graph.set_entry_point(\"create\")\n",
    "task_graph.add_edge(\"create\", \"assign\")\n",
    "task_graph.add_edge(\"assign\", \"process\")\n",
    "task_graph.add_edge(\"process\", \"complete\")\n",
    "task_graph.add_edge(\"complete\", \"report\")\n",
    "task_graph.add_edge(\"report\", END)\n",
    "\n",
    "# ç¼–è¯‘\n",
    "task_app = task_graph.compile()\n",
    "\n",
    "# å¯è§†åŒ–\n",
    "try:\n",
    "    display(Image(task_app.get_graph().draw_mermaid_png()))\n",
    "except:\n",
    "    print(task_app.get_graph().draw_mermaid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰§è¡Œä»»åŠ¡ç®¡ç†æµç¨‹\n",
    "initial_task_state = {\n",
    "    \"tasks\": [],\n",
    "    \"current_task_id\": None,\n",
    "    \"stats\": {\"total\": 0, \"pending\": 0, \"in_progress\": 0, \"completed\": 0},\n",
    "    \"logs\": [\"ç³»ç»Ÿå¯åŠ¨\"],\n",
    "    \"errors\": [],\n",
    "    \"system_status\": \"ready\"\n",
    "}\n",
    "\n",
    "print(\"å¼€å§‹æ‰§è¡Œä»»åŠ¡ç®¡ç†æµç¨‹...\\n\")\n",
    "result = task_app.invoke(initial_task_state)\n",
    "\n",
    "print(\"\\næœ€ç»ˆçŠ¶æ€:\")\n",
    "print(f\"ç³»ç»ŸçŠ¶æ€: {result['system_status']}\")\n",
    "print(f\"ç»Ÿè®¡ä¿¡æ¯: {result['stats']}\")\n",
    "print(f\"é”™è¯¯æ•°é‡: {len(result['errors'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. å¹¶è¡ŒçŠ¶æ€æ›´æ–°\n",
    "\n",
    "StateGraph æ”¯æŒå¹¶è¡Œæ‰§è¡ŒèŠ‚ç‚¹å¹¶åˆå¹¶å®ƒä»¬çš„çŠ¶æ€æ›´æ–°ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰å¹¶è¡Œå¤„ç†çŠ¶æ€\n",
    "class ParallelState(TypedDict):\n",
    "    data: list[str]\n",
    "    results: Annotated[dict, lambda x, y: {**x, **y}]\n",
    "    processed_count: Annotated[int, operator.add]\n",
    "    timestamps: Annotated[list, operator.add]\n",
    "\n",
    "# åˆ›å»ºå¹¶è¡Œå¤„ç†å›¾\n",
    "parallel_graph = StateGraph(ParallelState)\n",
    "\n",
    "def processor_a(state: ParallelState) -> dict:\n",
    "    \"\"\"å¤„ç†å™¨ A\"\"\"\n",
    "    import time\n",
    "    time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "    \n",
    "    print(\"ğŸ…°ï¸ å¤„ç†å™¨ A æ‰§è¡Œ\")\n",
    "    \n",
    "    return {\n",
    "        \"results\": {\"processor_a\": \"å®Œæˆ\"},\n",
    "        \"processed_count\": 1,\n",
    "        \"timestamps\": [f\"A: {datetime.now().isoformat()}\"]\n",
    "    }\n",
    "\n",
    "def processor_b(state: ParallelState) -> dict:\n",
    "    \"\"\"å¤„ç†å™¨ B\"\"\"\n",
    "    import time\n",
    "    time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "    \n",
    "    print(\"ğŸ…±ï¸ å¤„ç†å™¨ B æ‰§è¡Œ\")\n",
    "    \n",
    "    return {\n",
    "        \"results\": {\"processor_b\": \"å®Œæˆ\"},\n",
    "        \"processed_count\": 1,\n",
    "        \"timestamps\": [f\"B: {datetime.now().isoformat()}\"]\n",
    "    }\n",
    "\n",
    "def processor_c(state: ParallelState) -> dict:\n",
    "    \"\"\"å¤„ç†å™¨ C\"\"\"\n",
    "    import time\n",
    "    time.sleep(0.1)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "    \n",
    "    print(\"Â©ï¸ å¤„ç†å™¨ C æ‰§è¡Œ\")\n",
    "    \n",
    "    return {\n",
    "        \"results\": {\"processor_c\": \"å®Œæˆ\"},\n",
    "        \"processed_count\": 1,\n",
    "        \"timestamps\": [f\"C: {datetime.now().isoformat()}\"]\n",
    "    }\n",
    "\n",
    "def merge_results(state: ParallelState) -> dict:\n",
    "    \"\"\"åˆå¹¶ç»“æœ\"\"\"\n",
    "    results = state.get(\"results\", {})\n",
    "    count = state.get(\"processed_count\", 0)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š åˆå¹¶ç»“æœ: å…±å¤„ç† {count} ä¸ªä»»åŠ¡\")\n",
    "    print(f\"ç»“æœ: {results}\")\n",
    "    \n",
    "    return {\n",
    "        \"results\": {\"final\": f\"åˆå¹¶äº† {len(results)} ä¸ªå¤„ç†å™¨çš„ç»“æœ\"}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ„å»ºå¹¶è¡Œå¤„ç†å›¾\n",
    "def router(state: ParallelState) -> list[str]:\n",
    "    \"\"\"è·¯ç”±åˆ°å¤šä¸ªå¤„ç†å™¨\"\"\"\n",
    "    return [\"processor_a\", \"processor_b\", \"processor_c\"]\n",
    "\n",
    "# æ·»åŠ èŠ‚ç‚¹\n",
    "parallel_graph.add_node(\"start\", lambda x: {\"data\": [\"å¼€å§‹å¤„ç†\"]})\n",
    "parallel_graph.add_node(\"processor_a\", processor_a)\n",
    "parallel_graph.add_node(\"processor_b\", processor_b)\n",
    "parallel_graph.add_node(\"processor_c\", processor_c)\n",
    "parallel_graph.add_node(\"merge\", merge_results)\n",
    "\n",
    "# è®¾ç½®å¹¶è¡Œè¾¹\n",
    "parallel_graph.set_entry_point(\"start\")\n",
    "parallel_graph.add_conditional_edges(\n",
    "    \"start\",\n",
    "    router,\n",
    "    {\n",
    "        \"processor_a\": \"processor_a\",\n",
    "        \"processor_b\": \"processor_b\",\n",
    "        \"processor_c\": \"processor_c\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# æ‰€æœ‰å¤„ç†å™¨éƒ½è¿æ¥åˆ°åˆå¹¶èŠ‚ç‚¹\n",
    "parallel_graph.add_edge(\"processor_a\", \"merge\")\n",
    "parallel_graph.add_edge(\"processor_b\", \"merge\")\n",
    "parallel_graph.add_edge(\"processor_c\", \"merge\")\n",
    "parallel_graph.add_edge(\"merge\", END)\n",
    "\n",
    "# ç¼–è¯‘\n",
    "parallel_app = parallel_graph.compile()\n",
    "\n",
    "# æ‰§è¡Œ\n",
    "print(\"å¼€å§‹å¹¶è¡Œå¤„ç†...\\n\")\n",
    "result = parallel_app.invoke({})\n",
    "\n",
    "print(\"\\næœ€ç»ˆç»“æœ:\")\n",
    "print(json.dumps(result, ensure_ascii=False, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ç»ƒä¹ é¢˜\n",
    "\n",
    "### ç»ƒä¹  1ï¼šå®ç°ä¸€ä¸ªå¸¦ä¼˜å…ˆçº§çš„ä»»åŠ¡é˜Ÿåˆ—\n",
    "åˆ›å»ºä¸€ä¸ª StateGraphï¼Œç®¡ç†å¸¦ä¼˜å…ˆçº§çš„ä»»åŠ¡é˜Ÿåˆ—ï¼Œé«˜ä¼˜å…ˆçº§ä»»åŠ¡ä¼˜å…ˆå¤„ç†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨è¿™é‡Œå®ç°ä½ çš„ä¼˜å…ˆçº§ä»»åŠ¡é˜Ÿåˆ—\n",
    "class PriorityTaskState(TypedDict):\n",
    "    # å®šä¹‰ä½ çš„çŠ¶æ€ç»“æ„\n",
    "    pass\n",
    "\n",
    "# åˆ›å»ºå¹¶æµ‹è¯•ä½ çš„å›¾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ç»ƒä¹  2ï¼šå®ç°çŠ¶æ€å›æ»šæœºåˆ¶\n",
    "åˆ›å»ºä¸€ä¸ªæ”¯æŒçŠ¶æ€å›æ»šçš„ StateGraphï¼Œå¯ä»¥æ’¤é”€æœ€è¿‘çš„æ“ä½œã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åœ¨è¿™é‡Œå®ç°çŠ¶æ€å›æ»šæœºåˆ¶\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "åœ¨æœ¬è¯¾ä¸­ï¼Œæˆ‘ä»¬æ·±å…¥å­¦ä¹ äº†ï¼š\n",
    "\n",
    "1. **StateGraph çš„åŸºç¡€ä½¿ç”¨**\n",
    "   - çŠ¶æ€å®šä¹‰å’Œç±»å‹æ³¨è§£\n",
    "   - èŠ‚ç‚¹å‡½æ•°çš„ç¼–å†™è§„èŒƒ\n",
    "\n",
    "2. **Reducer å‡½æ•°**\n",
    "   - å†…ç½® reducerï¼ˆoperator.add, max ç­‰ï¼‰\n",
    "   - è‡ªå®šä¹‰ reducer å‡½æ•°\n",
    "   - çŠ¶æ€åˆå¹¶ç­–ç•¥\n",
    "\n",
    "3. **æ¶ˆæ¯å¤„ç†**\n",
    "   - add_messages reducer\n",
    "   - æ¶ˆæ¯ç±»å‹ç³»ç»Ÿ\n",
    "\n",
    "4. **å¤æ‚çŠ¶æ€ç®¡ç†**\n",
    "   - ä»»åŠ¡ç®¡ç†ç³»ç»Ÿç¤ºä¾‹\n",
    "   - å¹¶è¡ŒçŠ¶æ€æ›´æ–°\n",
    "   - çŠ¶æ€ç»Ÿè®¡å’Œæ—¥å¿—\n",
    "\n",
    "5. **æœ€ä½³å®è·µ**\n",
    "   - ä½¿ç”¨ TypedDict å®šä¹‰æ¸…æ™°çš„çŠ¶æ€ç»“æ„\n",
    "   - åˆç†é€‰æ‹© reducer å‡½æ•°\n",
    "   - å¤„ç†é”™è¯¯å’Œè¾¹ç•Œæƒ…å†µ\n",
    "\n",
    "## ä¸‹ä¸€è¯¾é¢„å‘Š\n",
    "\n",
    "åœ¨ä¸‹ä¸€è¯¾ä¸­ï¼Œæˆ‘ä»¬å°†å­¦ä¹ ï¼š\n",
    "- æ¡ä»¶è¾¹çš„è¯¦ç»†ä½¿ç”¨\n",
    "- å¤æ‚çš„å†³ç­–é€»è¾‘å®ç°\n",
    "- å¤šè·¯å¾„é€‰æ‹©å’ŒåŠ¨æ€è·¯ç”±\n",
    "- å¾ªç¯å’Œé€’å½’ç»“æ„"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}