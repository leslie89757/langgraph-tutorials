{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10_é«˜çº§åº”ç”¨æ¡ˆä¾‹\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "- æŒæ¡LangGraphåœ¨å¤æ‚åº”ç”¨åœºæ™¯ä¸­çš„ä½¿ç”¨\n",
    "- å­¦ä¹ RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ç³»ç»Ÿçš„æ„å»º\n",
    "- ç†è§£å¤šAgentåä½œç³»ç»Ÿçš„è®¾è®¡\n",
    "- æŒæ¡ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å’Œæœ€ä½³å®è·µ\n",
    "- å­¦ä¹ æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†ç­–ç•¥\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "### RAGç³»ç»Ÿ\n",
    "æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generationï¼‰ç»“åˆäº†ä¿¡æ¯æ£€ç´¢å’Œæ–‡æœ¬ç”ŸæˆæŠ€æœ¯ã€‚\n",
    "\n",
    "### å¤šAgentç³»ç»Ÿ\n",
    "å¤šä¸ªæ™ºèƒ½Agentåä½œå®Œæˆå¤æ‚ä»»åŠ¡çš„åˆ†å¸ƒå¼ç³»ç»Ÿã€‚\n",
    "\n",
    "### å·¥ä½œæµç¼–æ’\n",
    "å¤æ‚ä¸šåŠ¡æµç¨‹çš„è‡ªåŠ¨åŒ–ç¼–æ’å’Œæ‰§è¡Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, Any, List, Optional, TypedDict, Callable\n",
    "from dataclasses import dataclass, asdict\n",
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.tools import Tool\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"ç¯å¢ƒè®¾ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. é«˜çº§RAGç³»ç»Ÿ\n",
    "\n",
    "### 1.1 æ™ºèƒ½æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”ç³»ç»Ÿ\n",
    "\n",
    "æœ¬èŠ‚å°†å±•ç¤ºå¦‚ä½•æ„å»ºä¸€ä¸ªå®Œæ•´çš„RAGç³»ç»Ÿï¼ŒåŒ…æ‹¬æ–‡æ¡£æ£€ç´¢ã€ä¸Šä¸‹æ–‡ç®¡ç†å’Œç­”æ¡ˆç”Ÿæˆã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡æ‹Ÿå‘é‡æ•°æ®åº“\n",
    "class MockVectorDB:\n",
    "    \"\"\"æ¨¡æ‹Ÿå‘é‡æ•°æ®åº“\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.embeddings = {}\n",
    "    \n",
    "    def add_documents(self, docs: List[Document]):\n",
    "        \"\"\"æ·»åŠ æ–‡æ¡£\"\"\"\n",
    "        for doc in docs:\n",
    "            doc_id = str(uuid.uuid4())\n",
    "            self.documents.append({\"id\": doc_id, \"content\": doc.page_content, \"metadata\": doc.metadata})\n",
    "            # æ¨¡æ‹Ÿå‘é‡åµŒå…¥\n",
    "            self.embeddings[doc_id] = np.random.rand(768)  # æ¨¡æ‹Ÿ768ç»´å‘é‡\n",
    "    \n",
    "    def similarity_search(self, query: str, k: int = 3) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ç›¸ä¼¼æ€§æœç´¢\"\"\"\n",
    "        # æ¨¡æ‹Ÿæœç´¢é€»è¾‘\n",
    "        query_words = set(query.lower().split())\n",
    "        results = []\n",
    "        \n",
    "        for doc in self.documents:\n",
    "            content_words = set(doc[\"content\"].lower().split())\n",
    "            # ç®€å•çš„è¯æ±‡é‡å ç›¸ä¼¼åº¦\n",
    "            similarity = len(query_words.intersection(content_words)) / len(query_words.union(content_words))\n",
    "            results.append({\"document\": doc, \"similarity\": similarity})\n",
    "        \n",
    "        # æŒ‰ç›¸ä¼¼åº¦æ’åºå¹¶è¿”å›å‰kä¸ª\n",
    "        results.sort(key=lambda x: x[\"similarity\"], reverse=True)\n",
    "        return [r[\"document\"] for r in results[:k]]\n",
    "\n",
    "# åˆ›å»ºçŸ¥è¯†åº“\n",
    "knowledge_base = MockVectorDB()\n",
    "\n",
    "# æ·»åŠ ç¤ºä¾‹æ–‡æ¡£\n",
    "sample_docs = [\n",
    "    Document(\n",
    "        page_content=\"LangGraphæ˜¯ä¸€ä¸ªç”¨äºæ„å»ºæœ‰çŠ¶æ€ã€å¤šå‚ä¸è€…åº”ç”¨ç¨‹åºçš„åº“ï¼ŒåŸºäºLangChainæ„å»ºã€‚å®ƒæ‰©å±•äº†LangChain Expression Languageï¼Œå¢åŠ äº†å¾ªç¯ã€æ¡ä»¶åˆ†æ”¯å’ŒæŒä¹…æ€§ç­‰åŠŸèƒ½ã€‚\",\n",
    "        metadata={\"source\": \"langgraph_intro.txt\", \"type\": \"documentation\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"StateGraphæ˜¯LangGraphçš„æ ¸å¿ƒç»„ä»¶ï¼Œå®ƒå…è®¸æ‚¨å®šä¹‰å…·æœ‰çŠ¶æ€çš„è®¡ç®—å›¾ã€‚æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨ä¸€ä¸ªè®¡ç®—æ­¥éª¤ï¼Œè¾¹å®šä¹‰äº†æ‰§è¡Œæµç¨‹ã€‚\",\n",
    "        metadata={\"source\": \"stategragh_guide.txt\", \"type\": \"tutorial\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"æ£€æŸ¥ç‚¹æœºåˆ¶å…è®¸LangGraphåº”ç”¨ç¨‹åºä¿å­˜å’Œæ¢å¤çŠ¶æ€ã€‚è¿™å¯¹äºæ„å»ºèƒ½å¤Ÿä»æ•…éšœä¸­æ¢å¤çš„å¼¹æ€§åº”ç”¨ç¨‹åºè‡³å…³é‡è¦ã€‚\",\n",
    "        metadata={\"source\": \"checkpoint_guide.txt\", \"type\": \"tutorial\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"å·¥å…·è°ƒç”¨æ˜¯ç°ä»£AIåº”ç”¨çš„æ ¸å¿ƒåŠŸèƒ½ã€‚LangGraphæä¾›äº†ToolNodeæ¥ç®€åŒ–å·¥å…·é›†æˆï¼Œæ”¯æŒå‡½æ•°è°ƒç”¨å’Œå¤–éƒ¨APIé›†æˆã€‚\",\n",
    "        metadata={\"source\": \"tools_guide.txt\", \"type\": \"tutorial\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"å¤šAgentç³»ç»Ÿå…è®¸å¤šä¸ªAIä»£ç†åä½œå®Œæˆå¤æ‚ä»»åŠ¡ã€‚æ¯ä¸ªAgentéƒ½æœ‰ä¸“é—¨çš„èŒè´£å’Œèƒ½åŠ›ï¼Œé€šè¿‡åè°ƒæœºåˆ¶å®ç°ç›®æ ‡ã€‚\",\n",
    "        metadata={\"source\": \"multi_agent.txt\", \"type\": \"advanced\"}\n",
    "    )\n",
    "]\n",
    "\n",
    "knowledge_base.add_documents(sample_docs)\n",
    "print(f\"çŸ¥è¯†åº“å·²åŠ è½½ {len(sample_docs)} ä¸ªæ–‡æ¡£\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 RAGå¤„ç†æµç¨‹\n",
    "\n",
    "å®šä¹‰RAGç³»ç»Ÿçš„æ ¸å¿ƒå¤„ç†æµç¨‹ï¼ŒåŒ…æ‹¬æ–‡æ¡£æ£€ç´¢ã€ç­”æ¡ˆç”Ÿæˆå’Œè´¨é‡éªŒè¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAGç³»ç»ŸçŠ¶æ€\n",
    "class RAGState(TypedDict):\n",
    "    query: str\n",
    "    retrieved_docs: List[Dict[str, Any]]\n",
    "    context: str\n",
    "    answer: str\n",
    "    confidence: float\n",
    "    sources: List[str]\n",
    "    processing_steps: List[str]\n",
    "\n",
    "class MockLLM:\n",
    "    \"\"\"æ¨¡æ‹Ÿå¤§è¯­è¨€æ¨¡å‹\"\"\"\n",
    "    \n",
    "    def generate_answer(self, context: str, query: str) -> Dict[str, Any]:\n",
    "        \"\"\"åŸºäºä¸Šä¸‹æ–‡ç”Ÿæˆç­”æ¡ˆ\"\"\"\n",
    "        # æ¨¡æ‹ŸLLMç”Ÿæˆç­”æ¡ˆ\n",
    "        if \"langgraph\" in query.lower():\n",
    "            answer = f\"æ ¹æ®æ£€ç´¢åˆ°çš„æ–‡æ¡£ï¼Œ{query}çš„ç­”æ¡ˆæ˜¯ï¼šLangGraphæ˜¯ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„åº“ï¼Œç”¨äºæ„å»ºæœ‰çŠ¶æ€çš„å¤šå‚ä¸è€…åº”ç”¨ç¨‹åºã€‚å®ƒåŸºäºLangChainæ„å»ºï¼Œæä¾›äº†å¾ªç¯ã€æ¡ä»¶åˆ†æ”¯å’ŒæŒä¹…æ€§ç­‰é«˜çº§åŠŸèƒ½ã€‚\"\n",
    "            confidence = 0.9\n",
    "        elif \"stategragh\" in query.lower() or \"çŠ¶æ€å›¾\" in query.lower():\n",
    "            answer = f\"å…³äº{query}ï¼šStateGraphæ˜¯LangGraphçš„æ ¸å¿ƒç»„ä»¶ï¼Œç”¨äºå®šä¹‰å…·æœ‰çŠ¶æ€çš„è®¡ç®—å›¾ã€‚æ¯ä¸ªèŠ‚ç‚¹ä»£è¡¨è®¡ç®—æ­¥éª¤ï¼Œè¾¹å®šä¹‰æ‰§è¡Œæµç¨‹ã€‚\"\n",
    "            confidence = 0.85\n",
    "        elif \"æ£€æŸ¥ç‚¹\" in query.lower() or \"checkpoint\" in query.lower():\n",
    "            answer = f\"é’ˆå¯¹{query}ï¼šæ£€æŸ¥ç‚¹æœºåˆ¶æ˜¯LangGraphçš„é‡è¦åŠŸèƒ½ï¼Œå…è®¸åº”ç”¨ç¨‹åºä¿å­˜å’Œæ¢å¤çŠ¶æ€ï¼Œæ„å»ºå¼¹æ€§åº”ç”¨ç¨‹åºã€‚\"\n",
    "            confidence = 0.8\n",
    "        else:\n",
    "            answer = f\"æ ¹æ®å¯ç”¨ä¿¡æ¯ï¼Œæˆ‘å¯¹{query}çš„ç†è§£æ˜¯ï¼šè¿™æ˜¯ä¸€ä¸ªå…³äºLangGraphç›¸å…³æŠ€æœ¯çš„é—®é¢˜ï¼Œå»ºè®®æŸ¥é˜…æ›´å¤šå…·ä½“æ–‡æ¡£ã€‚\"\n",
    "            confidence = 0.6\n",
    "        \n",
    "        return {\"answer\": answer, \"confidence\": confidence}\n",
    "\n",
    "# åˆ›å»ºæ¨¡æ‹ŸLLMå®ä¾‹\n",
    "llm = MockLLM()\n",
    "\n",
    "def document_retrieval_node(state: RAGState) -> RAGState:\n",
    "    \"\"\"æ–‡æ¡£æ£€ç´¢èŠ‚ç‚¹\"\"\"\n",
    "    query = state[\"query\"]\n",
    "    state[\"processing_steps\"].append(f\"æ­£åœ¨æ£€ç´¢ä¸æŸ¥è¯¢ '{query}' ç›¸å…³çš„æ–‡æ¡£\")\n",
    "    \n",
    "    # ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³æ–‡æ¡£\n",
    "    retrieved_docs = knowledge_base.similarity_search(query, k=3)\n",
    "    state[\"retrieved_docs\"] = retrieved_docs\n",
    "    \n",
    "    # æ„å»ºä¸Šä¸‹æ–‡\n",
    "    context_parts = []\n",
    "    sources = []\n",
    "    \n",
    "    for i, doc in enumerate(retrieved_docs, 1):\n",
    "        context_parts.append(f\"æ–‡æ¡£{i}: {doc['content']}\")\n",
    "        sources.append(doc['metadata']['source'])\n",
    "    \n",
    "    state[\"context\"] = \"\\n\\n\".join(context_parts)\n",
    "    state[\"sources\"] = sources\n",
    "    state[\"processing_steps\"].append(f\"æ£€ç´¢åˆ° {len(retrieved_docs)} ä¸ªç›¸å…³æ–‡æ¡£\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def answer_generation_node(state: RAGState) -> RAGState:\n",
    "    \"\"\"ç­”æ¡ˆç”ŸæˆèŠ‚ç‚¹\"\"\"\n",
    "    state[\"processing_steps\"].append(\"æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ\")\n",
    "    \n",
    "    context = state[\"context\"]\n",
    "    query = state[\"query\"]\n",
    "    \n",
    "    # ä½¿ç”¨LLMç”Ÿæˆç­”æ¡ˆ\n",
    "    result = llm.generate_answer(context, query)\n",
    "    \n",
    "    state[\"answer\"] = result[\"answer\"]\n",
    "    state[\"confidence\"] = result[\"confidence\"]\n",
    "    state[\"processing_steps\"].append(f\"ç­”æ¡ˆç”Ÿæˆå®Œæˆï¼Œç½®ä¿¡åº¦: {result['confidence']:.2f}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def answer_validation_node(state: RAGState) -> RAGState:\n",
    "    \"\"\"ç­”æ¡ˆéªŒè¯èŠ‚ç‚¹\"\"\"\n",
    "    state[\"processing_steps\"].append(\"æ­£åœ¨éªŒè¯ç­”æ¡ˆè´¨é‡\")\n",
    "    \n",
    "    confidence = state[\"confidence\"]\n",
    "    answer = state[\"answer\"]\n",
    "    \n",
    "    # ç®€å•çš„ç­”æ¡ˆè´¨é‡æ£€æŸ¥\n",
    "    if confidence < 0.7:\n",
    "        state[\"answer\"] = f\"æ³¨æ„ï¼šç­”æ¡ˆç½®ä¿¡åº¦è¾ƒä½({confidence:.2f})ã€‚{answer}\\n\\nå»ºè®®ï¼šè¯·æä¾›æ›´å…·ä½“çš„é—®é¢˜ä»¥è·å¾—æ›´å‡†ç¡®çš„ç­”æ¡ˆã€‚\"\n",
    "        state[\"processing_steps\"].append(\"æ£€æµ‹åˆ°ä½ç½®ä¿¡åº¦ç­”æ¡ˆï¼Œå·²æ·»åŠ è­¦å‘Šä¿¡æ¯\")\n",
    "    \n",
    "    if len(answer) < 50:\n",
    "        state[\"answer\"] = f\"{answer}\\n\\nè¡¥å……è¯´æ˜ï¼šå¦‚éœ€æ›´è¯¦ç»†ä¿¡æ¯ï¼Œè¯·æŸ¥é˜…ç›¸å…³æ–‡æ¡£æˆ–æå‡ºæ›´å…·ä½“çš„é—®é¢˜ã€‚\"\n",
    "        state[\"processing_steps\"].append(\"ç­”æ¡ˆè¾ƒçŸ­ï¼Œå·²æ·»åŠ è¡¥å……è¯´æ˜\")\n",
    "    \n",
    "    state[\"processing_steps\"].append(\"ç­”æ¡ˆéªŒè¯å®Œæˆ\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# åˆ›å»ºRAGå·¥ä½œæµ\n",
    "rag_workflow = StateGraph(RAGState)\n",
    "rag_workflow.add_node(\"retrieve\", document_retrieval_node)\n",
    "rag_workflow.add_node(\"generate\", answer_generation_node)\n",
    "rag_workflow.add_node(\"validate\", answer_validation_node)\n",
    "\n",
    "rag_workflow.add_edge(START, \"retrieve\")\n",
    "rag_workflow.add_edge(\"retrieve\", \"generate\")\n",
    "rag_workflow.add_edge(\"generate\", \"validate\")\n",
    "rag_workflow.add_edge(\"validate\", END)\n",
    "\n",
    "rag_app = rag_workflow.compile()\n",
    "\n",
    "print(\"RAGç³»ç»Ÿåˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 æµ‹è¯•RAGç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rag_system(queries: List[str]):\n",
    "    \"\"\"æµ‹è¯•RAGç³»ç»Ÿ\"\"\"\n",
    "    for query in queries:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"æŸ¥è¯¢: {query}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # åˆ›å»ºåˆå§‹çŠ¶æ€\n",
    "        initial_state = {\n",
    "            \"query\": query,\n",
    "            \"retrieved_docs\": [],\n",
    "            \"context\": \"\",\n",
    "            \"answer\": \"\",\n",
    "            \"confidence\": 0.0,\n",
    "            \"sources\": [],\n",
    "            \"processing_steps\": []\n",
    "        }\n",
    "        \n",
    "        # æ‰§è¡ŒRAGæµç¨‹\n",
    "        result = rag_app.invoke(initial_state)\n",
    "        \n",
    "        # æ˜¾ç¤ºç»“æœ\n",
    "        print(\"\\nğŸ” å¤„ç†æ­¥éª¤:\")\n",
    "        for step in result[\"processing_steps\"]:\n",
    "            print(f\"  â€¢ {step}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“š æ£€ç´¢åˆ°çš„æ–‡æ¡£æ•°é‡: {len(result['retrieved_docs'])}\")\n",
    "        print(f\"ğŸ“„ å‚è€ƒæ¥æº: {', '.join(result['sources'])}\")\n",
    "        print(f\"ğŸ¯ ç½®ä¿¡åº¦: {result['confidence']:.2f}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¬ ç­”æ¡ˆ:\")\n",
    "        print(result[\"answer\"])\n",
    "        \n",
    "        print(f\"\\nğŸ“‹ æ£€ç´¢çš„æ–‡æ¡£å†…å®¹:\")\n",
    "        for i, doc in enumerate(result[\"retrieved_docs\"], 1):\n",
    "            print(f\"  {i}. [{doc['metadata']['source']}] {doc['content'][:100]}...\")\n",
    "\n",
    "# æµ‹è¯•æŸ¥è¯¢\n",
    "test_queries = [\n",
    "    \"ä»€ä¹ˆæ˜¯LangGraphï¼Ÿ\",\n",
    "    \"StateGraphå¦‚ä½•å·¥ä½œï¼Ÿ\",\n",
    "    \"æ£€æŸ¥ç‚¹æœºåˆ¶æœ‰ä»€ä¹ˆç”¨ï¼Ÿ\",\n",
    "    \"å¦‚ä½•å®ç°å¤šAgentåä½œï¼Ÿ\"\n",
    "]\n",
    "\n",
    "test_rag_system(test_queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å¤šAgentåä½œç³»ç»Ÿ\n",
    "\n",
    "### 2.1 æ™ºèƒ½å®¢æœç³»ç»Ÿ\n",
    "\n",
    "æœ¬èŠ‚å±•ç¤ºå¦‚ä½•æ„å»ºä¸€ä¸ªå¤šAgentåä½œçš„æ™ºèƒ½å®¢æœç³»ç»Ÿï¼Œä¸åŒçš„Agentè´Ÿè´£å¤„ç†ä¸åŒç±»å‹çš„å®¢æˆ·è¯·æ±‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CustomerRequest:\n",
    "    \"\"\"å®¢æˆ·è¯·æ±‚\"\"\"\n",
    "    request_id: str\n",
    "    customer_id: str\n",
    "    category: str\n",
    "    priority: str\n",
    "    content: str\n",
    "    timestamp: str\n",
    "    status: str = \"pending\"\n",
    "    assigned_agent: Optional[str] = None\n",
    "    resolution: Optional[str] = None\n",
    "\n",
    "@dataclass\n",
    "class Agent:\n",
    "    \"\"\"AgentåŸºç±»\"\"\"\n",
    "    agent_id: str\n",
    "    name: str\n",
    "    specialization: List[str]\n",
    "    availability: bool = True\n",
    "    current_load: int = 0\n",
    "    max_load: int = 3\n",
    "\n",
    "# å®šä¹‰ä¸åŒç±»å‹çš„Agent\n",
    "class TechnicalSupportAgent(Agent):\n",
    "    \"\"\"æŠ€æœ¯æ”¯æŒAgent\"\"\"\n",
    "    \n",
    "    def handle_request(self, request: CustomerRequest) -> Dict[str, Any]:\n",
    "        \"\"\"å¤„ç†æŠ€æœ¯æ”¯æŒè¯·æ±‚\"\"\"\n",
    "        if \"ç™»å½•\" in request.content or \"å¯†ç \" in request.content:\n",
    "            resolution = \"è¯·å°è¯•ä»¥ä¸‹æ­¥éª¤ï¼š1) æ¸…é™¤æµè§ˆå™¨ç¼“å­˜ 2) é‡ç½®å¯†ç  3) æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚å¦‚é—®é¢˜æŒç»­å­˜åœ¨ï¼Œè¯·è”ç³»ç³»ç»Ÿç®¡ç†å‘˜ã€‚\"\n",
    "            confidence = 0.9\n",
    "        elif \"é”™è¯¯\" in request.content or \"bug\" in request.content.lower():\n",
    "            resolution = \"æˆ‘ä»¬å·²è®°å½•æ­¤é”™è¯¯æŠ¥å‘Šã€‚æŠ€æœ¯å›¢é˜Ÿå°†åœ¨24å°æ—¶å†…è°ƒæŸ¥å¹¶æä¾›è§£å†³æ–¹æ¡ˆã€‚æ„Ÿè°¢æ‚¨çš„åé¦ˆã€‚\"\n",
    "            confidence = 0.8\n",
    "        elif \"æ€§èƒ½\" in request.content or \"æ…¢\" in request.content:\n",
    "            resolution = \"æ€§èƒ½é—®é¢˜å¯èƒ½ç”±å¤šç§å› ç´ å¼•èµ·ã€‚å»ºè®®ï¼š1) å…³é—­ä¸å¿…è¦çš„åº”ç”¨ç¨‹åº 2) æ£€æŸ¥ç½‘ç»œé€Ÿåº¦ 3) æ¸…ç†ç³»ç»Ÿåƒåœ¾æ–‡ä»¶ã€‚\"\n",
    "            confidence = 0.85\n",
    "        else:\n",
    "            resolution = \"æ‚¨çš„æŠ€æœ¯é—®é¢˜å·²æ”¶åˆ°ã€‚æˆ‘ä»¬çš„ä¸“å®¶å›¢é˜Ÿå°†è¯¦ç»†åˆ†æå¹¶åœ¨2ä¸ªå·¥ä½œæ—¥å†…å›å¤æ‚¨ã€‚\"\n",
    "            confidence = 0.7\n",
    "        \n",
    "        return {\n",
    "            \"resolution\": resolution,\n",
    "            \"confidence\": confidence,\n",
    "            \"estimated_time\": \"2-24å°æ—¶\",\n",
    "            \"follow_up_needed\": confidence < 0.8\n",
    "        }\n",
    "\n",
    "class BillingAgent(Agent):\n",
    "    \"\"\"è´¦å•Agent\"\"\"\n",
    "    \n",
    "    def handle_request(self, request: CustomerRequest) -> Dict[str, Any]:\n",
    "        \"\"\"å¤„ç†è´¦å•ç›¸å…³è¯·æ±‚\"\"\"\n",
    "        if \"å‘ç¥¨\" in request.content or \"è´¦å•\" in request.content:\n",
    "            resolution = \"æ‚¨çš„è´¦å•ä¿¡æ¯å·²å‘é€è‡³æ³¨å†Œé‚®ç®±ã€‚å¦‚æœªæ”¶åˆ°ï¼Œè¯·æ£€æŸ¥åƒåœ¾é‚®ä»¶æ–‡ä»¶å¤¹æˆ–è”ç³»æˆ‘ä»¬é‡æ–°å‘é€ã€‚\"\n",
    "            confidence = 0.95\n",
    "        elif \"ä»˜æ¬¾\" in request.content or \"æ”¯ä»˜\" in request.content:\n",
    "            resolution = \"æˆ‘ä»¬æ”¯æŒå¤šç§æ”¯ä»˜æ–¹å¼ï¼šä¿¡ç”¨å¡ã€é“¶è¡Œè½¬è´¦ã€æ”¯ä»˜å®ã€å¾®ä¿¡æ”¯ä»˜ã€‚ä»˜æ¬¾åé€šå¸¸1-3ä¸ªå·¥ä½œæ—¥åˆ°è´¦ã€‚\"\n",
    "            confidence = 0.9\n",
    "        elif \"é€€æ¬¾\" in request.content:\n",
    "            resolution = \"é€€æ¬¾ç”³è¯·å·²æäº¤è‡³è´¢åŠ¡éƒ¨é—¨ã€‚æ ¹æ®æ”¯ä»˜æ–¹å¼ï¼Œé€€æ¬¾å°†åœ¨5-10ä¸ªå·¥ä½œæ—¥å†…å¤„ç†å®Œæˆã€‚\"\n",
    "            confidence = 0.85\n",
    "        else:\n",
    "            resolution = \"æ‚¨çš„è´¦å•ç›¸å…³é—®é¢˜å·²æ”¶åˆ°ã€‚æˆ‘ä»¬çš„è´¢åŠ¡å›¢é˜Ÿå°†åœ¨1ä¸ªå·¥ä½œæ—¥å†…ä¸ºæ‚¨æ ¸å®å¹¶å›å¤ã€‚\"\n",
    "            confidence = 0.8\n",
    "        \n",
    "        return {\n",
    "            \"resolution\": resolution,\n",
    "            \"confidence\": confidence,\n",
    "            \"estimated_time\": \"1-5ä¸ªå·¥ä½œæ—¥\",\n",
    "            \"follow_up_needed\": \"é€€æ¬¾\" in request.content\n",
    "        }\n",
    "\n",
    "class GeneralInquiryAgent(Agent):\n",
    "    \"\"\"ä¸€èˆ¬å’¨è¯¢Agent\"\"\"\n",
    "    \n",
    "    def handle_request(self, request: CustomerRequest) -> Dict[str, Any]:\n",
    "        \"\"\"å¤„ç†ä¸€èˆ¬å’¨è¯¢\"\"\"\n",
    "        if \"äº§å“\" in request.content or \"åŠŸèƒ½\" in request.content:\n",
    "            resolution = \"æ„Ÿè°¢æ‚¨å¯¹æˆ‘ä»¬äº§å“çš„å…³æ³¨ã€‚æˆ‘ä»¬çš„äº§å“åŠŸèƒ½ä¸°å¯Œï¼ŒåŒ…æ‹¬æ ¸å¿ƒåŠŸèƒ½Aã€Bã€Cã€‚å¦‚éœ€è¯¦ç»†äº†è§£ï¼Œå»ºè®®é¢„çº¦äº§å“æ¼”ç¤ºã€‚\"\n",
    "            confidence = 0.8\n",
    "        elif \"ä»·æ ¼\" in request.content or \"è´¹ç”¨\" in request.content:\n",
    "            resolution = \"æˆ‘ä»¬æä¾›å¤šç§å¥—é¤é€‰æ‹©ï¼šåŸºç¡€ç‰ˆã€ä¸“ä¸šç‰ˆã€ä¼ä¸šç‰ˆã€‚å…·ä½“ä»·æ ¼å› åŠŸèƒ½å’Œä½¿ç”¨é‡è€Œå¼‚ï¼Œå»ºè®®è”ç³»é”€å”®é¡¾é—®è·å–å®šåˆ¶æŠ¥ä»·ã€‚\"\n",
    "            confidence = 0.85\n",
    "        elif \"åˆä½œ\" in request.content or \"åˆåŒ\" in request.content:\n",
    "            resolution = \"æ„Ÿè°¢æ‚¨çš„åˆä½œæ„å‘ã€‚æˆ‘ä»¬çš„å•†åŠ¡å›¢é˜Ÿå°†è”ç³»æ‚¨è®¨è®ºå…·ä½“åˆä½œæ–¹æ¡ˆå’Œæ¡æ¬¾ã€‚\"\n",
    "            confidence = 0.9\n",
    "        else:\n",
    "            resolution = \"è°¢è°¢æ‚¨çš„å’¨è¯¢ã€‚æˆ‘ä»¬å·²æ”¶åˆ°æ‚¨çš„é—®é¢˜ï¼Œå®¢æœä»£è¡¨å°†åœ¨4å°æ—¶å†…ä¸æ‚¨è”ç³»ã€‚\"\n",
    "            confidence = 0.75\n",
    "        \n",
    "        return {\n",
    "            \"resolution\": resolution,\n",
    "            \"confidence\": confidence,\n",
    "            \"estimated_time\": \"4å°æ—¶å†…\",\n",
    "            \"follow_up_needed\": confidence < 0.8\n",
    "        }\n",
    "\n",
    "print(\"å¤šAgentç³»ç»Ÿç±»å®šä¹‰å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 å¤šAgentåä½œå·¥ä½œæµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºAgentå®ä¾‹\n",
    "agents = {\n",
    "    \"tech_support\": TechnicalSupportAgent(\n",
    "        agent_id=\"tech_001\",\n",
    "        name=\"æŠ€æœ¯æ”¯æŒä¸“å®¶\",\n",
    "        specialization=[\"technical\", \"bug\", \"performance\"]\n",
    "    ),\n",
    "    \"billing\": BillingAgent(\n",
    "        agent_id=\"billing_001\",\n",
    "        name=\"è´¦å•ä¸“å‘˜\",\n",
    "        specialization=[\"billing\", \"payment\", \"invoice\"]\n",
    "    ),\n",
    "    \"general\": GeneralInquiryAgent(\n",
    "        agent_id=\"general_001\",\n",
    "        name=\"å®¢æœä»£è¡¨\",\n",
    "        specialization=[\"general\", \"inquiry\", \"product\"]\n",
    "    )\n",
    "}\n",
    "\n",
    "# å¤šAgentç³»ç»ŸçŠ¶æ€\n",
    "class MultiAgentState(TypedDict):\n",
    "    request: CustomerRequest\n",
    "    assigned_agent_type: Optional[str]\n",
    "    agent_response: Optional[Dict[str, Any]]\n",
    "    escalation_needed: bool\n",
    "    processing_log: List[str]\n",
    "    final_resolution: Optional[str]\n",
    "\n",
    "def request_classifier_node(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"è¯·æ±‚åˆ†ç±»èŠ‚ç‚¹\"\"\"\n",
    "    request = state[\"request\"]\n",
    "    content = request.content.lower()\n",
    "    \n",
    "    state[\"processing_log\"].append(f\"å¼€å§‹åˆ†ç±»è¯·æ±‚: {request.request_id}\")\n",
    "    \n",
    "    # åŸºäºå…³é”®è¯åˆ†ç±»\n",
    "    if any(keyword in content for keyword in [\"é”™è¯¯\", \"bug\", \"ç™»å½•\", \"å¯†ç \", \"æ€§èƒ½\", \"æ…¢\"]):\n",
    "        agent_type = \"tech_support\"\n",
    "        request.category = \"technical\"\n",
    "    elif any(keyword in content for keyword in [\"è´¦å•\", \"å‘ç¥¨\", \"ä»˜æ¬¾\", \"æ”¯ä»˜\", \"é€€æ¬¾\"]):\n",
    "        agent_type = \"billing\"\n",
    "        request.category = \"billing\"\n",
    "    else:\n",
    "        agent_type = \"general\"\n",
    "        request.category = \"general\"\n",
    "    \n",
    "    # è®¾ç½®ä¼˜å…ˆçº§\n",
    "    if any(keyword in content for keyword in [\"ç´§æ€¥\", \"ä¸¥é‡\", \"æ— æ³•ä½¿ç”¨\"]):\n",
    "        request.priority = \"high\"\n",
    "    elif any(keyword in content for keyword in [\"é‡è¦\", \"å°½å¿«\"]):\n",
    "        request.priority = \"medium\"\n",
    "    else:\n",
    "        request.priority = \"low\"\n",
    "    \n",
    "    state[\"assigned_agent_type\"] = agent_type\n",
    "    state[\"processing_log\"].append(f\"è¯·æ±‚åˆ†ç±»ä¸º: {request.category}, ä¼˜å…ˆçº§: {request.priority}, åˆ†é…ç»™: {agent_type}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def agent_processing_node(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"Agentå¤„ç†èŠ‚ç‚¹\"\"\"\n",
    "    request = state[\"request\"]\n",
    "    agent_type = state[\"assigned_agent_type\"]\n",
    "    \n",
    "    state[\"processing_log\"].append(f\"Agent {agent_type} å¼€å§‹å¤„ç†è¯·æ±‚\")\n",
    "    \n",
    "    # è·å–å¯¹åº”çš„Agent\n",
    "    agent = agents[agent_type]\n",
    "    \n",
    "    # æ£€æŸ¥Agentå¯ç”¨æ€§\n",
    "    if agent.current_load >= agent.max_load:\n",
    "        state[\"processing_log\"].append(f\"Agent {agent_type} è´Ÿè½½å·²æ»¡ï¼Œè¯·æ±‚åŠ å…¥é˜Ÿåˆ—\")\n",
    "        # åœ¨å®é™…ç³»ç»Ÿä¸­ï¼Œè¿™é‡Œä¼šæœ‰é˜Ÿåˆ—ç®¡ç†é€»è¾‘\n",
    "        agent_response = {\n",
    "            \"resolution\": \"å½“å‰å’¨è¯¢é‡è¾ƒå¤§ï¼Œæ‚¨çš„è¯·æ±‚å·²åŠ å…¥é˜Ÿåˆ—ï¼Œæˆ‘ä»¬ä¼šå°½å¿«ä¸ºæ‚¨å¤„ç†ã€‚\",\n",
    "            \"confidence\": 0.6,\n",
    "            \"estimated_time\": \"1-2å°æ—¶\",\n",
    "            \"follow_up_needed\": True\n",
    "        }\n",
    "    else:\n",
    "        # Agentå¤„ç†è¯·æ±‚\n",
    "        agent.current_load += 1\n",
    "        agent_response = agent.handle_request(request)\n",
    "        agent.current_load -= 1\n",
    "        \n",
    "        state[\"processing_log\"].append(f\"Agentå¤„ç†å®Œæˆï¼Œç½®ä¿¡åº¦: {agent_response['confidence']}\")\n",
    "    \n",
    "    state[\"agent_response\"] = agent_response\n",
    "    request.assigned_agent = agent.agent_id\n",
    "    request.status = \"processed\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "def quality_assurance_node(state: MultiAgentState) -> MultiAgentState:\n",
    "    \"\"\"è´¨é‡ä¿è¯èŠ‚ç‚¹\"\"\"\n",
    "    agent_response = state[\"agent_response\"]\n",
    "    request = state[\"request\"]\n",
    "    \n",
    "    state[\"processing_log\"].append(\"å¼€å§‹è´¨é‡æ£€æŸ¥\")\n",
    "    \n",
    "    # è´¨é‡æ£€æŸ¥é€»è¾‘\n",
    "    confidence = agent_response[\"confidence\"]\n",
    "    follow_up_needed = agent_response[\"follow_up_needed\"]\n",
    "    \n",
    "    if confidence < 0.7 or follow_up_needed or request.priority == \"high\":\n",
    "        state[\"escalation_needed\"] = True\n",
    "        state[\"processing_log\"].append(\"éœ€è¦å‡çº§å¤„ç†\")\n",
    "        \n",
    "        # æ·»åŠ å‡çº§å¤„ç†ä¿¡æ¯\n",
    "        escalation_note = \"\\n\\n[ç³»ç»Ÿæé†’] æ­¤é—®é¢˜å·²å‡çº§è‡³ä¸“ä¸šå›¢é˜Ÿï¼Œæˆ‘ä»¬ä¼šå®‰æ’èµ„æ·±ä¸“å®¶è·Ÿè¿›å¤„ç†ã€‚\"\n",
    "        final_resolution = agent_response[\"resolution\"] + escalation_note\n",
    "    else:\n",
    "        state[\"escalation_needed\"] = False\n",
    "        final_resolution = agent_response[\"resolution\"]\n",
    "        state[\"processing_log\"].append(\"è´¨é‡æ£€æŸ¥é€šè¿‡\")\n",
    "    \n",
    "    state[\"final_resolution\"] = final_resolution\n",
    "    request.resolution = final_resolution\n",
    "    request.status = \"resolved\" if not state[\"escalation_needed\"] else \"escalated\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "# åˆ›å»ºå¤šAgentå·¥ä½œæµ\n",
    "multi_agent_workflow = StateGraph(MultiAgentState)\n",
    "multi_agent_workflow.add_node(\"classify\", request_classifier_node)\n",
    "multi_agent_workflow.add_node(\"process\", agent_processing_node)\n",
    "multi_agent_workflow.add_node(\"qa\", quality_assurance_node)\n",
    "\n",
    "multi_agent_workflow.add_edge(START, \"classify\")\n",
    "multi_agent_workflow.add_edge(\"classify\", \"process\")\n",
    "multi_agent_workflow.add_edge(\"process\", \"qa\")\n",
    "multi_agent_workflow.add_edge(\"qa\", END)\n",
    "\n",
    "multi_agent_app = multi_agent_workflow.compile()\n",
    "\n",
    "print(\"å¤šAgentå®¢æœç³»ç»Ÿåˆ›å»ºå®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 æµ‹è¯•å¤šAgentç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multi_agent_system():\n",
    "    \"\"\"æµ‹è¯•å¤šAgentç³»ç»Ÿ\"\"\"\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•è¯·æ±‚\n",
    "    test_requests = [\n",
    "        CustomerRequest(\n",
    "            request_id=\"REQ001\",\n",
    "            customer_id=\"CUST001\",\n",
    "            category=\"\",\n",
    "            priority=\"\",\n",
    "            content=\"æˆ‘æ— æ³•ç™»å½•ç³»ç»Ÿï¼Œæ€»æ˜¯æ˜¾ç¤ºå¯†ç é”™è¯¯ï¼Œè¿™å¾ˆç´§æ€¥ï¼\",\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        ),\n",
    "        CustomerRequest(\n",
    "            request_id=\"REQ002\",\n",
    "            customer_id=\"CUST002\",\n",
    "            category=\"\",\n",
    "            priority=\"\",\n",
    "            content=\"æˆ‘éœ€è¦è¿™ä¸ªæœˆçš„å‘ç¥¨ï¼Œè¯·å‘é€åˆ°æˆ‘çš„é‚®ç®±\",\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        ),\n",
    "        CustomerRequest(\n",
    "            request_id=\"REQ003\",\n",
    "            customer_id=\"CUST003\",\n",
    "            category=\"\",\n",
    "            priority=\"\",\n",
    "            content=\"è¯·é—®ä½ ä»¬çš„äº§å“æœ‰å“ªäº›åŠŸèƒ½ï¼Ÿä»·æ ¼å¦‚ä½•ï¼Ÿ\",\n",
    "            timestamp=datetime.now().isoformat()\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    for request in test_requests:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"å¤„ç†å®¢æˆ·è¯·æ±‚: {request.request_id}\")\n",
    "        print(f\"å®¢æˆ·ID: {request.customer_id}\")\n",
    "        print(f\"è¯·æ±‚å†…å®¹: {request.content}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        \n",
    "        # åˆ›å»ºåˆå§‹çŠ¶æ€\n",
    "        initial_state = {\n",
    "            \"request\": request,\n",
    "            \"assigned_agent_type\": None,\n",
    "            \"agent_response\": None,\n",
    "            \"escalation_needed\": False,\n",
    "            \"processing_log\": [],\n",
    "            \"final_resolution\": None\n",
    "        }\n",
    "        \n",
    "        # æ‰§è¡Œå¤šAgentå¤„ç†æµç¨‹\n",
    "        result = multi_agent_app.invoke(initial_state)\n",
    "        \n",
    "        # æ˜¾ç¤ºå¤„ç†ç»“æœ\n",
    "        print(\"\\nğŸ“‹ å¤„ç†æµç¨‹:\")\n",
    "        for log in result[\"processing_log\"]:\n",
    "            print(f\"  â€¢ {log}\")\n",
    "        \n",
    "        processed_request = result[\"request\"]\n",
    "        agent_response = result[\"agent_response\"]\n",
    "        \n",
    "        print(f\"\\nğŸ·ï¸  åˆ†ç±»ç»“æœ: {processed_request.category}\")\n",
    "        print(f\"âš¡ ä¼˜å…ˆçº§: {processed_request.priority}\")\n",
    "        print(f\"ğŸ‘¤ åˆ†é…Agent: {result['assigned_agent_type']}\")\n",
    "        print(f\"ğŸ“Š ç½®ä¿¡åº¦: {agent_response['confidence']:.2f}\")\n",
    "        print(f\"â±ï¸  é¢„è®¡å¤„ç†æ—¶é—´: {agent_response['estimated_time']}\")\n",
    "        print(f\"ğŸ”„ æ˜¯å¦éœ€è¦å‡çº§: {'æ˜¯' if result['escalation_needed'] else 'å¦'}\")\n",
    "        print(f\"âœ… æœ€ç»ˆçŠ¶æ€: {processed_request.status}\")\n",
    "        \n",
    "        print(f\"\\nğŸ’¬ å®¢æœå›å¤:\")\n",
    "        print(result[\"final_resolution\"])\n",
    "\n",
    "# è¿è¡Œæµ‹è¯•\n",
    "test_multi_agent_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µ\n",
    "\n",
    "### 3.1 é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import random\n",
    "from enum import Enum\n",
    "\n",
    "class RetryPolicy(Enum):\n",
    "    \"\"\"é‡è¯•ç­–ç•¥\"\"\"\n",
    "    NO_RETRY = \"no_retry\"\n",
    "    FIXED_DELAY = \"fixed_delay\"\n",
    "    EXPONENTIAL_BACKOFF = \"exponential_backoff\"\n",
    "\n",
    "@dataclass\n",
    "class RetryConfig:\n",
    "    \"\"\"é‡è¯•é…ç½®\"\"\"\n",
    "    max_attempts: int = 3\n",
    "    base_delay: float = 1.0\n",
    "    max_delay: float = 60.0\n",
    "    policy: RetryPolicy = RetryPolicy.EXPONENTIAL_BACKOFF\n",
    "\n",
    "def with_retry(retry_config: RetryConfig):\n",
    "    \"\"\"é‡è¯•è£…é¥°å™¨\"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(*args, **kwargs):\n",
    "            last_exception = None\n",
    "            \n",
    "            for attempt in range(retry_config.max_attempts):\n",
    "                try:\n",
    "                    return func(*args, **kwargs)\n",
    "                except Exception as e:\n",
    "                    last_exception = e\n",
    "                    \n",
    "                    # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼ŒæŠ›å‡ºå¼‚å¸¸\n",
    "                    if attempt == retry_config.max_attempts - 1:\n",
    "                        break\n",
    "                    \n",
    "                    # è®¡ç®—å»¶è¿Ÿæ—¶é—´\n",
    "                    if retry_config.policy == RetryPolicy.FIXED_DELAY:\n",
    "                        delay = retry_config.base_delay\n",
    "                    elif retry_config.policy == RetryPolicy.EXPONENTIAL_BACKOFF:\n",
    "                        delay = min(retry_config.base_delay * (2 ** attempt), retry_config.max_delay)\n",
    "                    else:\n",
    "                        delay = 0\n",
    "                    \n",
    "                    print(f\"å°è¯• {attempt + 1} å¤±è´¥: {str(e)}, {delay}ç§’åé‡è¯•...\")\n",
    "                    time.sleep(delay)\n",
    "            \n",
    "            # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥äº†\n",
    "            raise last_exception\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "# è‡ªå®šä¹‰å¼‚å¸¸ç±»\n",
    "class NetworkError(Exception):\n",
    "    \"\"\"ç½‘ç»œé”™è¯¯\"\"\"\n",
    "    pass\n",
    "\n",
    "class ServiceUnavailableError(Exception):\n",
    "    \"\"\"æœåŠ¡ä¸å¯ç”¨é”™è¯¯\"\"\"\n",
    "    pass\n",
    "\n",
    "# å¸¦é‡è¯•æœºåˆ¶çš„æœåŠ¡ç±»\n",
    "class RobustService:\n",
    "    \"\"\"å…·æœ‰é‡è¯•æœºåˆ¶çš„å¥å£®æœåŠ¡\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.call_count = 0\n",
    "        self.failure_rate = 0.3  # 30%çš„å¤±è´¥ç‡ç”¨äºæ¨¡æ‹Ÿ\n",
    "    \n",
    "    @with_retry(RetryConfig(\n",
    "        max_attempts=3,\n",
    "        base_delay=1.0,\n",
    "        policy=RetryPolicy.EXPONENTIAL_BACKOFF\n",
    "    ))\n",
    "    def call_external_api(self, data: Dict[str, Any]) -> Dict[str, Any]:\n",
    "        \"\"\"è°ƒç”¨å¤–éƒ¨API\"\"\"\n",
    "        self.call_count += 1\n",
    "        print(f\"è°ƒç”¨å¤–éƒ¨APIï¼Œç¬¬ {self.call_count} æ¬¡å°è¯•\")\n",
    "        \n",
    "        # æ¨¡æ‹Ÿé”™è¯¯æƒ…å†µ\n",
    "        if random.random() < self.failure_rate:\n",
    "            error_type = random.choice([NetworkError, ServiceUnavailableError])\n",
    "            if error_type == NetworkError:\n",
    "                raise NetworkError(\"ç½‘ç»œè¿æ¥è¶…æ—¶\")\n",
    "            else:\n",
    "                raise ServiceUnavailableError(\"å¤–éƒ¨æœåŠ¡æš‚æ—¶ä¸å¯ç”¨\")\n",
    "        \n",
    "        # æˆåŠŸæƒ…å†µ\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"data\": f\"å¤„ç†æˆåŠŸï¼Œè°ƒç”¨æ¬¡æ•°: {self.call_count}\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "print(\"é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶è®¾ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 æ€§èƒ½ç›‘æ§ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "from contextlib import contextmanager\n",
    "\n",
    "@dataclass\n",
    "class PerformanceMetrics:\n",
    "    \"\"\"æ€§èƒ½æŒ‡æ ‡\"\"\"\n",
    "    node_name: str\n",
    "    execution_time: float\n",
    "    success: bool\n",
    "    timestamp: str\n",
    "    error_message: Optional[str] = None\n",
    "\n",
    "class PerformanceMonitor:\n",
    "    \"\"\"æ€§èƒ½ç›‘æ§å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self, max_history=1000):\n",
    "        self.metrics_history = deque(maxlen=max_history)\n",
    "        self.node_metrics = defaultdict(list)\n",
    "        self.alerts = []\n",
    "        self.thresholds = {\n",
    "            \"max_execution_time\": 10.0,  # ç§’\n",
    "            \"max_error_rate\": 0.1        # 10%\n",
    "        }\n",
    "    \n",
    "    @contextmanager\n",
    "    def monitor_node(self, node_name: str):\n",
    "        \"\"\"èŠ‚ç‚¹æ€§èƒ½ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨\"\"\"\n",
    "        start_time = time.time()\n",
    "        success = True\n",
    "        error_message = None\n",
    "        \n",
    "        try:\n",
    "            yield\n",
    "        except Exception as e:\n",
    "            success = False\n",
    "            error_message = str(e)\n",
    "            raise\n",
    "        finally:\n",
    "            # è®¡ç®—æ€§èƒ½æŒ‡æ ‡\n",
    "            execution_time = time.time() - start_time\n",
    "            \n",
    "            metrics = PerformanceMetrics(\n",
    "                node_name=node_name,\n",
    "                execution_time=execution_time,\n",
    "                success=success,\n",
    "                timestamp=datetime.now().isoformat(),\n",
    "                error_message=error_message\n",
    "            )\n",
    "            \n",
    "            self.record_metrics(metrics)\n",
    "    \n",
    "    def record_metrics(self, metrics: PerformanceMetrics):\n",
    "        \"\"\"è®°å½•æ€§èƒ½æŒ‡æ ‡\"\"\"\n",
    "        self.metrics_history.append(metrics)\n",
    "        self.node_metrics[metrics.node_name].append(metrics)\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦è§¦å‘å‘Šè­¦\n",
    "        self._check_alerts(metrics)\n",
    "    \n",
    "    def _check_alerts(self, metrics: PerformanceMetrics):\n",
    "        \"\"\"æ£€æŸ¥å‘Šè­¦æ¡ä»¶\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        # æ‰§è¡Œæ—¶é—´å‘Šè­¦\n",
    "        if metrics.execution_time > self.thresholds[\"max_execution_time\"]:\n",
    "            alerts.append({\n",
    "                \"type\": \"high_execution_time\",\n",
    "                \"node\": metrics.node_name,\n",
    "                \"value\": metrics.execution_time,\n",
    "                \"threshold\": self.thresholds[\"max_execution_time\"],\n",
    "                \"timestamp\": metrics.timestamp\n",
    "            })\n",
    "        \n",
    "        # æ£€æŸ¥é”™è¯¯ç‡\n",
    "        node_history = self.node_metrics[metrics.node_name]\n",
    "        if len(node_history) >= 10:  # è‡³å°‘10ä¸ªæ ·æœ¬æ‰è®¡ç®—é”™è¯¯ç‡\n",
    "            recent_metrics = node_history[-10:]\n",
    "            error_rate = sum(1 for m in recent_metrics if not m.success) / len(recent_metrics)\n",
    "            \n",
    "            if error_rate > self.thresholds[\"max_error_rate\"]:\n",
    "                alerts.append({\n",
    "                    \"type\": \"high_error_rate\",\n",
    "                    \"node\": metrics.node_name,\n",
    "                    \"value\": error_rate,\n",
    "                    \"threshold\": self.thresholds[\"max_error_rate\"],\n",
    "                    \"timestamp\": metrics.timestamp\n",
    "                })\n",
    "        \n",
    "        # æ·»åŠ å‘Šè­¦\n",
    "        for alert in alerts:\n",
    "            self.alerts.append(alert)\n",
    "            self._send_alert(alert)\n",
    "    \n",
    "    def _send_alert(self, alert: Dict[str, Any]):\n",
    "        \"\"\"å‘é€å‘Šè­¦\"\"\"\n",
    "        print(f\"ğŸš¨ ALERT: {alert['type']} - èŠ‚ç‚¹: {alert['node']}, å€¼: {alert['value']}, é˜ˆå€¼: {alert['threshold']}\")\n",
    "    \n",
    "    def get_node_statistics(self, node_name: str) -> Dict[str, Any]:\n",
    "        \"\"\"è·å–èŠ‚ç‚¹ç»Ÿè®¡ä¿¡æ¯\"\"\"\n",
    "        metrics = self.node_metrics[node_name]\n",
    "        if not metrics:\n",
    "            return {}\n",
    "        \n",
    "        execution_times = [m.execution_time for m in metrics]\n",
    "        success_count = sum(1 for m in metrics if m.success)\n",
    "        \n",
    "        return {\n",
    "            \"total_calls\": len(metrics),\n",
    "            \"success_rate\": success_count / len(metrics) if metrics else 0,\n",
    "            \"avg_execution_time\": sum(execution_times) / len(execution_times),\n",
    "            \"max_execution_time\": max(execution_times),\n",
    "            \"last_updated\": metrics[-1].timestamp\n",
    "        }\n",
    "    \n",
    "    def generate_report(self) -> str:\n",
    "        \"\"\"ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š\"\"\"\n",
    "        report = [\"\\n\" + \"=\"*60]\n",
    "        report.append(\"æ€§èƒ½ç›‘æ§æŠ¥å‘Š\")\n",
    "        report.append(\"=\"*60)\n",
    "        \n",
    "        # æ€»ä½“ç»Ÿè®¡\n",
    "        total_metrics = len(self.metrics_history)\n",
    "        if total_metrics > 0:\n",
    "            success_count = sum(1 for m in self.metrics_history if m.success)\n",
    "            overall_success_rate = success_count / total_metrics\n",
    "            \n",
    "            report.append(f\"\\nğŸ“Š æ€»ä½“ç»Ÿè®¡:\")\n",
    "            report.append(f\"  æ€»è°ƒç”¨æ¬¡æ•°: {total_metrics}\")\n",
    "            report.append(f\"  æ€»ä½“æˆåŠŸç‡: {overall_success_rate:.2%}\")\n",
    "            report.append(f\"  å‘Šè­¦æ•°é‡: {len(self.alerts)}\")\n",
    "        \n",
    "        # å„èŠ‚ç‚¹ç»Ÿè®¡\n",
    "        report.append(f\"\\nğŸ” èŠ‚ç‚¹æ€§èƒ½ç»Ÿè®¡:\")\n",
    "        for node_name in self.node_metrics:\n",
    "            stats = self.get_node_statistics(node_name)\n",
    "            if stats:\n",
    "                report.append(f\"\\n  èŠ‚ç‚¹: {node_name}\")\n",
    "                report.append(f\"    è°ƒç”¨æ¬¡æ•°: {stats['total_calls']}\")\n",
    "                report.append(f\"    æˆåŠŸç‡: {stats['success_rate']:.2%}\")\n",
    "                report.append(f\"    å¹³å‡æ‰§è¡Œæ—¶é—´: {stats['avg_execution_time']:.3f}ç§’\")\n",
    "                report.append(f\"    æœ€å¤§æ‰§è¡Œæ—¶é—´: {stats['max_execution_time']:.3f}ç§’\")\n",
    "        \n",
    "        report.append(\"\\n\" + \"=\"*60)\n",
    "        return \"\\n\".join(report)\n",
    "\n",
    "# åˆ›å»ºå…¨å±€æ€§èƒ½ç›‘æ§å™¨\n",
    "performance_monitor = PerformanceMonitor()\n",
    "\n",
    "print(\"æ€§èƒ½ç›‘æ§ç³»ç»Ÿè®¾ç½®å®Œæˆ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ç”Ÿäº§ç¯å¢ƒæµ‹è¯•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ç”Ÿäº§ç¯å¢ƒçŠ¶æ€ç®¡ç†\n",
    "class ProductionState(TypedDict):\n",
    "    task_id: str\n",
    "    input_data: Dict[str, Any]\n",
    "    processing_results: List[Dict[str, Any]]\n",
    "    errors: List[Dict[str, Any]]\n",
    "\n",
    "def monitored_node(node_name: str):\n",
    "    \"\"\"æ€§èƒ½ç›‘æ§è£…é¥°å™¨\"\"\"\n",
    "    def decorator(func):\n",
    "        @functools.wraps(func)\n",
    "        def wrapper(state):\n",
    "            with performance_monitor.monitor_node(node_name):\n",
    "                return func(state)\n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@monitored_node(\"data_processing\")\n",
    "def robust_data_processing_node(state: ProductionState) -> ProductionState:\n",
    "    \"\"\"å¥å£®çš„æ•°æ®å¤„ç†èŠ‚ç‚¹\"\"\"\n",
    "    try:\n",
    "        service = RobustService()\n",
    "        \n",
    "        # å¤„ç†æ•°æ®\n",
    "        result = service.call_external_api(state[\"input_data\"])\n",
    "        \n",
    "        state[\"processing_results\"].append({\n",
    "            \"node\": \"data_processing\",\n",
    "            \"status\": \"success\",\n",
    "            \"result\": result\n",
    "        })\n",
    "        \n",
    "        print(f\"âœ… data_processing å¤„ç†æˆåŠŸ\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        # è®°å½•é”™è¯¯ä½†ç»§ç»­å¤„ç†\n",
    "        error_info = {\n",
    "            \"node\": \"data_processing\",\n",
    "            \"type\": type(e).__name__,\n",
    "            \"message\": str(e),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        state[\"errors\"].append(error_info)\n",
    "        print(f\"âŒ data_processing å¤„ç†å¤±è´¥: {str(e)}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "@monitored_node(\"data_validation\")\n",
    "def validation_node(state: ProductionState) -> ProductionState:\n",
    "    \"\"\"æ•°æ®éªŒè¯èŠ‚ç‚¹\"\"\"\n",
    "    print(f\"æ‰§è¡Œæ•°æ®éªŒè¯: {state['task_id']}\")\n",
    "    \n",
    "    # æ¨¡æ‹ŸéªŒè¯é€»è¾‘\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    # æ¨¡æ‹Ÿéšæœºé”™è¯¯\n",
    "    if random.random() < 0.1:  # 10%é”™è¯¯ç‡\n",
    "        raise ValueError(\"æ•°æ®éªŒè¯å¤±è´¥\")\n",
    "    \n",
    "    state[\"processing_results\"].append({\n",
    "        \"node\": \"data_validation\",\n",
    "        \"result\": \"éªŒè¯é€šè¿‡\",\n",
    "        \"status\": \"success\"\n",
    "    })\n",
    "    \n",
    "    return state\n",
    "\n",
    "# åˆ›å»ºç”Ÿäº§ç¯å¢ƒæµ‹è¯•å·¥ä½œæµ\n",
    "production_workflow = StateGraph(ProductionState)\n",
    "production_workflow.add_node(\"validation\", validation_node)\n",
    "production_workflow.add_node(\"processing\", robust_data_processing_node)\n",
    "\n",
    "production_workflow.add_edge(START, \"validation\")\n",
    "production_workflow.add_edge(\"validation\", \"processing\")\n",
    "production_workflow.add_edge(\"processing\", END)\n",
    "\n",
    "production_app = production_workflow.compile()\n",
    "\n",
    "def run_production_test(num_tasks: int = 10):\n",
    "    \"\"\"è¿è¡Œç”Ÿäº§ç¯å¢ƒæµ‹è¯•\"\"\"\n",
    "    print(f\"å¼€å§‹ç”Ÿäº§ç¯å¢ƒæµ‹è¯•ï¼Œæ‰§è¡Œ {num_tasks} ä¸ªä»»åŠ¡...\\n\")\n",
    "    \n",
    "    successful_tasks = 0\n",
    "    failed_tasks = 0\n",
    "    \n",
    "    for i in range(num_tasks):\n",
    "        task_id = f\"TASK_{i+1:03d}\"\n",
    "        \n",
    "        # åˆ›å»ºåˆå§‹çŠ¶æ€\n",
    "        initial_state = {\n",
    "            \"task_id\": task_id,\n",
    "            \"input_data\": {\"data\": f\"æµ‹è¯•æ•°æ®_{i+1}\"},\n",
    "            \"processing_results\": [],\n",
    "            \"errors\": []\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"æ‰§è¡Œä»»åŠ¡ {task_id}...\", end=\" \")\n",
    "            \n",
    "            # æ‰§è¡Œå·¥ä½œæµ\n",
    "            result = production_app.invoke(initial_state)\n",
    "            \n",
    "            if result[\"errors\"]:\n",
    "                failed_tasks += 1\n",
    "                print(f\"âŒ å¤±è´¥ ({len(result['errors'])} ä¸ªé”™è¯¯)\")\n",
    "            else:\n",
    "                successful_tasks += 1\n",
    "                print(f\"âœ… æˆåŠŸ\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            failed_tasks += 1\n",
    "            print(f\"âŒ å¼‚å¸¸: {str(e)}\")\n",
    "        \n",
    "        # çŸ­æš‚å»¶è¿Ÿæ¨¡æ‹Ÿå®é™…è´Ÿè½½\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    print(f\"\\næµ‹è¯•å®Œæˆï¼\")\n",
    "    print(f\"æˆåŠŸä»»åŠ¡: {successful_tasks}/{num_tasks} ({successful_tasks/num_tasks:.1%})\")\n",
    "    print(f\"å¤±è´¥ä»»åŠ¡: {failed_tasks}/{num_tasks} ({failed_tasks/num_tasks:.1%})\")\n",
    "    \n",
    "    # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š\n",
    "    print(performance_monitor.generate_report())\n",
    "\n",
    "# è¿è¡Œç”Ÿäº§ç¯å¢ƒæµ‹è¯•\n",
    "run_production_test(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. æœ€ä½³å®è·µæ€»ç»“\n",
    "\n",
    "### 4.1 æ¶æ„è®¾è®¡åŸåˆ™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€ä½³å®è·µæ€»ç»“\n",
    "best_practices = {\n",
    "    \"æ¶æ„è®¾è®¡\": {\n",
    "        \"æ¨¡å—åŒ–è®¾è®¡\": \"å°†å¤æ‚ç³»ç»Ÿåˆ†è§£ä¸ºç‹¬ç«‹çš„ã€å¯é‡ç”¨çš„ç»„ä»¶\",\n",
    "        \"å•ä¸€èŒè´£\": \"æ¯ä¸ªèŠ‚ç‚¹åº”è¯¥æœ‰æ˜ç¡®çš„å•ä¸€èŒè´£\",\n",
    "        \"æ¾è€¦åˆ\": \"é€šè¿‡çŠ¶æ€ä¼ é€’å’Œäº‹ä»¶ç³»ç»Ÿå®ç°ç»„ä»¶é—´çš„æ¾è€¦åˆ\",\n",
    "        \"å¯æ‰©å±•æ€§\": \"è®¾è®¡æ—¶è€ƒè™‘ç³»ç»Ÿçš„æ¨ªå‘å’Œçºµå‘æ‰©å±•èƒ½åŠ›\"\n",
    "    },\n",
    "    \"é”™è¯¯å¤„ç†\": {\n",
    "        \"ä¼˜é›…é™çº§\": \"ç³»ç»Ÿåº”è¯¥èƒ½å¤Ÿåœ¨éƒ¨åˆ†åŠŸèƒ½å¤±æ•ˆæ—¶ç»§ç»­è¿è¡Œ\",\n",
    "        \"é‡è¯•æœºåˆ¶\": \"å¯¹äºä¸´æ—¶æ€§é”™è¯¯å®ç°æŒ‡æ•°é€€é¿é‡è¯•\",\n",
    "        \"é”™è¯¯åˆ†ç±»\": \"åŒºåˆ†å¯é‡è¯•å’Œä¸å¯é‡è¯•çš„é”™è¯¯ç±»å‹\",\n",
    "        \"é”™è¯¯è®°å½•\": \"è¯¦ç»†è®°å½•é”™è¯¯ä¿¡æ¯ç”¨äºè°ƒè¯•å’Œåˆ†æ\"\n",
    "    },\n",
    "    \"æ€§èƒ½ä¼˜åŒ–\": {\n",
    "        \"å¼‚æ­¥å¤„ç†\": \"å¯¹äºI/Oå¯†é›†å‹ä»»åŠ¡ä½¿ç”¨å¼‚æ­¥å¤„ç†\",\n",
    "        \"å¹¶è¡Œæ‰§è¡Œ\": \"å……åˆ†åˆ©ç”¨å¹¶è¡Œå¤„ç†èƒ½åŠ›æé«˜ååé‡\",\n",
    "        \"èµ„æºç®¡ç†\": \"åˆç†ç®¡ç†å†…å­˜å’ŒCPUèµ„æºä½¿ç”¨\",\n",
    "        \"ç¼“å­˜ç­–ç•¥\": \"å®ç°åˆé€‚çš„ç¼“å­˜æœºåˆ¶å‡å°‘é‡å¤è®¡ç®—\"\n",
    "    },\n",
    "    \"ç›‘æ§å’Œè¿ç»´\": {\n",
    "        \"æŒ‡æ ‡æ”¶é›†\": \"æ”¶é›†å…³é”®æ€§èƒ½å’Œä¸šåŠ¡æŒ‡æ ‡\",\n",
    "        \"å‘Šè­¦æœºåˆ¶\": \"è®¾ç½®åˆç†çš„å‘Šè­¦é˜ˆå€¼å’Œé€šçŸ¥æœºåˆ¶\",\n",
    "        \"æ—¥å¿—ç®¡ç†\": \"å®ç°ç»“æ„åŒ–æ—¥å¿—è®°å½•å’Œåˆ†æ\",\n",
    "        \"å¥åº·æ£€æŸ¥\": \"å®ç°ç³»ç»Ÿå¥åº·çŠ¶æ€æ£€æŸ¥å’Œè‡ªåŠ¨æ¢å¤\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def print_best_practices():\n",
    "    \"\"\"æ‰“å°æœ€ä½³å®è·µæŒ‡å—\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"LangGraph ç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µæŒ‡å—\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for category, practices in best_practices.items():\n",
    "        print(f\"\\nğŸ—ï¸ {category}:\")\n",
    "        for principle, description in practices.items():\n",
    "            print(f\"  â€¢ {principle}: {description}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"åº”ç”¨åœºæ™¯å»ºè®®\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    scenarios = {\n",
    "        \"RAGç³»ç»Ÿ\": \"é€‚ç”¨äºçŸ¥è¯†å¯†é›†å‹åº”ç”¨ï¼Œå¦‚æ™ºèƒ½å®¢æœã€æ–‡æ¡£é—®ç­”ã€ä¸“å®¶ç³»ç»Ÿ\",\n",
    "        \"å¤šAgentåä½œ\": \"é€‚ç”¨äºå¤æ‚ä¸šåŠ¡æµç¨‹ï¼Œå¦‚è®¢å•å¤„ç†ã€å®¡æ‰¹å·¥ä½œæµã€å¤šæ­¥éª¤åˆ†æ\",\n",
    "        \"å®æ—¶å¤„ç†\": \"é€‚ç”¨äºéœ€è¦å®æ—¶å“åº”çš„åœºæ™¯ï¼Œå¦‚ç›‘æ§ç³»ç»Ÿã€å®æ—¶æ¨èã€åœ¨çº¿è¯Šæ–­\",\n",
    "        \"æ‰¹å¤„ç†å·¥ä½œæµ\": \"é€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®å¤„ç†ï¼Œå¦‚ETLæµç¨‹ã€æŠ¥è¡¨ç”Ÿæˆã€æ•°æ®åŒæ­¥\"\n",
    "    }\n",
    "    \n",
    "    for scenario, description in scenarios.items():\n",
    "        print(f\"\\nğŸ“‹ {scenario}:\")\n",
    "        print(f\"  {description}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"éƒ¨ç½²å»ºè®®\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    deployment_tips = [\n",
    "        \"ä½¿ç”¨å®¹å™¨åŒ–æŠ€æœ¯ï¼ˆDocker/Kubernetesï¼‰è¿›è¡Œéƒ¨ç½²\",\n",
    "        \"å®ç°è“ç»¿éƒ¨ç½²æˆ–æ»šåŠ¨æ›´æ–°ç­–ç•¥\",\n",
    "        \"é…ç½®è´Ÿè½½å‡è¡¡å’Œè‡ªåŠ¨æ‰©ç¼©å®¹\",\n",
    "        \"å»ºç«‹å®Œæ•´çš„CI/CDæµæ°´çº¿\",\n",
    "        \"å®æ–½å…¨é¢çš„ç›‘æ§å’Œæ—¥å¿—ç®¡ç†\",\n",
    "        \"å®šæœŸè¿›è¡Œæ€§èƒ½æµ‹è¯•å’Œå‹åŠ›æµ‹è¯•\",\n",
    "        \"å»ºç«‹ç¾å¤‡å’Œæ•°æ®æ¢å¤æœºåˆ¶\",\n",
    "        \"ç»´æŠ¤è¯¦ç»†çš„è¿ç»´æ–‡æ¡£å’Œåº”æ€¥é¢„æ¡ˆ\"\n",
    "    ]\n",
    "    \n",
    "    for tip in deployment_tips:\n",
    "        print(f\"  âœ“ {tip}\")\n",
    "\n",
    "print_best_practices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å®è·µç»ƒä¹ \n",
    "\n",
    "### ç»ƒä¹ 1ï¼šæ„å»ºæ™ºèƒ½æ¨èç³»ç»Ÿ\n",
    "åŸºäºç”¨æˆ·è¡Œä¸ºå’Œå†…å®¹ç‰¹å¾ï¼Œæ„å»ºä¸€ä¸ªå¤šé˜¶æ®µçš„æ¨èç³»ç»Ÿï¼š\n",
    "- ç”¨æˆ·ç”»åƒåˆ†æ\n",
    "- å€™é€‰ç‰©å“å¬å›\n",
    "- ç‰¹å¾å·¥ç¨‹å’Œæ’åº\n",
    "- å¤šæ ·æ€§å’Œæ–°é¢–æ€§ä¼˜åŒ–\n",
    "- A/Bæµ‹è¯•å’Œæ•ˆæœè¯„ä¼°\n",
    "\n",
    "### ç»ƒä¹ 2ï¼šå®ç°åˆ†å¸ƒå¼æ•°æ®å¤„ç†ç®¡é“\n",
    "è®¾è®¡ä¸€ä¸ªå¯æ‰©å±•çš„æ•°æ®å¤„ç†ç®¡é“ï¼š\n",
    "- æ•°æ®æ‘„å–å’ŒéªŒè¯\n",
    "- å¹¶è¡Œæ•°æ®æ¸…æ´—å’Œè½¬æ¢\n",
    "- ç‰¹å¾æå–å’Œèšåˆ\n",
    "- æ•°æ®è´¨é‡æ£€æŸ¥\n",
    "- ç»“æœå­˜å‚¨å’Œé€šçŸ¥\n",
    "\n",
    "### ç»ƒä¹ 3ï¼šåˆ›å»ºæ™ºèƒ½è¿ç»´ç³»ç»Ÿ\n",
    "æ„å»ºä¸€ä¸ªè‡ªåŠ¨åŒ–è¿ç»´ç³»ç»Ÿï¼š\n",
    "- ç³»ç»Ÿç›‘æ§å’Œå‘Šè­¦\n",
    "- å¼‚å¸¸æ£€æµ‹å’Œåˆ†æ\n",
    "- è‡ªåŠ¨æ•…éšœè¯Šæ–­\n",
    "- ä¿®å¤å»ºè®®å’Œæ‰§è¡Œ\n",
    "- æ€§èƒ½ä¼˜åŒ–å»ºè®®"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. æ€»ç»“\n",
    "\n",
    "æœ¬æ•™ç¨‹å…¨é¢ä»‹ç»äº†LangGraphçš„é«˜çº§åº”ç”¨æ¡ˆä¾‹å’Œç”Ÿäº§ç¯å¢ƒæœ€ä½³å®è·µï¼š\n",
    "\n",
    "### ä¸»è¦å†…å®¹å›é¡¾\n",
    "\n",
    "1. **RAGç³»ç»Ÿæ„å»º**\n",
    "   - æ™ºèƒ½æ–‡æ¡£æ£€ç´¢å’Œé—®ç­”\n",
    "   - å‘é‡æ•°æ®åº“é›†æˆ\n",
    "   - ä¸Šä¸‹æ–‡ç®¡ç†å’Œç­”æ¡ˆç”Ÿæˆ\n",
    "   - è´¨é‡è¯„ä¼°å’ŒéªŒè¯æœºåˆ¶\n",
    "\n",
    "2. **å¤šAgentåä½œç³»ç»Ÿ**\n",
    "   - æ™ºèƒ½å®¢æœç³»ç»Ÿè®¾è®¡\n",
    "   - è¯·æ±‚åˆ†ç±»å’Œè·¯ç”±\n",
    "   - Agentä¸“ä¸šåŒ–å’Œåè°ƒ\n",
    "   - è´¨é‡ä¿è¯å’Œå‡çº§æœºåˆ¶\n",
    "\n",
    "3. **ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²**\n",
    "   - é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶\n",
    "   - æ€§èƒ½ç›‘æ§å’ŒæŒ‡æ ‡æ”¶é›†\n",
    "   - å‘Šè­¦ç³»ç»Ÿå’Œè‡ªåŠ¨åŒ–è¿ç»´\n",
    "   - å¯æ‰©å±•æ€§å’Œå¯é æ€§è®¾è®¡\n",
    "\n",
    "### æ ¸å¿ƒä»·å€¼\n",
    "\n",
    "- **å¯æ‰©å±•æ€§**: é€šè¿‡æ¨¡å—åŒ–è®¾è®¡å®ç°ç³»ç»Ÿçš„æ¨ªå‘å’Œçºµå‘æ‰©å±•\n",
    "- **å¯é æ€§**: é€šè¿‡é”™è¯¯å¤„ç†ã€é‡è¯•æœºåˆ¶å’Œç›‘æ§ç¡®ä¿ç³»ç»Ÿç¨³å®šè¿è¡Œ\n",
    "- **å¯ç»´æŠ¤æ€§**: é€šè¿‡æ¸…æ™°çš„æ¶æ„è®¾è®¡å’Œå®Œå–„çš„æ—¥å¿—ç›‘æ§é™ä½è¿ç»´æˆæœ¬\n",
    "- **æ€§èƒ½ä¼˜åŒ–**: é€šè¿‡å¼‚æ­¥å¤„ç†ã€å¹¶è¡Œæ‰§è¡Œå’Œç¼“å­˜ç­–ç•¥æé«˜ç³»ç»Ÿæ€§èƒ½\n",
    "- **ç”¨æˆ·ä½“éªŒ**: é€šè¿‡æ™ºèƒ½åŒ–å¤„ç†å’Œå®æ—¶åé¦ˆæå‡ç”¨æˆ·æ»¡æ„åº¦\n",
    "\n",
    "### å‘å±•æ–¹å‘\n",
    "\n",
    "éšç€AIæŠ€æœ¯çš„ä¸æ–­å‘å±•ï¼ŒLangGraphå°†åœ¨ä»¥ä¸‹æ–¹é¢ç»§ç»­æ¼”è¿›ï¼š\n",
    "- æ›´å¼ºå¤§çš„å¤šæ¨¡æ€å¤„ç†èƒ½åŠ›\n",
    "- æ›´æ™ºèƒ½çš„è‡ªåŠ¨åŒ–ç¼–æ’\n",
    "- æ›´å®Œå–„çš„äº‘åŸç”Ÿæ”¯æŒ\n",
    "- æ›´ä¸°å¯Œçš„ç”Ÿæ€ç³»ç»Ÿé›†æˆ\n",
    "\n",
    "é€šè¿‡æœ¬æ•™ç¨‹çš„å­¦ä¹ ï¼Œæ‚¨å·²ç»æŒæ¡äº†ä½¿ç”¨LangGraphæ„å»ºä¼ä¸šçº§AIåº”ç”¨çš„æ ¸å¿ƒæŠ€èƒ½ã€‚ç»§ç»­å®è·µå’Œæ¢ç´¢ï¼Œæ‚¨å°†èƒ½å¤Ÿæ„å»ºå‡ºæ›´åŠ æ™ºèƒ½å’Œé«˜æ•ˆçš„ç³»ç»Ÿè§£å†³æ–¹æ¡ˆã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}