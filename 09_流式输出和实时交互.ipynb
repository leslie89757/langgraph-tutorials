{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09_æµå¼è¾“å‡ºå’Œå®æ—¶äº¤äº’\n",
    "\n",
    "## å­¦ä¹ ç›®æ ‡\n",
    "- ç†è§£LangGraphçš„æµå¼è¾“å‡ºæœºåˆ¶\n",
    "- æŒæ¡å®æ—¶çŠ¶æ€æ›´æ–°å’Œäº‹ä»¶å¤„ç†\n",
    "- å­¦ä¹ å¼‚æ­¥æ‰§è¡Œå’Œäº‹ä»¶ç›‘å¬\n",
    "- å®ç°WebSocketå®æ—¶é€šä¿¡ç³»ç»Ÿ\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚å¿µ\n",
    "\n",
    "### æµå¼è¾“å‡º\n",
    "LangGraphæ”¯æŒæµå¼è¾“å‡ºï¼Œå…è®¸æˆ‘ä»¬å®æ—¶è·å–æ‰§è¡Œè¿‡ç¨‹ä¸­çš„ä¸­é—´ç»“æœå’ŒçŠ¶æ€å˜åŒ–ã€‚\n",
    "\n",
    "### äº‹ä»¶ç³»ç»Ÿ\n",
    "é€šè¿‡äº‹ä»¶ç³»ç»Ÿï¼Œæˆ‘ä»¬å¯ä»¥ç›‘å¬å›¾æ‰§è¡Œè¿‡ç¨‹ä¸­çš„å„ç§äº‹ä»¶ï¼Œå¦‚èŠ‚ç‚¹å¼€å§‹ã€ç»“æŸã€é”™è¯¯ç­‰ã€‚\n",
    "\n",
    "### å¼‚æ­¥æ‰§è¡Œ\n",
    "æ”¯æŒå¼‚æ­¥æ‰§è¡Œæ¨¡å¼ï¼Œæé«˜ç³»ç»Ÿå¹¶å‘æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒè®¾ç½®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import Dict, Any, List, AsyncGenerator\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import logging\n",
    "\n",
    "# è®¾ç½®æ—¥å¿—\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. åŸºç¡€æµå¼è¾“å‡º\n",
    "\n",
    "### 1.1 ç®€å•æµå¼æ‰§è¡Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "\n",
    "class StreamingState(TypedDict):\n",
    "    messages: List[str]\n",
    "    current_step: str\n",
    "    progress: int\n",
    "    results: Dict[str, Any]\n",
    "\n",
    "def data_processing_node(state: StreamingState) -> StreamingState:\n",
    "    \"\"\"æ•°æ®å¤„ç†èŠ‚ç‚¹\"\"\"\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] å¼€å§‹æ•°æ®å¤„ç†...\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†è¿‡ç¨‹\n",
    "    for i in range(1, 6):\n",
    "        time.sleep(0.5)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "        state[\"progress\"] = i * 20\n",
    "        state[\"current_step\"] = f\"å¤„ç†æ•°æ®æ‰¹æ¬¡ {i}/5\"\n",
    "        print(f\"[{datetime.now().strftime('%H:%M:%S')}] {state['current_step']} - è¿›åº¦: {state['progress']}%\")\n",
    "    \n",
    "    state[\"messages\"].append(\"æ•°æ®å¤„ç†å®Œæˆ\")\n",
    "    state[\"results\"][\"processed_data\"] = [f\"æ•°æ®_{i}\" for i in range(1, 101)]\n",
    "    return state\n",
    "\n",
    "def analysis_node(state: StreamingState) -> StreamingState:\n",
    "    \"\"\"åˆ†æèŠ‚ç‚¹\"\"\"\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] å¼€å§‹æ•°æ®åˆ†æ...\")\n",
    "    \n",
    "    state[\"current_step\"] = \"åˆ†ææ•°æ®æ¨¡å¼\"\n",
    "    time.sleep(1)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {state['current_step']}\")\n",
    "    \n",
    "    state[\"current_step\"] = \"ç”Ÿæˆåˆ†ææŠ¥å‘Š\"\n",
    "    time.sleep(1)\n",
    "    print(f\"[{datetime.now().strftime('%H:%M:%S')}] {state['current_step']}\")\n",
    "    \n",
    "    state[\"messages\"].append(\"æ•°æ®åˆ†æå®Œæˆ\")\n",
    "    state[\"results\"][\"analysis\"] = {\"pattern\": \"çº¿æ€§å¢é•¿\", \"accuracy\": 0.95}\n",
    "    state[\"progress\"] = 100\n",
    "    return state\n",
    "\n",
    "# åˆ›å»ºæµå¼å¤„ç†å›¾\n",
    "workflow = StateGraph(StreamingState)\n",
    "workflow.add_node(\"process\", data_processing_node)\n",
    "workflow.add_node(\"analyze\", analysis_node)\n",
    "\n",
    "workflow.add_edge(START, \"process\")\n",
    "workflow.add_edge(\"process\", \"analyze\")\n",
    "workflow.add_edge(\"analyze\", END)\n",
    "\n",
    "streaming_app = workflow.compile()\n",
    "\n",
    "# æ‰§è¡Œæµå¼å¤„ç†\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"current_step\": \"åˆå§‹åŒ–\",\n",
    "    \"progress\": 0,\n",
    "    \"results\": {}\n",
    "}\n",
    "\n",
    "print(\"=== å¼€å§‹æµå¼å¤„ç† ===\")\n",
    "final_state = streaming_app.invoke(initial_state)\n",
    "print(\"\\n=== å¤„ç†å®Œæˆ ===\")\n",
    "print(f\"æœ€ç»ˆæ¶ˆæ¯: {final_state['messages']}\")\n",
    "print(f\"æœ€ç»ˆç»“æœ: {final_state['results']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ä½¿ç”¨stream()æ–¹æ³•è¿›è¡Œæµå¼è¾“å‡º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# é‡æ–°å®šä¹‰å¸¦æœ‰æ›´å¤šè¾“å‡ºçš„èŠ‚ç‚¹\n",
    "def verbose_processing_node(state: StreamingState) -> StreamingState:\n",
    "    \"\"\"è¯¦ç»†è¾“å‡ºçš„å¤„ç†èŠ‚ç‚¹\"\"\"\n",
    "    state[\"current_step\"] = \"å¼€å§‹å¤„ç†\"\n",
    "    \n",
    "    for i in range(1, 4):\n",
    "        time.sleep(0.3)\n",
    "        state[\"progress\"] = i * 25\n",
    "        state[\"current_step\"] = f\"å¤„ç†é˜¶æ®µ {i}\"\n",
    "        state[\"messages\"].append(f\"å®Œæˆå¤„ç†é˜¶æ®µ {i}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def verbose_validation_node(state: StreamingState) -> StreamingState:\n",
    "    \"\"\"è¯¦ç»†è¾“å‡ºçš„éªŒè¯èŠ‚ç‚¹\"\"\"\n",
    "    state[\"current_step\"] = \"å¼€å§‹éªŒè¯\"\n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    state[\"current_step\"] = \"éªŒè¯å®Œæˆ\"\n",
    "    state[\"progress\"] = 100\n",
    "    state[\"messages\"].append(\"éªŒè¯é€šè¿‡\")\n",
    "    state[\"results\"][\"validation\"] = \"æˆåŠŸ\"\n",
    "    \n",
    "    return state\n",
    "\n",
    "# åˆ›å»ºæ–°çš„æµå¼å›¾\n",
    "verbose_workflow = StateGraph(StreamingState)\n",
    "verbose_workflow.add_node(\"process\", verbose_processing_node)\n",
    "verbose_workflow.add_node(\"validate\", verbose_validation_node)\n",
    "\n",
    "verbose_workflow.add_edge(START, \"process\")\n",
    "verbose_workflow.add_edge(\"process\", \"validate\")\n",
    "verbose_workflow.add_edge(\"validate\", END)\n",
    "\n",
    "verbose_app = verbose_workflow.compile()\n",
    "\n",
    "# ä½¿ç”¨stream()æ–¹æ³•è·å–æµå¼è¾“å‡º\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"current_step\": \"åˆå§‹åŒ–\",\n",
    "    \"progress\": 0,\n",
    "    \"results\": {}\n",
    "}\n",
    "\n",
    "print(\"=== æµå¼è¾“å‡ºæ¼”ç¤º ===\")\n",
    "for chunk in verbose_app.stream(initial_state):\n",
    "    # chunkæ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«èŠ‚ç‚¹åå’Œè¯¥èŠ‚ç‚¹çš„è¾“å‡ºçŠ¶æ€\n",
    "    for node_name, state_update in chunk.items():\n",
    "        print(f\"èŠ‚ç‚¹: {node_name}\")\n",
    "        print(f\"å½“å‰æ­¥éª¤: {state_update.get('current_step', 'N/A')}\")\n",
    "        print(f\"è¿›åº¦: {state_update.get('progress', 0)}%\")\n",
    "        print(f\"æ¶ˆæ¯æ•°é‡: {len(state_update.get('messages', []))}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. å¼‚æ­¥æµå¼å¤„ç†\n",
    "\n",
    "### 2.1 å¼‚æ­¥èŠ‚ç‚¹å®šä¹‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "class AsyncStreamingState(TypedDict):\n",
    "    messages: List[str]\n",
    "    current_step: str\n",
    "    progress: int\n",
    "    results: Dict[str, Any]\n",
    "    errors: List[str]\n",
    "\n",
    "async def async_fetch_data_node(state: AsyncStreamingState) -> AsyncStreamingState:\n",
    "    \"\"\"å¼‚æ­¥æ•°æ®è·å–èŠ‚ç‚¹\"\"\"\n",
    "    state[\"current_step\"] = \"å¼€å§‹è·å–æ•°æ®\"\n",
    "    state[\"messages\"].append(\"å¯åŠ¨æ•°æ®è·å–ä»»åŠ¡\")\n",
    "    \n",
    "    # æ¨¡æ‹Ÿå¤šä¸ªå¼‚æ­¥ä»»åŠ¡\n",
    "    tasks = []\n",
    "    for i in range(3):\n",
    "        tasks.append(fetch_mock_data(i))\n",
    "    \n",
    "    # å¹¶è¡Œæ‰§è¡Œä»»åŠ¡\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    \n",
    "    # å¤„ç†ç»“æœ\n",
    "    successful_results = []\n",
    "    for i, result in enumerate(results):\n",
    "        if isinstance(result, Exception):\n",
    "            state[\"errors\"].append(f\"ä»»åŠ¡ {i} å¤±è´¥: {str(result)}\")\n",
    "        else:\n",
    "            successful_results.append(result)\n",
    "        \n",
    "        # æ›´æ–°è¿›åº¦\n",
    "        state[\"progress\"] = ((i + 1) / len(results)) * 50\n",
    "        state[\"current_step\"] = f\"å®Œæˆæ•°æ®è·å– {i + 1}/{len(results)}\"\n",
    "    \n",
    "    state[\"results\"][\"fetched_data\"] = successful_results\n",
    "    state[\"messages\"].append(f\"æ•°æ®è·å–å®Œæˆï¼ŒæˆåŠŸ: {len(successful_results)}, å¤±è´¥: {len(state['errors'])}\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "async def fetch_mock_data(task_id: int) -> Dict[str, Any]:\n",
    "    \"\"\"æ¨¡æ‹Ÿå¼‚æ­¥æ•°æ®è·å–\"\"\"\n",
    "    await asyncio.sleep(0.5 + task_id * 0.2)  # ä¸åŒçš„å»¶è¿Ÿ\n",
    "    \n",
    "    # æ¨¡æ‹Ÿå¶å‘é”™è¯¯\n",
    "    if task_id == 1:\n",
    "        raise Exception(\"æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯\")\n",
    "    \n",
    "    return {\n",
    "        \"task_id\": task_id,\n",
    "        \"data\": f\"æ•°æ®_{task_id}\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "async def async_process_data_node(state: AsyncStreamingState) -> AsyncStreamingState:\n",
    "    \"\"\"å¼‚æ­¥æ•°æ®å¤„ç†èŠ‚ç‚¹\"\"\"\n",
    "    state[\"current_step\"] = \"å¼€å§‹å¤„ç†æ•°æ®\"\n",
    "    \n",
    "    fetched_data = state[\"results\"].get(\"fetched_data\", [])\n",
    "    \n",
    "    # å¼‚æ­¥å¤„ç†æ¯ä¸ªæ•°æ®é¡¹\n",
    "    processed_data = []\n",
    "    for i, data_item in enumerate(fetched_data):\n",
    "        await asyncio.sleep(0.2)  # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´\n",
    "        \n",
    "        processed_item = {\n",
    "            \"original\": data_item,\n",
    "            \"processed\": f\"å·²å¤„ç†_{data_item['task_id']}\",\n",
    "            \"process_time\": datetime.now().isoformat()\n",
    "        }\n",
    "        processed_data.append(processed_item)\n",
    "        \n",
    "        # æ›´æ–°è¿›åº¦\n",
    "        progress = 50 + ((i + 1) / len(fetched_data)) * 50\n",
    "        state[\"progress\"] = int(progress)\n",
    "        state[\"current_step\"] = f\"å¤„ç†æ•°æ®é¡¹ {i + 1}/{len(fetched_data)}\"\n",
    "    \n",
    "    state[\"results\"][\"processed_data\"] = processed_data\n",
    "    state[\"messages\"].append(f\"æ•°æ®å¤„ç†å®Œæˆï¼Œå¤„ç†äº† {len(processed_data)} ä¸ªæ•°æ®é¡¹\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "# åˆ›å»ºå¼‚æ­¥æµå¼å›¾\n",
    "async_workflow = StateGraph(AsyncStreamingState)\n",
    "async_workflow.add_node(\"fetch\", async_fetch_data_node)\n",
    "async_workflow.add_node(\"process\", async_process_data_node)\n",
    "\n",
    "async_workflow.add_edge(START, \"fetch\")\n",
    "async_workflow.add_edge(\"fetch\", \"process\")\n",
    "async_workflow.add_edge(\"process\", END)\n",
    "\n",
    "async_app = async_workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 æ‰§è¡Œå¼‚æ­¥æµå¼å¤„ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_async_streaming():\n",
    "    \"\"\"è¿è¡Œå¼‚æ­¥æµå¼å¤„ç†\"\"\"\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"current_step\": \"åˆå§‹åŒ–\",\n",
    "        \"progress\": 0,\n",
    "        \"results\": {},\n",
    "        \"errors\": []\n",
    "    }\n",
    "    \n",
    "    print(\"=== å¼‚æ­¥æµå¼å¤„ç†å¼€å§‹ ===\")\n",
    "    \n",
    "    # ä½¿ç”¨astream()è¿›è¡Œå¼‚æ­¥æµå¼å¤„ç†\n",
    "    async for chunk in async_app.astream(initial_state):\n",
    "        for node_name, state_update in chunk.items():\n",
    "            print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] èŠ‚ç‚¹: {node_name}\")\n",
    "            print(f\"æ­¥éª¤: {state_update.get('current_step', 'N/A')}\")\n",
    "            print(f\"è¿›åº¦: {state_update.get('progress', 0)}%\")\n",
    "            \n",
    "            if state_update.get('messages'):\n",
    "                print(f\"æœ€æ–°æ¶ˆæ¯: {state_update['messages'][-1]}\")\n",
    "            \n",
    "            if state_update.get('errors'):\n",
    "                print(f\"é”™è¯¯æ•°é‡: {len(state_update['errors'])}\")\n",
    "    \n",
    "    print(\"\\n=== å¼‚æ­¥æµå¼å¤„ç†å®Œæˆ ===\")\n",
    "\n",
    "# è¿è¡Œå¼‚æ­¥ç¤ºä¾‹\n",
    "await run_async_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. äº‹ä»¶é©±åŠ¨çš„å®æ—¶ç³»ç»Ÿ\n",
    "\n",
    "### 3.1 äº‹ä»¶ç›‘å¬å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "class EventSystem:\n",
    "    \"\"\"ç®€å•çš„äº‹ä»¶ç³»ç»Ÿ\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.listeners: Dict[str, List[Callable]] = defaultdict(list)\n",
    "        self.event_history: List[Dict[str, Any]] = []\n",
    "    \n",
    "    def on(self, event_type: str, callback: Callable):\n",
    "        \"\"\"æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨\"\"\"\n",
    "        self.listeners[event_type].append(callback)\n",
    "    \n",
    "    def emit(self, event_type: str, data: Any = None):\n",
    "        \"\"\"è§¦å‘äº‹ä»¶\"\"\"\n",
    "        event = {\n",
    "            \"type\": event_type,\n",
    "            \"data\": data,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        self.event_history.append(event)\n",
    "        \n",
    "        # è°ƒç”¨æ‰€æœ‰ç›‘å¬å™¨\n",
    "        for callback in self.listeners[event_type]:\n",
    "            try:\n",
    "                callback(event)\n",
    "            except Exception as e:\n",
    "                print(f\"äº‹ä»¶å¤„ç†é”™è¯¯: {e}\")\n",
    "    \n",
    "    def get_history(self, event_type: str = None) -> List[Dict[str, Any]]:\n",
    "        \"\"\"è·å–äº‹ä»¶å†å²\"\"\"\n",
    "        if event_type:\n",
    "            return [e for e in self.event_history if e[\"type\"] == event_type]\n",
    "        return self.event_history.copy()\n",
    "\n",
    "# åˆ›å»ºå…¨å±€äº‹ä»¶ç³»ç»Ÿ\n",
    "event_system = EventSystem()\n",
    "\n",
    "class EventDrivenState(TypedDict):\n",
    "    messages: List[str]\n",
    "    current_step: str\n",
    "    progress: int\n",
    "    results: Dict[str, Any]\n",
    "    events: List[Dict[str, Any]]\n",
    "\n",
    "def event_aware_node(node_name: str):\n",
    "    \"\"\"åˆ›å»ºäº‹ä»¶æ„ŸçŸ¥çš„èŠ‚ç‚¹è£…é¥°å™¨\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(state: EventDrivenState) -> EventDrivenState:\n",
    "            # è§¦å‘èŠ‚ç‚¹å¼€å§‹äº‹ä»¶\n",
    "            event_system.emit(\"node_start\", {\n",
    "                \"node_name\": node_name,\n",
    "                \"input_state\": state.copy()\n",
    "            })\n",
    "            \n",
    "            try:\n",
    "                # æ‰§è¡ŒèŠ‚ç‚¹å‡½æ•°\n",
    "                result_state = func(state)\n",
    "                \n",
    "                # è§¦å‘èŠ‚ç‚¹å®Œæˆäº‹ä»¶\n",
    "                event_system.emit(\"node_complete\", {\n",
    "                    \"node_name\": node_name,\n",
    "                    \"output_state\": result_state.copy()\n",
    "                })\n",
    "                \n",
    "                return result_state\n",
    "                \n",
    "            except Exception as e:\n",
    "                # è§¦å‘èŠ‚ç‚¹é”™è¯¯äº‹ä»¶\n",
    "                event_system.emit(\"node_error\", {\n",
    "                    \"node_name\": node_name,\n",
    "                    \"error\": str(e),\n",
    "                    \"state\": state.copy()\n",
    "                })\n",
    "                raise\n",
    "        \n",
    "        return wrapper\n",
    "    return decorator\n",
    "\n",
    "@event_aware_node(\"æ•°æ®æ”¶é›†\")\n",
    "def data_collection_node(state: EventDrivenState) -> EventDrivenState:\n",
    "    \"\"\"æ•°æ®æ”¶é›†èŠ‚ç‚¹\"\"\"\n",
    "    state[\"current_step\"] = \"æ”¶é›†æ•°æ®\"\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ•°æ®æ”¶é›†è¿‡ç¨‹\n",
    "    collected_data = []\n",
    "    for i in range(1, 6):\n",
    "        time.sleep(0.2)\n",
    "        data_item = f\"æ•°æ®é¡¹_{i}\"\n",
    "        collected_data.append(data_item)\n",
    "        \n",
    "        # è§¦å‘æ•°æ®æ”¶é›†äº‹ä»¶\n",
    "        event_system.emit(\"data_collected\", {\n",
    "            \"item\": data_item,\n",
    "            \"count\": len(collected_data)\n",
    "        })\n",
    "        \n",
    "        state[\"progress\"] = i * 20\n",
    "    \n",
    "    state[\"results\"][\"collected_data\"] = collected_data\n",
    "    state[\"messages\"].append(f\"æ”¶é›†äº† {len(collected_data)} ä¸ªæ•°æ®é¡¹\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "@event_aware_node(\"æ•°æ®åˆ†æ\")\n",
    "def data_analysis_node(state: EventDrivenState) -> EventDrivenState:\n",
    "    \"\"\"æ•°æ®åˆ†æèŠ‚ç‚¹\"\"\"\n",
    "    state[\"current_step\"] = \"åˆ†ææ•°æ®\"\n",
    "    \n",
    "    collected_data = state[\"results\"].get(\"collected_data\", [])\n",
    "    \n",
    "    # åˆ†ææ•°æ®\n",
    "    analysis_results = {\n",
    "        \"total_items\": len(collected_data),\n",
    "        \"analysis_time\": datetime.now().isoformat(),\n",
    "        \"summary\": \"æ•°æ®åˆ†æå®Œæˆ\"\n",
    "    }\n",
    "    \n",
    "    time.sleep(0.5)\n",
    "    \n",
    "    # è§¦å‘åˆ†æå®Œæˆäº‹ä»¶\n",
    "    event_system.emit(\"analysis_complete\", {\n",
    "        \"results\": analysis_results\n",
    "    })\n",
    "    \n",
    "    state[\"results\"][\"analysis\"] = analysis_results\n",
    "    state[\"messages\"].append(\"æ•°æ®åˆ†æå®Œæˆ\")\n",
    "    state[\"progress\"] = 100\n",
    "    \n",
    "    return state\n",
    "\n",
    "# æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨\n",
    "def on_node_start(event):\n",
    "    print(f\"ğŸŸ¡ èŠ‚ç‚¹å¼€å§‹: {event['data']['node_name']} at {event['timestamp']}\")\n",
    "\n",
    "def on_node_complete(event):\n",
    "    print(f\"ğŸŸ¢ èŠ‚ç‚¹å®Œæˆ: {event['data']['node_name']} at {event['timestamp']}\")\n",
    "\n",
    "def on_data_collected(event):\n",
    "    print(f\"ğŸ“Š æ”¶é›†æ•°æ®: {event['data']['item']} (æ€»è®¡: {event['data']['count']})\")\n",
    "\n",
    "def on_analysis_complete(event):\n",
    "    print(f\"ğŸ” åˆ†æå®Œæˆ: {event['data']['results']['summary']}\")\n",
    "\n",
    "def on_node_error(event):\n",
    "    print(f\"âŒ èŠ‚ç‚¹é”™è¯¯: {event['data']['node_name']} - {event['data']['error']}\")\n",
    "\n",
    "# æ³¨å†Œç›‘å¬å™¨\n",
    "event_system.on(\"node_start\", on_node_start)\n",
    "event_system.on(\"node_complete\", on_node_complete)\n",
    "event_system.on(\"data_collected\", on_data_collected)\n",
    "event_system.on(\"analysis_complete\", on_analysis_complete)\n",
    "event_system.on(\"node_error\", on_node_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 è¿è¡Œäº‹ä»¶é©±åŠ¨ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºäº‹ä»¶é©±åŠ¨çš„å›¾\n",
    "event_workflow = StateGraph(EventDrivenState)\n",
    "event_workflow.add_node(\"collect\", data_collection_node)\n",
    "event_workflow.add_node(\"analyze\", data_analysis_node)\n",
    "\n",
    "event_workflow.add_edge(START, \"collect\")\n",
    "event_workflow.add_edge(\"collect\", \"analyze\")\n",
    "event_workflow.add_edge(\"analyze\", END)\n",
    "\n",
    "event_app = event_workflow.compile()\n",
    "\n",
    "# è¿è¡Œäº‹ä»¶é©±åŠ¨ç³»ç»Ÿ\n",
    "initial_state = {\n",
    "    \"messages\": [],\n",
    "    \"current_step\": \"åˆå§‹åŒ–\",\n",
    "    \"progress\": 0,\n",
    "    \"results\": {},\n",
    "    \"events\": []\n",
    "}\n",
    "\n",
    "print(\"=== äº‹ä»¶é©±åŠ¨ç³»ç»Ÿæ¼”ç¤º ===\")\n",
    "final_state = event_app.invoke(initial_state)\n",
    "\n",
    "print(\"\\n=== äº‹ä»¶å†å² ===\")\n",
    "for event in event_system.get_history():\n",
    "    print(f\"{event['timestamp']}: {event['type']} - {event.get('data', {})}\")\n",
    "\n",
    "print(f\"\\n=== æœ€ç»ˆç»“æœ ===\")\n",
    "print(f\"æ¶ˆæ¯: {final_state['messages']}\")\n",
    "print(f\"ç»“æœ: {final_state['results']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. WebSocketå®æ—¶é€šä¿¡ç³»ç»Ÿ\n",
    "\n",
    "### 4.1 WebSocketæœåŠ¡å™¨æ¨¡æ‹Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import queue\n",
    "import threading\n",
    "from typing import Optional\n",
    "\n",
    "class MockWebSocketServer:\n",
    "    \"\"\"æ¨¡æ‹ŸWebSocketæœåŠ¡å™¨\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.clients = []\n",
    "        self.message_queue = queue.Queue()\n",
    "        self.running = False\n",
    "    \n",
    "    def add_client(self, client_id: str):\n",
    "        \"\"\"æ·»åŠ å®¢æˆ·ç«¯\"\"\"\n",
    "        self.clients.append(client_id)\n",
    "        print(f\"å®¢æˆ·ç«¯ {client_id} è¿æ¥\")\n",
    "    \n",
    "    def remove_client(self, client_id: str):\n",
    "        \"\"\"ç§»é™¤å®¢æˆ·ç«¯\"\"\"\n",
    "        if client_id in self.clients:\n",
    "            self.clients.remove(client_id)\n",
    "            print(f\"å®¢æˆ·ç«¯ {client_id} æ–­å¼€è¿æ¥\")\n",
    "    \n",
    "    def broadcast(self, message: Dict[str, Any]):\n",
    "        \"\"\"å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰å®¢æˆ·ç«¯\"\"\"\n",
    "        for client in self.clients:\n",
    "            print(f\"ğŸ“¡ å‘é€ç»™ {client}: {json.dumps(message, ensure_ascii=False)}\")\n",
    "    \n",
    "    def send_to_client(self, client_id: str, message: Dict[str, Any]):\n",
    "        \"\"\"å‘é€æ¶ˆæ¯ç»™ç‰¹å®šå®¢æˆ·ç«¯\"\"\"\n",
    "        if client_id in self.clients:\n",
    "            print(f\"ğŸ“¨ å‘é€ç»™ {client_id}: {json.dumps(message, ensure_ascii=False)}\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ å®¢æˆ·ç«¯ {client_id} ä¸å­˜åœ¨\")\n",
    "\n",
    "# åˆ›å»ºWebSocketæœåŠ¡å™¨å®ä¾‹\n",
    "ws_server = MockWebSocketServer()\n",
    "\n",
    "class WebSocketState(TypedDict):\n",
    "    messages: List[str]\n",
    "    current_step: str\n",
    "    progress: int\n",
    "    results: Dict[str, Any]\n",
    "    client_id: str\n",
    "\n",
    "def websocket_data_processor(state: WebSocketState) -> WebSocketState:\n",
    "    \"\"\"WebSocketæ•°æ®å¤„ç†èŠ‚ç‚¹\"\"\"\n",
    "    client_id = state[\"client_id\"]\n",
    "    \n",
    "    # å‘é€å¼€å§‹æ¶ˆæ¯\n",
    "    ws_server.send_to_client(client_id, {\n",
    "        \"type\": \"processing_start\",\n",
    "        \"message\": \"å¼€å§‹æ•°æ®å¤„ç†\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "    \n",
    "    # æ¨¡æ‹Ÿæ•°æ®å¤„ç†è¿‡ç¨‹\n",
    "    for i in range(1, 6):\n",
    "        time.sleep(0.5)\n",
    "        progress = i * 20\n",
    "        \n",
    "        # å‘é€è¿›åº¦æ›´æ–°\n",
    "        ws_server.send_to_client(client_id, {\n",
    "            \"type\": \"progress_update\",\n",
    "            \"progress\": progress,\n",
    "            \"step\": f\"å¤„ç†æ­¥éª¤ {i}/5\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        state[\"progress\"] = progress\n",
    "        state[\"current_step\"] = f\"å¤„ç†æ­¥éª¤ {i}/5\"\n",
    "    \n",
    "    # å‘é€å®Œæˆæ¶ˆæ¯\n",
    "    result_data = {\"processed_items\": 100, \"status\": \"å®Œæˆ\"}\n",
    "    ws_server.send_to_client(client_id, {\n",
    "        \"type\": \"processing_complete\",\n",
    "        \"result\": result_data,\n",
    "        \"message\": \"æ•°æ®å¤„ç†å®Œæˆ\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "    \n",
    "    state[\"results\"][\"processing\"] = result_data\n",
    "    state[\"messages\"].append(\"æ•°æ®å¤„ç†å®Œæˆ\")\n",
    "    \n",
    "    return state\n",
    "\n",
    "def websocket_analyzer(state: WebSocketState) -> WebSocketState:\n",
    "    \"\"\"WebSocketåˆ†æèŠ‚ç‚¹\"\"\"\n",
    "    client_id = state[\"client_id\"]\n",
    "    \n",
    "    # å‘é€åˆ†æå¼€å§‹æ¶ˆæ¯\n",
    "    ws_server.send_to_client(client_id, {\n",
    "        \"type\": \"analysis_start\",\n",
    "        \"message\": \"å¼€å§‹æ•°æ®åˆ†æ\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "    \n",
    "    time.sleep(1)\n",
    "    \n",
    "    # åˆ†æç»“æœ\n",
    "    analysis_result = {\n",
    "        \"patterns_found\": 3,\n",
    "        \"accuracy\": 0.95,\n",
    "        \"insights\": [\"è¶‹åŠ¿1\", \"è¶‹åŠ¿2\", \"è¶‹åŠ¿3\"]\n",
    "    }\n",
    "    \n",
    "    # å‘é€åˆ†æå®Œæˆæ¶ˆæ¯\n",
    "    ws_server.send_to_client(client_id, {\n",
    "        \"type\": \"analysis_complete\",\n",
    "        \"result\": analysis_result,\n",
    "        \"message\": \"æ•°æ®åˆ†æå®Œæˆ\",\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    })\n",
    "    \n",
    "    state[\"results\"][\"analysis\"] = analysis_result\n",
    "    state[\"messages\"].append(\"æ•°æ®åˆ†æå®Œæˆ\")\n",
    "    state[\"progress\"] = 100\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 WebSocketå®æ—¶å¤„ç†ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºWebSocketå¤„ç†å›¾\n",
    "ws_workflow = StateGraph(WebSocketState)\n",
    "ws_workflow.add_node(\"process\", websocket_data_processor)\n",
    "ws_workflow.add_node(\"analyze\", websocket_analyzer)\n",
    "\n",
    "ws_workflow.add_edge(START, \"process\")\n",
    "ws_workflow.add_edge(\"process\", \"analyze\")\n",
    "ws_workflow.add_edge(\"analyze\", END)\n",
    "\n",
    "ws_app = ws_workflow.compile()\n",
    "\n",
    "def handle_client_request(client_id: str, request_data: Dict[str, Any]):\n",
    "    \"\"\"å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚\"\"\"\n",
    "    print(f\"\\n=== å¤„ç†å®¢æˆ·ç«¯ {client_id} çš„è¯·æ±‚ ===\")\n",
    "    \n",
    "    # æ·»åŠ å®¢æˆ·ç«¯\n",
    "    ws_server.add_client(client_id)\n",
    "    \n",
    "    # åˆ›å»ºåˆå§‹çŠ¶æ€\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"current_step\": \"åˆå§‹åŒ–\",\n",
    "        \"progress\": 0,\n",
    "        \"results\": {},\n",
    "        \"client_id\": client_id\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # å‘é€ç¡®è®¤æ¶ˆæ¯\n",
    "        ws_server.send_to_client(client_id, {\n",
    "            \"type\": \"request_received\",\n",
    "            \"message\": \"è¯·æ±‚å·²æ¥æ”¶ï¼Œå¼€å§‹å¤„ç†\",\n",
    "            \"request_data\": request_data,\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "        # æ‰§è¡Œå¤„ç†æµç¨‹\n",
    "        final_state = ws_app.invoke(initial_state)\n",
    "        \n",
    "        # å‘é€æœ€ç»ˆç»“æœ\n",
    "        ws_server.send_to_client(client_id, {\n",
    "            \"type\": \"task_complete\",\n",
    "            \"message\": \"ä»»åŠ¡å®Œæˆ\",\n",
    "            \"final_results\": final_state[\"results\"],\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "        \n",
    "    except Exception as e:\n",
    "        # å‘é€é”™è¯¯æ¶ˆæ¯\n",
    "        ws_server.send_to_client(client_id, {\n",
    "            \"type\": \"error\",\n",
    "            \"message\": f\"å¤„ç†é”™è¯¯: {str(e)}\",\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        })\n",
    "    \n",
    "    finally:\n",
    "        # ç§»é™¤å®¢æˆ·ç«¯\n",
    "        ws_server.remove_client(client_id)\n",
    "\n",
    "# æ¨¡æ‹Ÿå¤šä¸ªå®¢æˆ·ç«¯è¯·æ±‚\n",
    "client_requests = [\n",
    "    {\"client_id\": \"client_001\", \"data\": {\"task\": \"æ•°æ®åˆ†æ\", \"priority\": \"high\"}},\n",
    "    {\"client_id\": \"client_002\", \"data\": {\"task\": \"æ•°æ®å¤„ç†\", \"priority\": \"normal\"}}\n",
    "]\n",
    "\n",
    "# å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚\n",
    "for request in client_requests:\n",
    "    handle_client_request(request[\"client_id\"], request[\"data\"])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å®é™…åº”ç”¨ï¼šå®æ—¶ç›‘æ§ä»ªè¡¨æ¿\n",
    "\n",
    "### 5.1 ç›‘æ§ç³»ç»ŸçŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "@dataclass\n",
    "class SystemMetrics:\n",
    "    \"\"\"ç³»ç»ŸæŒ‡æ ‡\"\"\"\n",
    "    timestamp: str\n",
    "    cpu_usage: float\n",
    "    memory_usage: float\n",
    "    disk_usage: float\n",
    "    network_io: float\n",
    "    active_connections: int\n",
    "    error_rate: float\n",
    "\n",
    "class MonitoringDashboard:\n",
    "    \"\"\"ç›‘æ§ä»ªè¡¨æ¿\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.connected_clients = set()\n",
    "        self.metrics_history = []\n",
    "        self.alert_thresholds = {\n",
    "            \"cpu_usage\": 80.0,\n",
    "            \"memory_usage\": 85.0,\n",
    "            \"disk_usage\": 90.0,\n",
    "            \"error_rate\": 5.0\n",
    "        }\n",
    "    \n",
    "    def add_client(self, client_id: str):\n",
    "        \"\"\"æ·»åŠ ç›‘æ§å®¢æˆ·ç«¯\"\"\"\n",
    "        self.connected_clients.add(client_id)\n",
    "        print(f\"ğŸŸ¢ ç›‘æ§å®¢æˆ·ç«¯ {client_id} å·²è¿æ¥\")\n",
    "    \n",
    "    def remove_client(self, client_id: str):\n",
    "        \"\"\"ç§»é™¤ç›‘æ§å®¢æˆ·ç«¯\"\"\"\n",
    "        self.connected_clients.discard(client_id)\n",
    "        print(f\"ğŸ”´ ç›‘æ§å®¢æˆ·ç«¯ {client_id} å·²æ–­å¼€\")\n",
    "    \n",
    "    def generate_metrics(self) -> SystemMetrics:\n",
    "        \"\"\"ç”Ÿæˆç³»ç»ŸæŒ‡æ ‡\"\"\"\n",
    "        return SystemMetrics(\n",
    "            timestamp=datetime.now().isoformat(),\n",
    "            cpu_usage=random.uniform(20, 95),\n",
    "            memory_usage=random.uniform(30, 90),\n",
    "            disk_usage=random.uniform(40, 85),\n",
    "            network_io=random.uniform(0, 100),\n",
    "            active_connections=random.randint(10, 500),\n",
    "            error_rate=random.uniform(0, 10)\n",
    "        )\n",
    "    \n",
    "    def check_alerts(self, metrics: SystemMetrics) -> List[Dict[str, Any]]:\n",
    "        \"\"\"æ£€æŸ¥å‘Šè­¦\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        for metric_name, threshold in self.alert_thresholds.items():\n",
    "            value = getattr(metrics, metric_name)\n",
    "            if value > threshold:\n",
    "                alerts.append({\n",
    "                    \"type\": \"threshold_exceeded\",\n",
    "                    \"metric\": metric_name,\n",
    "                    \"value\": value,\n",
    "                    \"threshold\": threshold,\n",
    "                    \"severity\": \"high\" if value > threshold * 1.1 else \"medium\",\n",
    "                    \"timestamp\": metrics.timestamp\n",
    "                })\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    def broadcast_metrics(self, metrics: SystemMetrics, alerts: List[Dict[str, Any]]):\n",
    "        \"\"\"å¹¿æ’­æŒ‡æ ‡ç»™æ‰€æœ‰å®¢æˆ·ç«¯\"\"\"\n",
    "        message = {\n",
    "            \"type\": \"metrics_update\",\n",
    "            \"metrics\": asdict(metrics),\n",
    "            \"alerts\": alerts,\n",
    "            \"client_count\": len(self.connected_clients)\n",
    "        }\n",
    "        \n",
    "        for client_id in self.connected_clients:\n",
    "            print(f\"ğŸ“Š å‘é€æŒ‡æ ‡ç»™ {client_id}:\")\n",
    "            print(f\"   CPU: {metrics.cpu_usage:.1f}% | å†…å­˜: {metrics.memory_usage:.1f}% | ç£ç›˜: {metrics.disk_usage:.1f}%\")\n",
    "            print(f\"   ç½‘ç»œIO: {metrics.network_io:.1f} MB/s | è¿æ¥: {metrics.active_connections} | é”™è¯¯ç‡: {metrics.error_rate:.2f}%\")\n",
    "            \n",
    "            if alerts:\n",
    "                print(f\"   âš ï¸ å‘Šè­¦æ•°é‡: {len(alerts)}\")\n",
    "                for alert in alerts:\n",
    "                    print(f\"      {alert['severity'].upper()}: {alert['metric']} = {alert['value']:.1f} (é˜ˆå€¼: {alert['threshold']})\")\n",
    "            print()\n",
    "\n",
    "# åˆ›å»ºç›‘æ§ä»ªè¡¨æ¿\n",
    "dashboard = MonitoringDashboard()\n",
    "\n",
    "class MonitoringState(TypedDict):\n",
    "    dashboard: MonitoringDashboard\n",
    "    current_metrics: Optional[SystemMetrics]\n",
    "    alerts: List[Dict[str, Any]]\n",
    "    running: bool\n",
    "\n",
    "def metrics_collector_node(state: MonitoringState) -> MonitoringState:\n",
    "    \"\"\"æŒ‡æ ‡æ”¶é›†èŠ‚ç‚¹\"\"\"\n",
    "    dashboard = state[\"dashboard\"]\n",
    "    \n",
    "    # ç”Ÿæˆæ–°çš„æŒ‡æ ‡\n",
    "    metrics = dashboard.generate_metrics()\n",
    "    dashboard.metrics_history.append(metrics)\n",
    "    \n",
    "    # æ£€æŸ¥å‘Šè­¦\n",
    "    alerts = dashboard.check_alerts(metrics)\n",
    "    \n",
    "    # æ›´æ–°çŠ¶æ€\n",
    "    state[\"current_metrics\"] = metrics\n",
    "    state[\"alerts\"] = alerts\n",
    "    \n",
    "    return state\n",
    "\n",
    "def metrics_broadcaster_node(state: MonitoringState) -> MonitoringState:\n",
    "    \"\"\"æŒ‡æ ‡å¹¿æ’­èŠ‚ç‚¹\"\"\"\n",
    "    dashboard = state[\"dashboard\"]\n",
    "    metrics = state[\"current_metrics\"]\n",
    "    alerts = state[\"alerts\"]\n",
    "    \n",
    "    if metrics and dashboard.connected_clients:\n",
    "        dashboard.broadcast_metrics(metrics, alerts)\n",
    "    \n",
    "    return state\n",
    "\n",
    "def should_continue(state: MonitoringState) -> str:\n",
    "    \"\"\"åˆ¤æ–­æ˜¯å¦ç»§ç»­ç›‘æ§\"\"\"\n",
    "    return \"collect\" if state[\"running\"] else END\n",
    "\n",
    "# åˆ›å»ºç›‘æ§å›¾\n",
    "monitoring_workflow = StateGraph(MonitoringState)\n",
    "monitoring_workflow.add_node(\"collect\", metrics_collector_node)\n",
    "monitoring_workflow.add_node(\"broadcast\", metrics_broadcaster_node)\n",
    "\n",
    "monitoring_workflow.add_edge(START, \"collect\")\n",
    "monitoring_workflow.add_edge(\"collect\", \"broadcast\")\n",
    "monitoring_workflow.add_conditional_edges(\n",
    "    \"broadcast\",\n",
    "    should_continue,\n",
    "    {\"collect\": \"collect\", END: END}\n",
    ")\n",
    "\n",
    "monitoring_app = monitoring_workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 è¿è¡Œå®æ—¶ç›‘æ§ç³»ç»Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_monitoring_system():\n",
    "    \"\"\"è¿è¡Œç›‘æ§ç³»ç»Ÿ\"\"\"\n",
    "    # æ·»åŠ å®¢æˆ·ç«¯\n",
    "    dashboard.add_client(\"admin_dashboard\")\n",
    "    dashboard.add_client(\"mobile_app\")\n",
    "    dashboard.add_client(\"alert_system\")\n",
    "    \n",
    "    # åˆ›å»ºåˆå§‹çŠ¶æ€\n",
    "    initial_state = {\n",
    "        \"dashboard\": dashboard,\n",
    "        \"current_metrics\": None,\n",
    "        \"alerts\": [],\n",
    "        \"running\": True\n",
    "    }\n",
    "    \n",
    "    print(\"=== å¯åŠ¨å®æ—¶ç›‘æ§ç³»ç»Ÿ ===\")\n",
    "    print(f\"è¿æ¥çš„å®¢æˆ·ç«¯: {list(dashboard.connected_clients)}\")\n",
    "    print()\n",
    "    \n",
    "    # è¿è¡Œ5ä¸ªç›‘æ§å‘¨æœŸ\n",
    "    for cycle in range(5):\n",
    "        print(f\"--- ç›‘æ§å‘¨æœŸ {cycle + 1} ---\")\n",
    "        \n",
    "        # æ‰§è¡Œä¸€æ¬¡ç›‘æ§å¾ªç¯\n",
    "        result_state = monitoring_app.invoke(initial_state)\n",
    "        \n",
    "        # æ›´æ–°è¿è¡ŒçŠ¶æ€\n",
    "        initial_state = result_state\n",
    "        \n",
    "        # ç­‰å¾…ä¸‹ä¸€ä¸ªå‘¨æœŸ\n",
    "        await asyncio.sleep(2)\n",
    "    \n",
    "    # åœæ­¢ç›‘æ§\n",
    "    initial_state[\"running\"] = False\n",
    "    print(\"\\n=== åœæ­¢ç›‘æ§ç³»ç»Ÿ ===\")\n",
    "    \n",
    "    # ç§»é™¤å®¢æˆ·ç«¯\n",
    "    for client_id in list(dashboard.connected_clients):\n",
    "        dashboard.remove_client(client_id)\n",
    "    \n",
    "    print(f\"\\næ€»å…±æ”¶é›†äº† {len(dashboard.metrics_history)} ä¸ªæŒ‡æ ‡æ•°æ®ç‚¹\")\n",
    "    \n",
    "    # æ˜¾ç¤ºå†å²æŒ‡æ ‡ç»Ÿè®¡\n",
    "    if dashboard.metrics_history:\n",
    "        avg_cpu = sum(m.cpu_usage for m in dashboard.metrics_history) / len(dashboard.metrics_history)\n",
    "        avg_memory = sum(m.memory_usage for m in dashboard.metrics_history) / len(dashboard.metrics_history)\n",
    "        max_connections = max(m.active_connections for m in dashboard.metrics_history)\n",
    "        \n",
    "        print(f\"å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%\")\n",
    "        print(f\"å¹³å‡å†…å­˜ä½¿ç”¨ç‡: {avg_memory:.1f}%\")\n",
    "        print(f\"æœ€å¤§è¿æ¥æ•°: {max_connections}\")\n",
    "\n",
    "# è¿è¡Œç›‘æ§ç³»ç»Ÿ\n",
    "await run_monitoring_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. å®è·µç»ƒä¹ \n",
    "\n",
    "### ç»ƒä¹ 1ï¼šåˆ›å»ºè‚¡ç¥¨ä»·æ ¼å®æ—¶æ¨é€ç³»ç»Ÿ\n",
    "åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿè‚¡ç¥¨ä»·æ ¼å®æ—¶æ¨é€ç³»ç»Ÿï¼Œè¦æ±‚ï¼š\n",
    "- æ¨¡æ‹Ÿå¤šåªè‚¡ç¥¨çš„ä»·æ ¼å˜åŠ¨\n",
    "- æ”¯æŒå®¢æˆ·ç«¯è®¢é˜…ç‰¹å®šè‚¡ç¥¨\n",
    "- å®æ—¶æ¨é€ä»·æ ¼å˜åŠ¨å’Œå‘Šè­¦ä¿¡æ¯\n",
    "- æ”¯æŒå†å²æ•°æ®æŸ¥è¯¢\n",
    "\n",
    "### ç»ƒä¹ 2ï¼šå®ç°èŠå¤©å®¤ç³»ç»Ÿ\n",
    "ä½¿ç”¨æµå¼è¾“å‡ºå®ç°ä¸€ä¸ªèŠå¤©å®¤ç³»ç»Ÿï¼Œè¦æ±‚ï¼š\n",
    "- æ”¯æŒå¤šç”¨æˆ·å®æ—¶èŠå¤©\n",
    "- æ¶ˆæ¯å¹¿æ’­å’Œç§èŠåŠŸèƒ½\n",
    "- ç”¨æˆ·çŠ¶æ€ç®¡ç†ï¼ˆåœ¨çº¿/ç¦»çº¿ï¼‰\n",
    "- æ¶ˆæ¯å†å²è®°å½•\n",
    "\n",
    "### ç»ƒä¹ 3ï¼šæ„å»ºå®æ—¶æ—¥å¿—åˆ†æç³»ç»Ÿ\n",
    "åˆ›å»ºä¸€ä¸ªå®æ—¶æ—¥å¿—åˆ†æç³»ç»Ÿï¼Œè¦æ±‚ï¼š\n",
    "- å®æ—¶å¤„ç†æ—¥å¿—æµ\n",
    "- å¼‚å¸¸æ£€æµ‹å’Œå‘Šè­¦\n",
    "- ç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–\n",
    "- æ”¯æŒå¤šç§æ—¥å¿—æ ¼å¼"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ€»ç»“\n",
    "\n",
    "æœ¬æ•™ç¨‹è¯¦ç»†ä»‹ç»äº†LangGraphçš„æµå¼è¾“å‡ºå’Œå®æ—¶äº¤äº’åŠŸèƒ½ï¼š\n",
    "\n",
    "### å…³é”®æ¦‚å¿µ\n",
    "1. **æµå¼è¾“å‡º**ï¼šä½¿ç”¨`stream()`å’Œ`astream()`æ–¹æ³•è·å–æ‰§è¡Œè¿‡ç¨‹ä¸­çš„ä¸­é—´ç»“æœ\n",
    "2. **å¼‚æ­¥å¤„ç†**ï¼šæ”¯æŒå¼‚æ­¥èŠ‚ç‚¹å’Œå¹¶å‘æ‰§è¡Œï¼Œæé«˜ç³»ç»Ÿæ€§èƒ½\n",
    "3. **äº‹ä»¶ç³»ç»Ÿ**ï¼šé€šè¿‡äº‹ä»¶ç›‘å¬å®ç°æ¾è€¦åˆçš„ç³»ç»Ÿç»„ä»¶é€šä¿¡\n",
    "4. **å®æ—¶é€šä¿¡**ï¼šæ¨¡æ‹ŸWebSocketç­‰å®æ—¶é€šä¿¡åè®®\n",
    "5. **ç›‘æ§ä»ªè¡¨æ¿**ï¼šå®ç°å®æ—¶æŒ‡æ ‡æ”¶é›†å’Œå¹¿æ’­ç³»ç»Ÿ\n",
    "\n",
    "### æœ€ä½³å®è·µ\n",
    "1. **åˆç†ä½¿ç”¨æµå¼è¾“å‡º**ï¼šå¯¹äºé•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼Œä½¿ç”¨æµå¼è¾“å‡ºæä¾›è¿›åº¦åé¦ˆ\n",
    "2. **å¼‚æ­¥ä¼˜åŒ–**ï¼šå¯¹äºI/Oå¯†é›†å‹ä»»åŠ¡ï¼Œä½¿ç”¨å¼‚æ­¥èŠ‚ç‚¹æé«˜å¹¶å‘æ€§èƒ½\n",
    "3. **äº‹ä»¶è§£è€¦**ï¼šé€šè¿‡äº‹ä»¶ç³»ç»Ÿå®ç°ç»„ä»¶é—´çš„æ¾è€¦åˆ\n",
    "4. **é”™è¯¯å¤„ç†**ï¼šåœ¨å®æ—¶ç³»ç»Ÿä¸­å®ç°robustçš„é”™è¯¯å¤„ç†å’Œæ¢å¤æœºåˆ¶\n",
    "5. **æ€§èƒ½ç›‘æ§**ï¼šå®æ—¶ç›‘æ§ç³»ç»Ÿæ€§èƒ½å’Œèµ„æºä½¿ç”¨æƒ…å†µ\n",
    "\n",
    "### åº”ç”¨åœºæ™¯\n",
    "- å®æ—¶æ•°æ®å¤„ç†ç®¡é“\n",
    "- ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ\n",
    "- å®æ—¶é€šä¿¡åº”ç”¨\n",
    "- åœ¨çº¿åä½œå¹³å°\n",
    "- å®æ—¶åˆ†æä»ªè¡¨æ¿\n",
    "\n",
    "é€šè¿‡æŒæ¡è¿™äº›æµå¼è¾“å‡ºå’Œå®æ—¶äº¤äº’æŠ€æœ¯ï¼Œä½ å¯ä»¥æ„å»ºé«˜æ•ˆã€å“åº”è¿…é€Ÿçš„å®æ—¶åº”ç”¨ç³»ç»Ÿã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}